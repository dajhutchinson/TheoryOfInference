\documentclass[11pt,a4paper]{article}

\usepackage[margin=1in, paperwidth=8.3in, paperheight=11.7in]{geometry}
\usepackage[ruled, vlined, linesnumbered]{algorithm2e}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{dsfont}
\usepackage{enumerate}
\usepackage{enumitem}
\usepackage{fancyhdr}
\usepackage{graphicx}
\usepackage{tikz}
\usepackage{changepage} 

\begin{document}

\pagestyle{fancy}
\setlength\parindent{0pt}
\allowdisplaybreaks

\renewcommand{\headrulewidth}{0pt}
\setlist[enumerate,1]{label={\roman*)}}

% Cover page title
\title{Theory of Inference - Notes}
\author{Dom Hutchinson}
\date{\today}
\maketitle

% Header
\fancyhead[L]{Dom Hutchinson}
\fancyhead[C]{Theory of Inference - Notes}
\fancyhead[R]{\today}

% Counters
\newcounter{definition}[section]
\newcounter{example}[section]
\newcounter{notation}[section]
\newcounter{proposition}[section]
\newcounter{proof}[section]
\newcounter{remark}[section]
\newcounter{theorem}[section]

% commands
\newcommand{\dotprod}[0]{\boldsymbol{\cdot}}
\newcommand{\cosech}[0]{\mathrm{cosech}\ }
\newcommand{\cosec}[0]{\mathrm{cosec}\ }
\newcommand{\sech}[0]{\mathrm{sech}\ }
\newcommand{\prob}[0]{\mathbb{P}}
\newcommand{\nats}[0]{\mathbb{N}}
\newcommand{\cov}[0]{\mathrm{Cov}}
\newcommand{\var}[0]{\mathrm{Var}}
\newcommand{\expect}[0]{\mathbb{E}}
\newcommand{\reals}[0]{\mathbb{R}}
\newcommand{\integers}[0]{\mathbb{Z}}
\newcommand{\indicator}[0]{\mathds{1}}
\newcommand{\nb}[0]{\textit{N.B.} }
\newcommand{\ie}[0]{\textit{i.e.} }
\newcommand{\eg}[0]{\textit{e.g.} }
\newcommand{\X}[0]{\textbf{X}}
\newcommand{\x}[0]{\textbf{x}}
\newcommand{\iid}[0]{\overset{\text{iid}}{\sim}}
\newcommand{\proved}[0]{$\hfill\square$\\}

\newcommand{\definition}[1]{\stepcounter{definition} \textbf{Definition \arabic{section}.\arabic{definition}\ - }\textit{#1}\\}
\newcommand{\definitionn}[1]{\stepcounter{definition} \textbf{Definition \arabic{section}.\arabic{definition}\ - }\textit{#1}}
\newcommand{\proof}[1]{\stepcounter{proof} \textbf{Proof \arabic{section}.\arabic{proof}\ - }\textit{#1}\\}
\newcommand{\prooff}[1]{\stepcounter{proof} \textbf{Proof \arabic{section}.\arabic{proof}\ - }\textit{#1}}
\newcommand{\example}[1]{\stepcounter{example} \textbf{Example \arabic{section}.\arabic{example}\ - }\textit{#1}\\}
\newcommand{\examplee}[1]{\stepcounter{example} \textbf{Example \arabic{section}.\arabic{example}\ - }\textit{#1}}
\newcommand{\notation}[1]{\stepcounter{notation} \textbf{Notation \arabic{section}.\arabic{notation}\ - }\textit{#1}\\}
\newcommand{\notationn}[1]{\stepcounter{notation} \textbf{Notation \arabic{section}.\arabic{notation}\ - }\textit{#1}}
\newcommand{\proposition}[1]{\stepcounter{proposition} \textbf{Proposition \arabic{section}.\arabic{proposition}\ - }\textit{#1}\\}
\newcommand{\propositionn}[1]{\stepcounter{proposition} \textbf{Proposition \arabic{section}.\arabic{proposition}\ - }\textit{#1}}
\newcommand{\remark}[1]{\stepcounter{remark} \textbf{Remark \arabic{section}.\arabic{remark}\ - }\textit{#1}\\}
\newcommand{\remarkk}[1]{\stepcounter{remark} \textbf{Remark \arabic{section}.\arabic{remark}\ - }\textit{#1}}
\newcommand{\theorem}[1]{\stepcounter{theorem} \textbf{Theorem \arabic{section}.\arabic{theorem}\ - }\textit{#1}\\}
\newcommand{\theoremm}[1]{\stepcounter{theorem} \textbf{Theorem \arabic{section}.\arabic{theorem}\ - }\textit{#1}}

\tableofcontents

% Start of content
\newpage

\section{Motivation}

\remark{General Idea}
Learn something about the world using data \& statistical models.\\

\definition{Statistical Models}
\textit{Statistical Models} describe the way in which data is generate. They depend upon \textit{unknown} constant parameters, $\pmb\theta$, and subsidiary information (known data \& parameters).\\

\definition{Parameteric Statistical Inference}
\textit{Parameteric Statistical Inference} is the process of taking some data \& learning the \textit{unknown} parameters of the model which generated it.

\definition{Parameteric Models}
A \textit{Parameteric Model} is a statistical model whose pdf depends on some unknown parameter.\\
A \textit{Semi-Parameteric Models} is a statistical models which contains unknown functions, as well as unknown parameters.\\
A \textit{Non-Parameteric Model} has no parameters and thus makes minimal assumptions about how the data was generated.\\

\proposition{Inferential Questions}
When performing \textit{Statistical Inference} we wish to answer the following questions
\begin{enumerate}
	\item \textit{Confidence Intervals \& Credible Intervals} - What range of parameter valeus are consistent with the data?
	\item \textit{Hypothesis Testing} - Are some pre-specified valeus (or restrictions) for the parameters consistent with the data?
	\item \textit{Model Checking} - Could our model have generated the data at all?
	\item \textit{Model Selection} - Which of several alternative odels could most plausibly have generated the data?
	\item \textit{Statistical Design} - How could we better arrange teh data gathering process to improve the answers to the preceding questions?
\end{enumerate}

\subsection{Examples}

\example{Mean Annual Temperatures}
Consider a dataset of the mean annual temperature in New Haven, Conneticut.\\
Suppose we plot it in a histogram \& notice that it fits a bell curve, then we may assume the data fits a simple model where each data point is observed independently from a $\mathcal{N}(\mu,\sigma^2)$ distribution with $\mu,\sigma^2$ unknown.\\
Then the pdf for each data point, $y_i$, is
$$f(y_i)=\frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac1{2\sigma^2}(y_i-\mu)^2}$$
The pdf for the whole data set, $\textbf{y}$, is the joint pdf of each data point since we assume iid
$$f(\textbf{y})=\prod_{i=1}^Nf(y_i)$$
Now suppose we notice that the histogram is \textit{heavy tailed} relative to a normal distribution.\\
A better model might be
$$\frac{y_i-\mu}\sigma\sim t_\alpha$$
where $\mu,\sigma^2,\alpha$ are unknown.\\
This means the pdf of the whole data set is
$$f(\textbf{y})=\prod_{i=1}^N\frac{1}{\sigma}f_{t_\alpha}\left(\frac{y_i-\mu}{\sigma}\right)$$
by \textit{standard transformation theory}.\\

\example{Hourly Air Temperature}
Consider a dataset of the air temperature, $a_i$, measured at hourly intervals, $t_i$, over the course of a week.\\
The temperature is believed to follow a daily cycle, with a long-term dift over the course of the week and to be subject to random autocorrelated depatures from this overall pattern.\\
A suitable model might be
$$a_i=\underbrace{\theta_0+\theta_1t_i}_\text{Long-Term Drift}+\underbrace{\theta_2\sin(2\pi t_i/24)+\theta_3\cos(2\pi t_i/24)}_\text{Daily Cycle}+\underbrace{e_i}_\text{Auto Correlation}$$
where $e_{i+1}:=\rho r_i+\varepsilon_i$ with $|\rho|<1$ \& $\varepsilon\iid\mathcal{N}(0,\sigma^2)$.\\
This means $\textbf{e}\sim\mathcal{N}(\pmb0,\Sigma)$ \& $\textbf{a}\sim\mathcal{N}(\pmb\mu,\Sigma)$ with $\Sigma_{i,j}=\frac{\rho^{|1-j|}\sigma^2}{1-\rho}$.\\
Thus, the pdf of the data set, $\textbf{a}$, is
$$f(\textbf{a})=\frac{1}{\sqrt{(2\pi)^n|\Sigma|}}e^{-\frac{1}{2}(\textbf{a}-\pmb\mu)^T\Sigma^{-1}(\textbf{a}-\pmb\mu)}$$

\example{Bone Marrow}
Consider a dataset produced 23 patients suffering from non-Hodgkin's Lymphoma are split into two groups, each recieving a different treatment. We wish to test whether one of these treatments is more efficitive than the other.\\
For each patient the days between treatment \& relapse was recorded. We have some \textit{censored data} as the patient had not relapsed by the time of their last appointment.\\
Consider using an exponential distribution to model the times to relapse with parameters $\theta_a$ \& $\theta_b$ respecitvely. We want to test if $\theta_a=\theta_b$.\\
We have the follow pdf for patients in group $a$
$$f_a(t_i)=\begin{cases}\theta_ae^{-\theta_at_i}&\text{uncensored}\\\int_{t_i}^\infty\theta_ae^{-\theta_at_i}=e^{-\theta_at_i}&\text{censored}\end{cases}$$
An equivalent pdf exists for patients in group $b$, with $\theta_b$ swapped in.\\
Thus the model for the whole data set, $\textbf{t}$, is
$$f(\textbf{t})=\prod_{i=1}^{11}f_a(t_i)\prod_{i=12}^{23}f_b(t_i)$$
when patients $\{1,\dots,11\}$ are in group $a$ and the rest in group $b$.

\section{Basic Approaches to Inference}

\definition{Frequentist Approach}
In the \textit{Frequentist Approach} to inference we assume the model parameters are fixed states, which we wish to estimate. The parameter estimator $\hat\theta$ is a random variable which inherits its randomnewss from the data which it is constructed from.\\

\definition{Bayesian Approach}
In the \textit{Bayesian Approach} to inference model parameters are treated as random variables and we use probability distributions to encode our uncertainty about the parameters. We set a prior distribution, $\prob(\theta)$, and then use data to update it and learn a posterior distribution, $\prob(\theta|\x)$.\\

\remark{Assumptions}
Often we are required to make assumptions in order to analyse the results these approaches. For the \textit{Frequentist Approach} we often assume we have a large data set, whilst for the \textit{Bayesian Approach} we produce simulations from the posterior.\\

\example{Comparing Frequentist \& Bayesian Approach}
Let $X_1,\dots,X_n\iid\text{Normal}(\mu,1)$ where $\mu$ is an unknown parameter we wish to learn.\\
Let $\x:=\{x_1,\dots,x_n\}$  be a realisation of $\X$.
\begin{itemize}
	\item[Frequentist]Let's use $\hat\mu=\bar{x}=\frac{1}{n}\sum_{i=1}^n x_i$.\\
	Consider the expectation and variance of $\hat\mu$
	$$\expect(\hat\mu)=\expect(\bar{x})=\frac{1}{n}\sum_{i=1}^n\expect(X_i)=\mu\text{ and }\var(\hat\mu)=\var(\bar{x})=\frac{1}{n^2}\sum_{i=1}^n\var(X_i)=\frac{1}{n}$$
	Since $\hat\mu$ is a linear transformation of normal random variables it has a normal random variable, thus
	$$\hat\mu\sim\text{Normal}\left(\mu,\frac1n\right)$$
	Thus $\hat\mu$ is an \textit{unbiased} estimator of $\mu$.\\
	By noting that $\sqrt{n}(\hat\mu-\mu)\sim\text{Normal}(0,1)$ we can construct \textit{Confidence Intervals} for $\mu$
	\[\begin{array}{rcl}
	0.95&=&\prob(-1.96<\sqrt{n}(\hat\mu-\mu)<1.96)\\
	\implies0.95&=&\prob\left(\hat\mu-\dfrac{1.96}{\sqrt{n}}<\mu<\hat\mu+\dfrac{1.96}{\sqrt{n}}\right)
	\end{array}\]
	\item[Bayesian] Here we treat $\mu$ as a random variable and thus must choose a distribution for it
	$$\mu\sim\text{Normal}(0,\sigma^2_\mu)$$
	where $\sigma^2_\mu$ is a value we set. Generally we choose greater values for the variance when we are less certain.\\
	We want to find $\prob(\mu|\x)$ and note that \textit{Bayes' Rule} states
	$$\prob(\mu|\x)=\dfrac{\prob(\x|\mu)\prob(\mu)}{\prob(\x)}$$
	In this setting $\prob(\x)$ is intractable so we use a trick that since $\prob(\x)$ is a normalising factor we have
	$$\prob(\mu|\x)\propto\prob(\x|\mu)\prob(\mu)$$
	From this proportionality we aim to identity the distribution of $\prob(\mu|\x)$.
	\[\begin{array}{rcl}
	\prob(\mu|\x)&\propto&\text{exp}\left\{-\dfrac{1}{2\sigma^2_\mu}\displaystyle\sum_{i=1}^n[(x_i-\mu)^2+\mu^2]\right\}\\
	&\propto&\text{exp}\left\{-\dfrac{1}{2}\left(-2n\bar{x}\mu+\dfrac{\mu^2(n\sigma^2_\mu+1)}{\sigma^2_\mu}\right)\right\}\\
	&\propto&\text{exp}\left\{-\dfrac12\left(\dfrac{n\sigma^2_\mu+1}{\sigma^2_\mu}\right)\left(\mu^2-2\bar{x}\mu\dfrac{n\sigma^2_\mu}{n\sigma^2_\mu+1}\right)\right\}\\
	&\propto&\text{exp}\Bigg\{-\dfrac12\underbrace{\left(\dfrac{n\sigma^2_\mu+1}{\sigma^2_\mu}\right)}_{1/\sigma^2}\underbrace{\left(\mu-\bar{x}\dfrac{n\sigma^2_\mu}{n\sigma^2_\mu+1}\right)^2}_\mu\Bigg\}\text{ by completing the square}
	\end{array}\]
	We can produce a \textit{Credible Interval} for $\mu$ as
	$$\bar{x}\dfrac{n\sigma^2_\mu}{n\sigma^2_\mu+1}\pm1.96\dfrac{\sigma_mu}{\sqrt{n\sigma^2_\mu+1}}$$
\end{itemize}
If we consider the final distribution from the \textit{Bayesian Approach} as $n\to\infty$ we notice that
$$\mu|\x\to\bar{x}=\hat\mu\quad\text{and}\quad\sigma^2|\x\to\frac1n$$

\subsection{Inference by Resampling}

\remark{Motivation}
The uncertainty we have about a parameter is inherited from the uncertainty in the data sampling process. Often we have a data set \& are unable to repeat the data gathering process, and even if we could we would just combine it into a larger sample rather than split it.\\

\definition{Resampling}
Let $\x$ be a given data set.\\
We can \textit{Resample} from $\x$ be sampling values in $\x$ uniformly, with repetition. Since we use repetition the \textit{Resample}'s size is independent of the size of $\x$ (Although it makes little sense for it to be greater than $|\x|$).\\

\definition{Bootstrapping}
\textit{Bootstrapping} is the process of generating multiple \textit{Resamples} of a data set \& then estimating a parameter value for each of these \textit{resamples}. These estimated values can then be assessed.\\

\example{Bootstrapping}
The algorithm below describes how to perofrm a \textit{Bootstrapping} operation for the mean of a given data set $\x$. It produces $m$ \textit{resamples} of size $n$ from $\x$ and returns a $95\%$ \textit{Confidence Interval} for the estimated means of these samples.\\
\begin{algorithm}[H]
\SetKwInOut{Require}{require}
\caption{Estimating Mean using Bootstrapping}
\Require{$\x\ \{\text{data set}\}$}
$\mu s=\{\}\ \{$resample means$\}$\\
$\mu s$ append $mean(\x)$\\
\For{$i=0\dots m$} {
$x_i\leftarrow sample(\x,n,$replace=$TRUE)$\\
$\mu s$ append $mean(x_i)$
}
\Return{$quantile(\mu s,(0.025,0.0975)$}
\end{algorithm}

\section{Inference for Linear Models}

\definition{Linear Model}
A \textit{Linear Model} is a mathematical model where the \textit{response vector}, $\textbf{y}$, is linear wrt some parameters $\pmb\beta$ and zero-mean \textit{random error} $\pmb\varepsilon$.
$$\textbf{y}=X\pmb\beta+\pmb\varepsilon$$
where $X$ is the \textit{Model Matrix} (\ie observed data).\\
Usually we assume $\pmb\varepsilon\sim\text{Normal}(0,\sigma^2 I)$ although the normality assumption is less important as the \textit{Central Limit Theorem} typically takes care of any issues.\\

\definition{Model Matrix}
A \textit{Model Matrix}, $X$, is the set of values observed in a system. Rows are read as a single observation \& columns as a single \textit{Predictor Varaible}.\\
The \textit{Predictor Variables} fulfil one of the following roles
\begin{itemize}
	\item[-] \textit{Metric} - Quantifable measurement from the system.
	\item[-] \textit{Factor} - A categorisation. Typically take the a binary value ($0,1$) to represent whether an observation fits a given category or not.
\end{itemize}

\remark{Only the parameters of a Linear model need to be linear. The predictor variables can be composed in any way deemed fit.}
$y=\alpha x^2+\varepsilon$ is valid but $y=\alpha^2x+\varepsilon$ is not.\\

\example{Formulating Linear Model}
The following is a linear model for a system with \textit{Metrics} $x_i\ \&\ z_i$ and \textit{Factor} $g_i$.
$$y_i=\gamma_{g_i}+\alpha_1x_i+\alpha_2z_i+\alpha_4z_i^2+\alpha_4z_ix_i+\varepsilon_i$$
where $\gamma_{g_i}$ is the parameter for category represented by $g_i$.\\
We can describe the system about in terms of matrices
$$\begin{pmatrix}y_1\\y_2\\\vdots\\y_n\end{pmatrix}=\begin{pmatrix}1&0&0&x_1&z_1&z_1^2&z_1x_1\\0&0&1&x_2&z_2&z_2^2&z_2x_2\\\vdots&\vdots&\vdots&\vdots&\vdots&\vdots&\vdots\\0&1&0&x_n&z_n&z_n^2&z_nx_n\end{pmatrix}\begin{pmatrix}
\gamma_1\\\gamma_2\\\gamma_3\\\alpha_1\\\alpha_2\\\alpha_3\\\alpha_4\end{pmatrix}+\begin{pmatrix}\varepsilon_1+\varepsilon_2\\\vdots\\\varepsilon_n\end{pmatrix}$$
In the above formulation $y_1$ fulfils category $1$, $y_2$ fulfils $3$ and $y_n$ fulfils $2$.\\

\example{Linear Model}
Consider a data set for the stopping $distance$ of a car with \textit{Predictor Variable} $speed$ at the point at which the signal to stop is given.\\
By considering basic physics we can theorise the following model
\[\begin{array}{rcl}
distance_i&=&\beta_1 speed_i+\beta_2 speed_i^2+\varepsilon_i\\
&=&\text{Thinking}+\text{Loss Kinetic Energy}+\text{Error}
\end{array}\]
where $\varepsilon_i\iid\text{Normal}(0,\sigma^2)$.\\
Suppose we want to test whether to make the model more flexible. We can theorise the following model \& test whether $\beta_0=0=\beta_3$ (as expected).
$$distance_i=\beta_0+\beta_1 speed_i+\beta_2 speed_i^2+\beta_3speed_i^3+\varepsilon_i\\$$

\subsection{Linear Model Estimation \& Checking}

\proposition{Frequentist Approach}
In the \textit{Frequentist Approach} to \textit{Linear Models} we assume that $\pmb\beta$ and $\sigma^2$ are fixed states of nature, although they are unknown to us, and all randomness is inherited from the random variability in the data. We want to find a point estimate for $\pmb\beta$ which minimises the \textit{Residual Sum of Squares}.\\

\definition{Residual Sum of Squares}
Let $(X,\textbf{y})$  be a set of training data \& $\pmb\beta$ a \textit{Parameter Vector}.\\
The \textit{Residual Sum of Squares} is the square difference between our estimate for the \textit{Response Variable} and its true value.
$$S:=\sum_{i=1}^n(y_i-\mu_i)^2=\|\textbf{y}-\pmb\mu\|^2\text{ where }\pmb\mu=X\pmb\beta$$

\proposition{Least Squares for Linear Model}
From the definition of \textit{Residual Sum of Squares} as the \textit{Euclidian Distance} between the response \& estimated vectors we note that its value is unchanged if we reflect or rotate $(\textbf{y}-\pmb\mu)$.\\
Next we note that any real matrix, $X\in\reals(n\times p)$, can be decomposed into
$$X=\mathcal{Q}\begin{pmatrix}R\\0\end{pmatrix}=QR\text{ note that }\mathcal{Q}\neq Q$$
where $R\in\reals(p\times p)$ is an \textit{Upper Triangular Matrix} and $\mathcal{Q}\in\reals(n\times n)$ is an \textit{Orthogonal Matrix}, the first $p$ columns of which form $Q$.\\
Since $\mathcal{Q}$ is \textit{Orthogonal} we have that $\mathcal{Q}^T\mathcal{Q}=I$.\\
We can now derive the result that
\[\begin{array}{rcl}
\|\textbf{y}-X\pmb\beta\|^2&=&\|\mathcal{Q}^T\textbf{y}-\mathcal{Q}^TX\pmb\beta\|^2\\
&=&\left\|\mathcal{Q}^T\textbf{y}-\begin{pmatrix}R\\0\end{pmatrix}\pmb\beta\right\|^2\\
&=&\left\|\begin{pmatrix}\textbf{f}\\\textbf{r}\end{pmatrix}-\begin{pmatrix}R\\0\end{pmatrix}\right\|^2\text{ where }\begin{pmatrix}\textbf{f}\\\textbf{r}\end{pmatrix}\equiv\mathcal{Q}^T\textbf{y}\\
&=&\|\textbf{f}-R\pmb\beta\|^2+\|\textbf{r}\|^2
\end{array}\]
Thus minimising the \textit{Residual Sum of Squares} is reduced to choosing $\pmb\beta$ st $R\pmb\beta=\textbf{f}$.\\
Hence, provided that $X$ and $R$ have full rank
$$\hat{\pmb\beta}_\text{LS}=R^{-1}\textbf{f}$$
\nb After choosing $\pmb\beta$ we have that the \textit{Residual Sum of Squares} is just $\|\textbf{r}\|^2$.

\proposition{$\hat{\pmb\beta}_\text{LS}$ is Unbiased}
We have that
\[\begin{array}{rcl}
\expect(\hat{\pmb\beta})&=&\expect(\textbf{R}^{-1}\textbf{Q}^T\textbf{y})\\
&=&\textbf{R}^{-1}\textbf{Q}^T\expect(\textbf{y})\\
&=&\textbf{R}^{-1}\textbf{Q}^T\textbf{X}\pmb\beta\\
&=&\textbf{R}^{-1}\textbf{Q}^T\textbf{Q}\textbf{R}\pmb\beta\\
&=&\pmb\beta
\end{array}\]
Thus $\hat{\pmb\beta}_\text{LS}$ is unbiased.\\

\proposition{Variance of $\hat{\pmb\beta}_\text{LS}$}
We have $\Sigma_\textbf{y}=I\sigma^2$.\\
Thus $\Sigma_\textbf{f}=\textbf{Q}^T\textbf{Q}\Sigma_\textbf{y}=\textbf{Q}^T\textbf{Q}I\sigma^2=I\sigma^2$.\\
Hence
$$\Sigma_{\hat\beta}=\textbf{R}^{-1}\textbf{R}^{-T}\sigma^2$$

\remark{Checking}
In order to make inferences beyond estimating $\beta$ we need to check that our assumptions about $\varepsilon_i$ still hold.\\
We can estimate these values as $\hat\varepsilon_i=y_i-\hat\mu_i$ where $\hat{\pmb\mu}=\textbf{X}\hat{\pmb\beta}$.\\
Plotting these estimates, $\hat\varepsilon_i$, against fitted values, $\hat\mu_i$, allows us to look for systematic patterns in the mean of residuals, which would indicate a violation of the independence assumption

\subsection{Gauss-Markov Theorem}

\remarkk{Alternatives to Least-Squares Estimates}
\begin{itemize}
	\item[-] We may wish to find an estimate of $\beta$ which is as close to the real value as possible, so minimising $\|\hat\beta-\beta\|^2$. However it is possible the data gives a lot of information about $\beta_i$ but little about $\beta_j$, does it make sense to weight these equally.
	\item[-] We could only allow \textit{unbiased estimators}, ie $\expect(\hat\beta)=\beta$. And then among those choose the one with least variance.
\end{itemize}

\theorem{Gauss-Markov Theorem}
Define $\pmb\mu:=\expect(\textbf{Y})=\textbf{X}\pmb\beta$ and $\Sigma_y=\sigma^2I$.\\
Let $\tilde\phi=\textbf{c}^T\textbf{Y}$ be any unbiased linear estimator of $\phi=\textbf{t}^T\pmb\beta$ where $\textbf{t}$ is an arbitrary vector. Then
$$\var(\tilde\phi)\geq\var(\hat\phi)\text{ where }\hat\phi=\textbf{t}^T\hat{\pmb\beta_\text{LS}}\ \&\ \hat{\pmb\beta}_\text{LS}=\textbf{R}^{-1}\textbf{Q}^T\textbf{Y}$$
Since $\textbf{t}$ is arbitraru, this implies that each element of $\hat{\pmb\beta}$ is a minimum variance unbiased estimator.\\

\proof{Gauss-Markov Theorem}
Since $\tilde\phi$ is a linear transformation of $\textbf{Y}$, $var(\tilde\phi)=\textbf{c}^T\textbf{c}\sigma^2$.\\
To compare the variances of $\hat\phi$ and $\tilde\phi$ it is useful to express $\var(\hat\phi)$ in terms of $\textbf{c}$.\\
Because $\tilde\phi$ is unbiased we have
\[\begin{array}{rrcl}
&\expect(\textbf{c}^T\textbf{Y})&=&\textbf{t}^T\pmb\beta\\
\implies&\textbf{c}^T\expect(\textbf{Y})&=&\textbf{t}^T\pmb\beta\\
\implies&\textbf{c}^T\textbf{X}\pmb\beta&=&\textbf{t}^T\pmb\beta\\
\implies&\textbf{c}^T\textbf{X}&=&\textbf{t}^T
\end{array}\]
So the variance of $\hat\phi$ can be written as
$$\var(\hat\phi)=\var(\textbf{t}^T\hat{\pmb\beta})=\var(\textbf{c}^T\textbf{X}\hat{\pmb\beta})=\var(\textbf{c}^T\textbf{QR}\hat{\pmb\beta})$$
This is the variance of a linear transformation of $\hat{\pmb\beta}$ and the covariance matrix of $\hat{\pmb\beta}$ is $\textbf{R}^{-1}\textbf{R}^{-T}\sigma^2$.\\
Thus
$$\var(\hat\phi)=\var(\textbf{c}^T\textbf{QR}\hat{\pmb\beta})=\textbf{c}^T\textbf{QRR}^{-1}\textbf{R}^{-T}\textbf{R}^T\textbf{Q}^T\textbf{c}^T\sigma^2=\textbf{c}^T\textbf{QQ}^T\textbf{c}\sigma^2$$
Hence
$$\var(\tilde\phi)-\var(\hat\phi)=\textbf{c}^T(I-\textbf{QQ}^T)\textbf{c}\sigma^2$$
Because the columns of $\textbf{Q}$ are orthogonal, $\textbf{QQ}^T=\textbf{QQ}^T\textbf{QQ}^T$ it follows that
$$\textbf{c}^T(I-\textbf{QQ}^T)\textbf{c}=[(I-\textbf{QQ}^T)\textbf{c}]^T(I-\textbf{Q}\textbf{Q}^T)\textbf{c}\geq0$$
since this is just the sum of squares of the elements of teh vector $(I-\textbf{QQ}^T)\textbf{c}$.\proved

\remark{Least Squares Variance}
Amongst unbiased and linear estimators in $\textbf{Y}$, least squares estimators have minimum variance.\\
It is still possible that some non-linear estimator might be even better.

\subsection{Further Inference on Linear Models}

\remark{Requirements}
In order to make further inferences about linear models (\eg confidence intervals \& hypothesis testing) we need to make our model completely probabilistic, since these inferences are probabilistic concepts.\\
This requires us to specify a full distribution for the error $\pmb\varepsilon$.\\
We assume
\[\begin{array}{rcl}
\pmb\varepsilon&\iid&\text{Normal}(0,I\sigma^2)\\
\implies\textbf{y}&\sim&\text{Normal}(\textbf{X}\beta,I\sigma^2)\\
\implies\hat{\pmb\beta}&\sim&\text{Normal}(\pmb\beta,\Sigma_{\hat\beta})\\
\text{where }\Sigma_{\hat\beta}&=&R^{-1}R^{-T}\sigma^2
\end{array}\]

\theorem{$\dfrac{\hat\beta_i-\beta_i}{\hat\sigma_{\hat\beta_i}}\sim t_{n-p}$}

\proof{Theorem 3.2}
$\pmb{\mathcal{Q}}^T\textbf{y}$ is a linear transformation of a normal random vector, so is a normal random vector with covariance matrix
$$\Sigma_{\pmb{\mathcal{Q}}^T\textbf{y}}=\pmb{\mathcal{Q}}^TI\pmb{\mathcal{Q}}\sigma^2=I\sigma^2$$
The elements of $\pmb{\mathcal{Q}}^T\textbf{y}$ are mtually independent. Further
\[\begin{array}{rcl}
\expect\left[\begin{pmatrix}\textbf{f}\\\textbf{r}\end{pmatrix}\right]&=&\expect[\pmb{\mathcal{Q}}^T\textbf{y})\\
&=&\pmb{\mathcal{Q}}^T\textbf{X}\pmb\beta\\
&=&\begin{pmatrix}\textbf{R}\\\pmb0\end{pmatrix}\pmb\beta\\
\implies\expect(\textbf{f})&=&\textbf{R}\pmb\beta\\
\text{and }\expect(\textbf{r})&=&\pmb0
\end{array}\]
Thus
$$\textbf{f}\sim\text{Normal}(\textbf{R}\pmb\beta,I_p\sigma^2)\text{ and }\textbf{r}\sim\text{Normal}(0,I_{n-p}\sigma^2)$$
Now we can deduce
\[\begin{array}{rrcl}
&r_i&\overset{\text{ind}}{\sim}&\text{Normal}(0,\sigma^2)\\
\implies&\frac{r_i}{\sigma}&\sim&\text{Normal}(0,1)\\
\implies&\displaystyle{\sum_{i=1}^{n-p}\left(\frac{r_i}{\sigma}\right)^2}&\sim&\chi^2_{n-p}
\end{array}\]
Since $\expect(\chi^2_{n-p})=n-p$ we have that $\hat\sigma^2=\frac1{n-P}\|\textbf{r}\|^2$ is an unbiased estimator.\\
Let $\sigma_{\hat\beta_i}=\sqrt{\Sigma_{\hat\beta_i}(i,i)}$ then $\hat\sigma_{\hat\beta_i}=\sqrt{\hat\Sigma_{\hat\beta_i}(i,i)}$ but $\hat\Sigma_{\hat\beta_i}=\Sigma_{\hat\beta_i}\frac{\hat\sigma^2}{\sigma^2}\implies\hat\sigma_{\hat\beta_i}\frac{\hat\sigma}{\sigma}$.\\
Consider
\[\begin{array}{rcl}
\dfrac{\hat\beta_i-\beta_i}{\hat\sigma_{\beta_i}}&=&\dfrac{\hat\beta_i-\beta_i}{\sigma_{\hat\beta_i}\hat\sigma/\sigma}\\
&=&\dfrac{(\hat\beta_i-\beta_i)/\sigma_{\hat\beta_i}}{\sqrt{\frac1{\sigma^2}\|\textbf{r}\|^2/(n-p)}}\\
&\sim&\dfrac{\text{Normal}(0,1)}{\sqrt{\chi^2_{n-p}/(n-p)}}\\
&\sim&t_{n-p}
\end{array}\]

\proposition{Confidence Intervals for $\beta_i$}
Supose we want a $(1-2\alpha)100\%$ confidence interval for $\beta_i$.\\
Then
\[\begin{array}{rcl}
\prob\left(-t_{n-p}(\alpha)<\dfrac{\hat\beta_i-\beta_i}{\hat\sigma_{\hat\beta_i}}<t_{n-p}(\alpha)\right)&=&\prob\left(\hat\beta_i-t_{n-p}(\alpha)\sigma_{\hat\beta_i}<\beta_i<\hat\beta_i+t_{n-p}(\alpha)\sigma_{\hat\beta_i}\right)\\
&=&1-2\alpha
\end{array}\]
where $\prob(t_{n-p}(\alpha)\geq t_{n-p})=1-\alpha$.\\

\subsection{Geometry of Linear Models}

\remark{Least Squares Estimation as Geometry}
\textit{Least Squares Estimation} of linear models is the same as finding the orthogonal projection of the response vector $\textbf{y}\in\reals^n$ onto the $p$-dimensional linear subspace spanned by the columns of $\X\in\reals^{n\times p}$.\\
By the linear model $\expect(\textbf{y})$ lies in the space spanned by all possible linear combinations of the columns of $\X$ \& least squares find the point in that space that is cloests to $\textbf{y}$ in \textit{Euclidean Distance}.\\

\remark{Projection Matrix}
Consider the \textit{Projection Matrix} that maps the response data $\textbf{y}$ to the fitted values $\hat{\pmb\mu}$.\\
We have that
$$\hat{\pmb\mu}=\X\hat{\pmb\beta}=\textbf{QRR}^{-1}\textbf{Q}^T\textbf{y}=\textbf{QQ}^T\textbf{y}$$
Thus the projection matrix is $\textbf{A}=\textbf{QQ}^T$.\\
\nb Often $\textbf{A}$ is referred to as the \textit{Influence Matrix} or \textit{Hat Matrix}.\\

\proposition{Projection Matrix Idempotent}
Let \textbf{A} be the \textit{Projection Matrix} of a \textit{Linear Model}.\\
$\textbf{A}$ is said to be \textit{Idempotent} since $\textbf{A}=\textbf{AA}$.\\
This is since the orthogonal projection of $\hat{\pmb\mu}$ onto the column space of $\X$ must be $\hat{\pmb\mu}$.\\

\subsection{Results in terms of Model Matrix, $\X$}

\propositionn{Results in terms of Model Matrix, $\X$}
\[\begin{array}{rclcrclcrcl}
\Sigma_{\hat\beta}&=&(\X^T\X)^{-1}\sigma^2&\quad&\hat{\pmb\beta}&=&(\X^T\X)^{-1}\X^T\textbf{y}&\quad&\textbf{A}&=&\X(\X^T\X)^{-1}\X^T\\
&=&(\textbf{R}^T\textbf{Q}^T\textbf{QR})^{-1}\sigma^2&&&=&\textbf{R}^{-1}\textbf{R}^{-T}\textbf{R}^T\textbf{Q}^T\textbf{y}\\
&=&(\textbf{R}^T\textbf{R}^{-1}\sigma^2&&&=&\textbf{R}^{-1}\textbf{Q}^T\textbf{y}\\
&=&\textbf{R}^{-1}\textbf{R}^{-T}\sigma^2&&&=&\textbf{R}^{-1}\textbf{f}\\
\end{array}\]

\subsection{Bayesian Analysis}

\remark{Bayesian Analysis of Linear Models}
To perfor a full \textit{Bayesian Analysis} of a \textit{Linear Model} we need to define prior distributions for $\pmb\beta$ and $\sigma^2$. Typically
In order to make this problem analytically tractable we use conjugate priors. Conjugacy can be used for defining
$$\pmb\beta\sim\text{Normal}(\pmb\beta_0,\pmb\psi^{-1})\quad\text{and}\quad\tau\sim\Gamma(a,b)$$
where $tau:=\frac1{\sigma^2}$ is precision measure.\\
Here $a,b,\pmb\beta_0\text{ and }\pmb\psi$ are quantities which we need to define values for, for practical analysis.\\
This gives us the following distributions
\[\begin{array}{rcl}
f(\textbf{y},\pmb\beta,\tau)&\propto&{\displaystyle\tau^{n/2}e^{-\frac{\tau}{2}\|\textbf{y}-\X\pmb\beta\|^2}e^{-\frac12(\pmb\beta-\pmb\beta_0)^T\pmb\psi(\pmb\beta-\pmb\beta_0)}e^{-b\tau}\tau^{a-1}}\\
f(\tau|\pmb\beta,\textbf{y})&\propto&{\displaystyle\tau^{\frac{n}2+a-1}e^{-\tau(b+\frac12\|\textbf{y}-\X\pmb\beta\|^2)}}\\
&\sim&{\displaystyle\Gamma(\frac{n}2+a,b+\frac12\|\textbf{y}-\X\pmb\beta\|^2)}\\
f(\pmb\beta|\tau,\textbf{y})&\propto&e^{-\frac12(\pmb\beta^T\X^T\X\pmb\beta\tau-2\beta\X^T\textbf{y}\tau+\pmb\beta^T\pmb\psi\pmb\beta-2\pmb\beta^T\pmb\psi\pmb\beta_0)}\\
&\propto&e^{-\frac12[\pmb\beta-(\X^T\X\tau+\pmb\psi)^{-1}(\tau\X^T\textbf{y}+\pmb\psi\pmb\beta_0)]^T(\X^T\X\tau+\pmb\psi)\pmb\beta-(\X^T\X\tau+\pmb\psi)^{-1}(\tau\X^T\textbf{y}+\pmb\psi\pmb\beta_0)]}\\
&\sim&\text{Normal}[(\X^T\X\tau+\pmb\psi)^{-1}(\tau\X^T\textbf{y}+\pmb\psi\pmb\beta+0),(\X^T\X\tau+\pmb\psi)^{-1}]
\end{array}\]
If either the sample size tends to infinity (\ie $n\to\infty$) or the prior precision matrix tends to the zero matrix then
$$f(\pmb\beta|\tau,\textbf{y})\overset\to\sim\text{Normal}(\hat{\pmb\beta},(\X^T\X)^{-1}\sigma^2)$$
\nb We have not produced the joint distribution $\pmb\beta,\tau|\textbf{y}$ but just two conditionals.\\

\remark{Proceeding from Conditionals}
There are a few options to proceed from the results in \textbf{Remark 3.8}
\begin{enumerate}
	\item Iteratively find the posteior modes of $\pmb\beta$ given teh estiamte mode of $\tau$ and the posterior mode of $\tau$ given the estimated modes of $\pmb\beta$ until the mode of $\tau$ connverges.\\
	Then plug this into the conditional density of $\pmb\beta$.
	\item Integrate $\pmb\beta$ out of $f(\tau|\pmb\beta,\textbf{y})$ to obtain the marginal likelihood $f(\tau|\textbf{y})$ which can be maximised to find $\hat\tau$.\\
	$\hat\tau$ can be plugged into $f(\pmb\beta|\tau,\textbf{y})$.
	\nb Also known as \textit{Empirical Bayes}.
	\item Alternate simulate of $\pmb\beta$ from $f(\pmb\beta|\tau,\textbf{y})$ given $tau$ with simulation from $f(\tau|\pmb\beta,\textbf{y})$, given the last simulated $\pmb\beta$, to generate joint draws of $\tau\ \&\ \pmb\beta$ from $f(\pmb\beta,\tau|\textbf{y})$.\\
	\nb Also known as \textit{Gibbs Sampling}.
\end{enumerate}

\section{Causality, Confounding \& Randomisation}

\definition{Causality}
\textit{Causality} is a problem in statistical inference where we wish to find out which variables affect a particular variable, and are mearly correlated. This is more difficult that other forms of inference, but is useful in many real world scenarios especially in science \& economics.\\

\example{Causation \& Correlation}
There is an observed correlation between birth rates in Europe \& stork populations. There is no causation between the two, however it is likely that increased industrialisation led to the decrease in both since it lead to more healthcare for humans \& less habitats for storks.\\

\subsection{Controlled Experiments and Randomisation}

\definition{Hidden Variables}
\textit{Hidden Variables} are variables which likely effect a system but which we can/do not observed.\\

\definition{Randomisation}
\textit{Randomisation} is the process of splitting subjects into different groups. Typically a control \& an active group. This is meant to break correlation between observed \& hidden variables.\\

\remark{Hidden Variables}
Consider the scenario where we wish to test whether exercise influences fat mass. It is likely that ther are lots of other factors. These factors will correlate with both exercise \& fat mass. By splitting subjects into a control \& exercise groups at random we break the correlation of these other features but not that between fat mass \& exercise. The other factors are now random error.\\

\proposition{Formalisation of Hidden Variables}
Consider the true model matrix $(X,H)$ where $X$ is the observed variables \& $H$ is the hidden variables. We assume that the columns of $H$ have mean 0.\\
We have
$$\tilde\beta_X=(X^TX)^{-1}X^T\textbf{y}\text{ for assumed model }y=X\beta_X+\varepsilon$$
If we knew $H$ then we would have
$$\begin{pmatrix}\hat\beta_X\\\hat\beta_H\end{pmatrix}=\begin{pmatrix}X^X&X^TH\\H^TX&H^TH\end{pmatrix}^{-1}\begin{pmatrix}X^T\\H^T\end{pmatrix}\textbf{y}\text{ for true model }\textbf{y}=X\beta_X+H\beta_H+\varepsilon$$
Since $X^TH\neq0\implies\tilde\beta_X\neq\hat\beta_X$.\\
The randomised allocation to groups is used to try and make $X^TH=0$.\\

\remark{Randomised Tests}
Sometimes it is frowned upon (ethically) to perform random tests. Such as testing if high levels of alcohol consumtion is correlated with heart disease.\\
\nb There is a reason China is becoming such an advanced country.

\subsection{Instrumental Variables}

\definition{Instrumental Variable}
An \textit{Instrumental Variable}, $Z$, is used in regression analysis when there are \textit{hidden variables} in the model. \textit{Instrumental Variables} are correlated with the \textit{Explanatory Variables}, $X$ but uncorrelated with the error term $\textbf{e}$ in the model $\textbf{y}=X\beta+\textbf{e}$.\\

\proposition{Without Instrumental Variables}
Consider the true model $\textbf{y}=X\beta_X+H\beta_H+\pmb\varepsilon$ with $H$ being the hidden variables with columns centred at 0.\\
Suppose we wish to fit the model $\textbf{y}=X\beta_X+\textbf{e}$.\\
In this case $\textbf{e}=H\beta_H+\varepsilon$ and likely does not fulfil the criteria of linear model random error.\\
We have
\[\begin{array}{rcl}
\expect(\hat\beta_X)&=&(X^TX)^{-1}X^T\begin{pmatrix}X&H\end{pmatrix}\begin{pmatrix}\beta_X\\\beta_H\end{pmatrix}\\
&=&\beta_X+(X^TX)^{-1}X^TH\beta_H\\
&\neq&\beta_x\text{ since }X\perp\textbf{e}\text{ and thus }X^TH\neq0
\end{array}\].\\

\proposition{With Instrumental Variables}
Let $Z$ be an instrumental variable (\ie it is correlated with $X$ but not with $H$).\\
Assume that $\text{rank}(Z)\geq\text{rank}(X)$ and $Z$'s columns are centred around 0.\\
Project $X$ onto column space of $Z$
$$X\mapsto A_ZY\text{ where }\underbrace{A_Z=Z(Z^TZ)^{-1}Z^T}_\text{Projection Matrix}$$
Now use $A_ZX$ as the model matrix
\[\begin{array}{rcl}
\hat\beta_X&=&(X^TA_ZX)^{-1}X^TA_z\textbf{y}\\
\expect(\textbf{y})&=&\begin{pmatrix}X&H\end{pmatrix}\begin{pmatrix}\beta_X\\\beta_H\end{pmatrix}\\
\expect(\hat\beta_X)&=&(X^TA_ZX)^{-1}X^TA_ZX\beta_X+(X^TA_ZX)^{-1}X^T\underbrace{A_ZH}_{\approx0}\beta_H\\
&=&\beta_X+0\\
&=&\beta
\end{array}\]
Thus this $\hat\beta_X$ is unbiased.\\
\nb $A_ZH\approx0$ since $Z$ and $H$ are uncorrelated.

\section{Maximum Likelihood Estimation}

\definition{Maximum Likelihood Estimation}
A \textit{Maximum Likelihood Estimate} is the estimated value of a parameter which maximises some likelihood function, wrt observed data.
$$\hat{\pmb\theta}_\text{MLE}=\text{argmax}_\theta\ell(\pmb\theta)\text{ where }\ell(\cdot):=\ln f(\textbf{y}|\pmb\theta)$$

\remark{MLEs are only unbiased for large sample sizes}

\proposition{MLE - Frequentist Approach}
In the \textit{Frequentist Approach} parameters are fixed states of natire and teh uncertainty comes from our estimates of these parameters.\\
We define the \textit{Likelihood Function} to be the probability of observing certain values given the parameters have certain values
$$L(\pmb\theta)=f(\textbf{y}|\pmb\theta)\text{ where }\textbf{y}\text{ is fixed}$$
Note that the natural log of the likelihood function is increasing wrt it so they have the same maximum.\\
Thus we define the \textit{Maximum Likelihood Estimate} to be the set of parameters which maximise the \textit{Log-Likelihood Function}
$$\hat{\pmb\theta}_\text{MLE}=\text{argmax}_\theta\ell(\pmb\theta)\text{ where }\ell(\cdot):=\ln f(\textbf{y}|\pmb\theta)$$

\remark{Effectiveness of MLE}
We have that
$$\hat{\pmb\theta}_\text{MLE}\underset{n\to\infty}{\sim}\text{Normal}(\pmb\theta,\pmb{\mathcal{I}}^{-1})\text{ where }\pmb{\mathcal{I}}^{-1}:=-\expect\left(\frac{\partial^2\ell}{\partial\pmb\theta\partial\pmb\theta^T}\right)$$
This is the best that can be achieved for an unbiased estimator.

\definition{Nested Models}
Two models are said to be \textit{Nested Models} if one can be expressed as the other model subject to some restrictions, $\textbf{R}$, on its parameters, $\pmb\theta$, which are written as $R(\pmb\theta)=\pmb0$.\\

\proposition{}
Consider wishing to compare two nested models.\\
Let $\hat{\pmb\theta}_0$ denote the MLE of $\pmb\theta$ under the restrictions of the nested model.\\
We want to test $H_0:\textbf{R}(\pmb\theta)=\textbf{0}$.\\
If this null hypothesis is true then
$$2[\ell(\hat{\pmb\theta})-\ell(\hat{\pmb\theta}_0]\sim\chi^2_r\text{ where }r=|\text{restrictions}|$$

\example{Poisson Maximum Likelihood Estimate}
Consider the following model with a single parameter $\beta$
$$y_i\sim\text{Poisson}(e^{\beta x_i})$$
Let $\{(x_1,y_1),\dots,(x_n,y_n)\}$.\\
For our model we have $f(y_i)=\dfrac{(e^{\beta x_i})^{y_i}e^{-e^{\beta x_i}}}{y_i!}$.\\
Thus
\[\begin{array}{rcl}
L(\beta)&=&\displaystyle{\prod_{i=1}^n\dfrac{(e^{\beta x_i})^{y_i}e^{-e^{\beta x_i}}}{y_i!}}\\
\implies\ell(\beta)&=&\sum_{i=1}^ny_i\beta x_i-e^{\beta x_i}-\ln y_i!
\end{array}\]
By taking the derivative of $\ell(\cdot)$ and finding the stationary points we identify $\hat\beta_\text{MLE}=2.41$.

\subsection{Numerical Optimisation}

\remark{MLE in Practice}
It is often not possile to find an explicit expression for a maximum likelihood estimate. In these cases we maximise the log-likelihood numerically.\\
There are several methods for doing this. Newton's Method is deemed the best.\\

\remark{Numerical Optimisation in R}
In R \textit{numerical optimisation} concentrates on finding parameters which minimise a function, not those which maximise them.\\
Finding the parameters which maximise is equivalnt to finding those which minimise the negative of the function.
$$\hat\theta=\text{argmax}_\theta f(\theta)=\text{argmin}_\theta -f(\theta)$$

\remark{Assumptions}
As there are so very hard problems around numerical optimisation, we make the following assumptions
\begin{enumerate}
	\item The \textit{Objective Function}, $f$, is sufficiently smooth and bounded below.
	\item The elements of the parameter vector $\pmb\theta$ are unrestricted real values.\\
	If we want to restrict $\pmb\theta$ it needs to be implemented as $\pmb\theta=\textbf{r}(\pmb\theta_r)$ where $\pmb\theta_r$ is unrestricted.
\end{enumerate}
\nb Given these assumptions we are still not guaranteed to find a solution unless we know that $f$ is convex, which is generally an assumption too far.

\definitionn{Newton's Method for Numerically Maximisation}
\begin{enumerate}
	\item Make an initial parameter value guess.
	\item Obtain a quadratic approximation to the \textit{Log-Likelihood Function} which behaves similarlly to the log-likelihood function in the region of this guess.\\
	\nb This is done by using a \textit{Taylor Approximation} of the \textit{Log-Likelihood Function}.
	$$f(\pmb\theta+\pmb\Delta)=f(\pmb\theta)+\nabla f(\pmb\theta)^T\pmb\Delta+\frac12\pmb\Delta^T\nabla^2f(\pmb\theta+t\pmb\Delta)\pmb\Delta$$
	Solve for $\pmb\Delta$ which maximises.
	\item Update parameter guesss to be maximiser of this quadratic approxiation.
	\item Repeat \textit{ii)-iii)} with new guesses, until convergence.
\end{enumerate}

\propositionn{Newton's Method Algorithm}
\begin{enumerate}
	\item Set $k=0$ and $\pmb\theta^{[0]}$ to be an initial guess.
	\item Evaluate $f(\pmb\theta^{[k]}),\nabla f(\pmb\theta^{[k]})$ and $\nabla^2 f(\pmb\theta^{[k]})$.
	\item Test whether $\pmb\theta^{[k]}$ is a minimum by confirmed $\nabla f(\pmb\theta^{[k]})=\textbf{0}$ and terminate if it is.\\
11	\nb Typically we just check that $\nabla f(\pmb\theta^{[k]})$ is sufficiently close to $\textbf{0}$.
	\item If $\textbf{H}:=\nabla^2 f(\pmb\theta^{[k]})$ is not positive definite, perturb it so that it is.
	\item If $\textbf{H}\pmb\Delta=-\nabla f(\pmb\theta^{[k]})$ for the search direction $\pmb\Delta$.
	\item If $f(\pmb\theta^{[k]}+\pmb\Delta)$ is not $<f(\pmb\theta^{[k]})$, repeatdely halve $\pmb\Delta$ until it is.
	\item Set $\pmb\theta^{[k+1]}=\pmb\theta^{[k]}+\pmb\Delta$ increment $k$ by one and return to step \textit{ii)}.
\end{enumerate}

\remark{Ensure Newton's Method converges to the MLE}
We need to ensure that the approximating quadratic actually has a maximum (rather than a minimum or saddle point).\\
In one dimension this is done by confirming the second deriative is negative, in multiple dimensions we confirm that the second derivative matrix is positive definite.\\
\textbf{And}, we need to check that the proposed change in parameter values actually increases the log-likelihood function. If it doesn't then we move the parameter back towards the previous parameter guess until the log-likelihood is increased at the new values.\\

\proposition{Netwon's Method with evaluating $f$}
Sometimes $f$ is not available (or is difficult to compute in a stable fassion).\\
Newton's Method only requires evaluation of $f$ in order to chek that the Newton Step has led to a reduction in $f$.\\
We can replace the condition that $f(\pmb\theta+\pmb\Delta)\leq f(\pmb\theta)$ with the condition that $f$ is non-increasing in the direction $\pmb\Delta$ at $\pmb\theta'+\pmb\Delta$. (\ie $\nabla f(\pmb\theta'+\pmb\Delta)^T\pmb\Delta\leq0$).\\
By controlling step length here we can often ensure convergence in cases where the iteration would otherwise diverge.\\

\proposition{Variation on Newton's Method}
We can replace $-\nabla^2 \ell(\pmb\theta)$ by $-\expect[\nabla^2\ell(\pmb\theta)]$ (AKA \textit{Fisher Scoring}). This replacement is always positive (semi-)definite, perturbation to positive definitness is not requirement and by the arguments surrounding ($\Delta=-\textbf{H}\nabla f(\pmb\theta)$), the method converges when used with simple step-length control.\\

\definition{Quasi-Newton Methods}
\textit{Quasi-Newton Methods} are Newton-Type methods in which an approximation to the Hessian Matrix, or its inverse, is built up iteratively from the first derivative information computed at each trial set of parameter values.\\
This does not require the computation of the second derivation.\\
\nb Available from $\mathtt{optim(\dots,method=``BFGS")}$ in R

\subsection{MLE Theory}

\proposition{Properties of Expected Log Likelihood}
Large sample theory for maximum likelihood estimators relies on some results for the expected value as teh sample size tends to infinity.
\begin{enumerate}
	\item $\expect\left(\dfrac{\partial\ell}{\partial\pmb\theta}\bigg|_{\theta_t}\right)=\textbf{0}$.\\
	\textit{Proof}
	$$\expect\left(\frac\partial{\partial\pmb\theta}\ln f(\textbf{y};\pmb\theta)\right)=\int\frac{1}{f(\textbf{y};\theta)}\dfrac{\partial f(\textbf{y};\theta)}{\partial\pmb\theta}d\textbf{y}=\int\dfrac{\partial f}{\partial\pmb\theta}d\textbf{y}=\dfrac{\partial}{\partial\pmb\theta}\int f(\textbf{y};\pmb\theta)d\textbf{y}=\dfrac{\partial\pmb1}{\partial\pmb\theta}=\pmb0$$
	\item $\text{Cov}\left(\dfrac{\partial\ell}{\partial\pmb\theta}\bigg|_{\theta_t}\right)=\expect\left(\dfrac{\partial\ell}{\partial\pmb\theta}\bigg|_{\theta_t}\dfrac{\partial\ell}{\partial\pmb\theta^T}\bigg|_{\theta_t}\right)$\\
	\textit{Proof} follows directly from $i)$ and the definition of a covariance matrix.\\
	\nb Here $\frac{\partial l}{\partial\pmb\theta}$ is a column vector and $\frac{\partial l}{\partial\pmb\theta^T}$ is a row vector.
	\item $\pmb{\mathcal{I}}=\expect\left(\dfrac{\partial\ell}{\partial\pmb\theta}\bigg|_{\theta_t}\dfrac{\partial\ell}{\partial\pmb\theta^T}\bigg|_{\theta_t}\right)=-\expect\left(\dfrac{\partial^2\ell}{\partial\pmb\theta\partial\pmb\theta^T}\bigg|_{\theta_t}\right)$. This is the \textit{Fisher Information Matrix}.\\
	\textit{Proof}\\
	\[\begin{array}{rrcl}
	&\displaystyle\int\frac{\partial\log f_\theta}{d\pmb\theta}f_\theta(\textbf{y})d\textbf{y}&=&\textbf{0}\\
	\implies&\displaystyle\int\frac{\partial^2\log f_\theta}{\partial\pmb\theta\partial\pmb\theta^T}f_\theta(\textbf{y})+\frac{\partial\log f_\theta}{\partial\pmb\theta}\frac{\partial f_\theta}{\partial\pmb\theta^T}d\textbf{y}&=&\pmb0\\
	\text{but}&\dfrac{\partial\log f_\theta}{\partial\pmb\theta^T}&=&\frac1{f_\theta}\frac{\partial f_\theta}{\partial\pmb\theta^T}\\
	\implies&\displaystyle\int\dfrac{\partial^2\log f_\theta}{\partial\pmb\theta\partial\pmb\theta^T}f_\theta(\textbf{y})d\textbf{y}&=&-\displaystyle\int\dfrac{\partial\log f_\theta}{\partial\pmb\theta}\dfrac{\partial\log f_\theta}{\partial\pmb\theta^T}f_\theta(\textbf{y})d\textbf{y}
	\end{array}\]
	\item The expected log-likelihood has a global maximum at $\pmb\theta_t$. $$\expect(\ell(\pmb\theta_t))\geq\expect(\ell(\pmb\theta))\ \forall\ \pmb\theta$$
	\textit{Proof}\\
	Since $\log$ is a concanve function we can use \textit{Jensen's Inequality} to show that
	\[\begin{array}{rcl}
	\expect\left(\log\left(\dfrac{f_\theta(\textbf{y})}{f_{\theta_t}(\textbf{y})}\right)\right)&\leq&\log\left(\expect\left(\dfrac{f_\theta(\textbf{y})}{f_{\theta_t}(\textbf{y})}\right)\right)\\
	&=&\log\displaystyle\int\dfrac{f_\theta(\textbf{y})}{f_{\theta_t}(\textbf{y})}f_{\theta_t}(\textbf{y})d\textbf{y}\\
	&=&\log\displaystyle\int f_\theta(\textbf{y})d\textbf{y}\\
	&=&\log1\\
	&=&0
	\end{array}\]
\end{enumerate}

\subsection{Cramer-Rao Lower Bound}

\theorem{Cramer-Rao Lower Bound}
$\pmb{\mathcal{I}}^{-1}$ is a lower bound on the variance matrix of any unbiased estimator $\tilde{\pmb\theta}$ in the sense that $\cov(\tilde{\pmb\theta})-\pmb{\mathcal{I}}^{-1}$ is positive semi-definite.\\

\proof{Cramer-Rao Lower Bound}
Note that $f\frac{\partial(\log f)}{\partial\theta}=\frac{\partial f}{\partial\theta}$, $\frac{\partial\pmb\theta_t}{\partial\pmb\theta_t^T}=\textbf{I}$ and $\tilde{\pmb\theta}$ is unbiased.\\
Thus
\[\begin{array}{rrcl}
&\displaystyle\int\tilde{\pmb\theta}f_{\theta_t}(\textbf{y})d\textbf{y}&=&\pmb\theta_t\\
\implies&\displaystyle\int\tilde{\pmb\theta}\dfrac{\partial\log f_{\theta_t}}{\partial\pmb\theta_t^T}\bigg|_{\theta_t}f_{\theta_t}(\textbf{y})d\textbf{y}&=&\textbf{I}
\end{array}\]
Hence, by \textbf{Proposition 5.6} $i)$, the matrix of covariances of elements of $\tilde{\pmb\theta}_t$ with elements of $\frac{\partial\log f_{\theta_t}}{\partial\pmb\theta_t}$ can be obtained 
$$\cov\left(\tilde{\pmb\theta},\frac{\partial\log f_{\theta_t}}{\partial\pmb\theta_t}\bigg|_{\theta_t}\right)=\expect\left(\tilde{\pmb\theta}\dfrac{\partial\log f_{\theta_t}}{\partial\pmb\theta_t^T}\bigg|_{\theta_t}\right)-\expect(\tilde{\pmb\theta})\expect\left(\dfrac{\partial\log f_{\theta_t}}{\partial\pmb\theta_t^T}\bigg|_{\theta_t}\right)=\textbf{I}$$
Combining this with \textbf{Proposition 5.6} $ii)$ we obtain the variance-covariance matrix
$$\cov\begin{pmatrix}\tilde{\pmb\theta}\\\dfrac{\partial\log f_{\theta_t}}{\partial\pmb\theta_t}\bigg|_{\theta_t}\end{pmatrix}=\begin{pmatrix}\cov(\tilde{\pmb\theta})&\textbf{I}\\\textbf{I}&\pmb{\mathcal{I}}\end{pmatrix}$$
This matrix is positive semi-definite by virtue of being a variance-covariance matrix.\\
If follows that
$$\begin{pmatrix}\textbf{I}&-\pmb{\mathcal{I}}^{-1}\end{pmatrix}\begin{pmatrix}\cov(\tilde{\pmb\theta})&\textbf{I}\\\textbf{I}&\pmb{\mathcal{I}}\end{pmatrix}\begin{pmatrix}\textbf{I}\\-\pmb{\mathcal{I}}^{-1}=\cov(\tilde{\pmb\theta})-\pmb{\mathcal{I}}^{-1}\end{pmatrix}$$
is positive semi-definite, and the result is problem.\\

\remark{As a lower bound}
The sense in which $\pmb{\mathcal{I}}^{-1}$ can be unclear.\\
Consider the variance of any linear transformaton of the form $\textbf{a}^T\tilde{\pmb\theta}$.\\
By the result proven in \textbf{Proof 5.1} and the definition of positive semi-definiteness
\[\begin{array}{rrcl}
&0&\leq&\textbf{a}^T[\cov(\tilde{\pmb\theta}-\pmb{\mathcal{I}}^{-1}]\textbf{a}\\
&&=&\var(\textbf{a}^T\tilde{\pmb\theta})-\textbf{a}^T\pmb{\mathcal{I}}^{-1}\textbf{a}\\
\implies&\var(\textbf{a}^T\tilde{\pmb\theta})&\geq&\textbf{a}^T\pmb{\mathcal{I}}^{-1}\textbf{a}
\end{array}\]

\remark{Consistency of MLE}
\textit{Maximum Likelihood Estimators} are usually consistent (\ie as the sample size tends to infty $\hat{\pmb\theta}$ tends to $\pmb\theta_t$) provided that the likelihood is informative about the parameters.\\
This occurs as, in regualar situations, $\frac1n\ell(\pmb\theta)\to\frac1n\expect(\ell(\pmb\theta))$.\\

\proposition{Large Sample Distribution of MLE}
Taylor's Theorem states that
$$\frac{\partial\ell}{\partial\pmb\theta}\bigg|_{\hat\theta}\simeq\frac{\partial\ell}{\partial\pmb\theta}\bigg|_{\theta_t}+\dfrac{\partial^2\ell}{\partial\pmb\theta\partial{\pmb\theta}^T}\bigg|_{\theta_t}(\hat{\pmb\theta}-\pmb\theta_t)$$
Assuming $\frac1n\pmb{\mathcal{I}}$ is constant (in the $n\to\infty$ limit) then
$$\frac1n\frac{\partial^2\ell}{\partial\pmb\theta\partial\pmb{\theta}^T}\bigg|_{\theta_t}\overset{n\to\infty}{\longrightarrow}-\frac{\pmb{\mathcal{I}}}{n}$$
while $\frac{\partial\ell}{\partial\pmb\theta}\big|_{\theta_t}$ is a random vector with mean $\pmb0$ and covariance matrix $\pmb{\mathcal{I}}$ by \textbf{Proposition 5.6} $i)$ \& $ii)$.\\
Therefore in the large sample limit
$$\hat{\pmb\theta}-\pmb\theta_t\sim\pmb{\mathcal{I}}^{-1}\frac{\partial\ell}{\partial\pmb\theta}\bigg|_{\theta_t}$$
Meaning $\expect(\hat{\pmb\theta}-\pmb\theta_t)=0$ and $\var(\hat{\pmb\theta}-\pmb\theta_t)=\pmb{\mathcal{I}}^{-1}$.\\
Hence in regular situations in the large sample limit, ML estimators are unbiased and achieve the \textit{Cramer-Rao Lower Bound}.

\subsection{Hypothesis Testing}

\proposition{$p$-Value}
Suppose we observe data $\textbf{y}$ and wish to test if some parameters $\pmb\theta_0$ are likely to have produced these results.\\
The $p$-value is the probability of observing data at least as extreme as $\textbf{y}$ under $\pmb\theta_0$.\\
\nb In this scenario the null hypothesis is a simple hypothesis while the alternative is a composite hypothesis. There are cases where we wish to compare two composite hypotheses.\\

\remark{Problem with $p$-Value}
Consider the scenario in \textbf{Proposition 5.8} and an alternative hypothesis $H_1:`\pmb\theta\text{ unrestricted}'$.\\
Here a $p$-value for $H_0$ is no good asit does not make a distinciton between $\textbf{y}$ be improbable under $H_0$ but probable under $H_1$, and $\textbf{y}$ being improbable under both.\\

\propositionn{Solutions to \textbf{Remark 5.9}}
Standarise the PMF under the null hypothesis to be the highest value that could have been given for $\textbf{y}$ (under any set of parameters).\\
\ie Judge the \textit{Relative Plausibility} of $\textbf{y}$ under $H_0$ on the basis of $\frac{f_{\theta_0}(\textbf{y})}{f_{\hat\theta}(\textbf{y})}$ where $\hat\theta$ is the set of parameters which maximises $f_\theta(\textbf{y})$ for the given $\textbf{y}$.\\
\nb The reciprocal of this is known as the \textit{Likelihood Ratio}.\\

\definition{Likelihood Ratio}
The \textit{Likelihood Ratio} measures how likely the alternative hypothesis is relative to the null, given the data.
$$LR:=\frac{f(\textbf{y};\hat\theta_1)}{f(\textbf{y};\theta_0)}$$
This is a \textit{test statistic} from which we can calculate $p$-values.\\
\nb The \textit{Likelihood Ratio Test Statistic} returns high values when alternative hypothesis is more likely, and lower when null hypothesis is more likely.

\proposition{Test Variants}
There are a number of variations on hypothesis tests: two composite hypotheses; two simple hypotheses; one simple \& one composite.\\
These can all be dealt with using the \textit{Likelihood Ratio Test Statistic}.\\

\theorem{Neyman-Pearson Lemma}
Likelihood ratio is the most powerful test possible.\\
%TODO proof

\subsection{Distribution of Generalise Likelihood Ratio Test}

\proof{$2[\ell(\hat\theta)-\ell-\ell(\hat\theta_0)]\sim\chi^2_r$}
Consider testing
$$H_0:\textbf{R}(\pmb\theta)=\pmb0\text{ against }H_1:\textbf{R}(\pmb\theta)\neq\pmb0$$
where $\textbf{R}$ is a vector-valued function of $\pmb\theta$ such that $H_0$ imposes $r$ restrictions on the parameter vector.\\
If $H_0$ is true then as $n\to\infty$
$$2\lambda:=2[\ell(\hat{\pmb\theta}_\text{MLE})-\ell(\hat{\pmb\theta}_0]\sim\chi^2_r$$
where $\ell$ is the log-likelihood function and $\hat{\pmb\theta}_0$ is the value of $\pmb\theta$ which maximises the likelihood subject to the constraint that $\textbf{R}(\pmb\theta)=\pmb0$.\\
Re-parameterise st $\pmb\theta^T=(\pmb\phi^T,\pmb\gamma^T)$ where $\pmb\phi$ is $r$ dimensional and the null-hypothesis can be rewritter $H_0:\pmb\phi=\pmb\phi_0$.\\
Let the unrestricted MLE be $(\hat{\pmb\phi}^T,\hat{\pmb\gamma}^T)$ and let $(\hat{\pmb\phi}_0^T,\hat{\pmb\gamma}_0^T)$ be the MLE under the restrictions which define the null hypothesis.\\
We wish to express $\hat{\pmb\gamma}_0$ in terms of $\hat{\pmb\phi},\hat{\pmb\gamma}$ and $\pmb\phi_0$.\\
We take a taylor expansion of $\ell$ around the unrestricted MLE, $\hat{\pmb\theta}$
$$\ell(\pmb\theta)\simeq\ell(\hat{\pmb\theta})-\frac12(\pmb\theta-\hat{\pmb\theta})^T\textbf{H}(\pmb\theta-\hat{\pmb\theta})\text{ where }H_{ij}=-\frac{\partial^2\ell}{\partial\theta_i\partial\theta_j}\bigg|_{\hat{\pmb\theta}}$$
Taking the exponent we find
$$L(\pmb\theta)\simeq L(\hat{\pmb\theta})\text{exp}\left\{-\frac12(\pmb\theta-\hat{\pmb\theta})^T\textbf{H}(\pmb\theta-\hat{\pmb\theta}\right\}$$
For a large sample limit and defining $\pmb\Sigma=\textbf{H}^{-1}$ the likelihood is proportional to the pdf of
$$\text{Normal}\left(\begin{pmatrix}\hat{\pmb\psi}\\\hat{\pmb\gamma}\end{pmatrix},\begin{pmatrix}\pmb\Sigma_{\phi\phi}&\pmb\Sigma_{\phi\gamma}\\\pmb\Sigma_{\gamma\phi}&\pmb\Sigma_{\gamma\gamma}\end{pmatrix}\right)$$
If $\pmb\phi=\pmb\phi_0$ then this pdf is maximised by $\hat{\pmb\gamma}_0:=\expect(\pmb\gamma|\pmb\phi_0)$ which is
$$\hat{\pmb\gamma}_0:=\hat{\pmb\gamma}+\pmb\Sigma_{\gamma\phi}\pmb\Sigma_{\phi\phi}^{-1}(\pmb\phi_0-\hat{\pmb\phi})\text{ by general properties of MVN densities}$$
If the null hypothesis is true then in the large sample limit $\hat{\pmb\phi}\to_\prob\pmb\phi_0$ so that the approximate likelihood tends to the true likelihood and we can expected this definition of $\hat{\pmb\gamma}_0$ to hold for maximisers of the true likelihood.\\
We can express $\hat{\pmb\gamma}_0$ in terms of $\textbf{H}$.\\
Writing $\pmb\Sigma\textbf{H}=\textbf{I}$ in partioned form gives
$$\begin{pmatrix}\Sigma_{\phi\phi}&\Sigma_{\phi\gamma}\\\Sigma_{\gamma\phi}&\Sigma_{\gamma\gamma}\end{pmatrix}\begin{pmatrix}\textbf{H}_{\phi\phi}&\textbf{H}_{\phi\gamma}\\\textbf{H}_{\gamma\phi}&\textbf{H}_{\gamma\gamma}\end{pmatrix}=\begin{pmatrix}\textbf{I}&\pmb0\\\pmb0&\textbf{I}\end{pmatrix}$$
Multiplying out gives two useful equations
$$\pmb\Sigma_{\phi\phi}\textbf{H}_{\phi\phi}+\pmb\Sigma_{\phi\gamma}\textbf{H}_{\gamma\phi}=\textbf{I}\text{ and }\pmb\Sigma_{\phi\phi}\textbf{H}_{\phi\gamma}+\pmb\Sigma_{\phi\gamma}\textbf{H}_{\gamma\gamma}=\textbf{0}$$
Note that $\textbf{H}_{\phi\gamma}^T=\textbf{H}_{\gamma\phi}$ and $\pmb\Sigma_{\phi\gamma}^T=\pmb\Sigma_{\gamma\phi}$ by symmetry.\\
Rearranging the two previous equations gives that
$$\pmb\Sigma_{\phi\phi}^{-1}=\textbf{H}_{\phi\phi}-\textbf{H}_{\phi\gamma}\textbf{H}^{-1}_{\gamma\gamma}\textbf{H}_{\gamma\phi}\text{ and }-\textbf{H}_{\gamma\gamma}^{-1}\textbf{H}_{\gamma\phi}=\pmb\Sigma_{\gamma\phi}\pmb\Sigma_{\phi\phi}^{-1}$$.\\
Substituting back we get
$$\hat{\pmb\gamma}_0=\hat{\pmb\gamma}+\textbf{H}_{\gamma\gamma}^{-1}\textbf{H}_{\gamma\phi}(\hat{\pmb\phi}-\pmb\phi_0)$$
Provided the null hypothesis is true (so that $\hat{\pmb\phi}$ is close to $\pmb\phi_0$) we can reuse the previous expansion and write the log-likelihood at the restricted MLE
$$\ell(\pmb\phi_0,\hat{\pmb\gamma}_0)\simeq\ell(\hat{\pmb\phi},\hat{\pmb\gamma})-\frac12\begin{pmatrix}\pmb\phi_0-\hat{\pmb\phi}\\\hat{\pmb\gamma}_0-\hat{\pmb\gamma}\end{pmatrix}\textbf{H}\begin{pmatrix}\pmb\phi_0-\hat{\pmb\phi}\\\hat{\pmb\gamma}_0-\hat{\pmb\gamma}\end{pmatrix}$$
Hence
$$2[\ell(\hat{\pmb\phi},\hat{\pmb\gamma})-\ell(\pmb\phi_0,\hat{\pmb\gamma}_0)\simeq\begin{pmatrix}\pmb\phi_0-\hat{\pmb\phi}\\\hat{\pmb\gamma}_0-\hat\gamma\end{pmatrix}^T\textbf{H}\begin{pmatrix}\pmb\phi_0-\hat{\pmb\phi}\\\hat{\pmb\gamma}_0-\hat\gamma\end{pmatrix}$$
Substituting for $\hat{\pmb\gamma}_0$ and expanding $\textbf{H}$ to its partioned form gives
\[\begin{array}{rcl}
2\lambda&\simeq&\begin{pmatrix}\pmb\phi_0-\hat{\pmb\phi}\\\textbf{H}^{-1}_{\gamma\gamma}\textbf{H}_{\gamma\phi}(\hat{\pmb\phi}-\pmb\phi_0)\end{pmatrix}^T\begin{pmatrix}\textbf{H}_{\phi\phi}&\textbf{H}_{\phi\gamma}\\\textbf{H}_{\gamma\phi}&\textbf{H}_{\gamma\gamma}\end{pmatrix}\begin{pmatrix}\pmb\phi_0-\hat{\pmb\phi}\\\textbf{H}^{-1}_{\gamma\gamma}\textbf{H}_{\gamma\phi}(\hat{\pmb\phi}-\pmb\phi_0)\end{pmatrix}\\
&=&(\hat{\pmb\phi}-\pmb\phi_0)^T[\textbf{H}_{\phi\phi}-\textbf{H}_{\phi\gamma}\textbf{H}^{-1}_{\gamma\gamma}\textbf{H}_{\gamma\phi}](\hat{\pmb\phi}-\pmb\phi_0)\\
&=&(\hat{\pmb\phi}-\pmb\phi_0)^T\pmb\Sigma_{\phi\phi}^{-1}(\hat{\pmb\phi}-\pmb\phi_0)
\end{array}\]
If $H_0$ is true, then as $n\to\infty$ this expresion will tend towards exactness as $\hat{\pmb\phi}\to\pmb\phi_0$.\\
Further, provided $\textbf{H}\overset{n\to\infty}{\longrightarrow}\pmb{\mathcal{I}}$ as then $\pmb\Sigma$ tends to $\pmb{\mathcal{I}}^{-1}$, hence $\pmb\Sigma_{\phi\phi}$ tends to teh covarance matrix of $\hat{\pmb\phi}$.\\
Hence, by tthe asymptotic normality of the MLE $\hat{\pmb\phi}$
$$2[\ell(\hat\theta)-\ell-\ell(\hat\theta_0)]\sim\chi^2_r\text{ under }H_0$$

\subsection{Confidence Intevals}

\definition{Test Inversion}
\textit{Test Inversion}  is the process of finding confidence intervals or sets by finding the range of values that would be accepted as the null hypothesis in a test is known.

\subsection{Regularity Conditions}

\definition{Regularity Conditions}
\textit{Regularity Conditions} are a set of conditions that a model must meed in order to be deemed ``\textit{Regular}". Several results depend on these conditions being met
\begin{enumerate}
	\item The densities defined by distinct values of $\pmb\theta$ are distinct.\\
	If this is not the case the parameters need not be \textit{identifable} and these is no guarantee of consistency.
	\item $\pmb\theta_t$ is interior to the space of possible parameter values.\\
	This is necessary in order to be able to approximate the log-likelihood by a \textit{Taylor Expansion} in the vicinity of $\pmb\theta_t$.
	\item Within some neighbourhood of $\pmb\theta_t$, the first three derivatives of the log likelihood exist and are bounded, while the Fisher Information Matrix satisfies \textbf{Proposition 5.6} $iii)$.
\end{enumerate}

\subsection{Akaike's Information Criterion}

\definition{Kullback-Leibler Divergence}
\textit{Kullback-Leibler Divergence} is a similiarity measure for two densities
$$KL(f_\theta,f_t)=\int[\log f_t(\textbf{y})-\log f_\theta(\textbf{y})]f_t(\textbf{y})d\textbf{y}$$
where $f_t$ is the true density of \textbf{y} and $f_\theta$ is the model approximation to \textbf{y}.\\

\proposition{Using Kullback-Leibler Divergence to choose models}
Given a choice of models it makes sense to pick one which has the lowest \textit{KL Divergence} from the true model.\\
In order for this to be practical we use the expected value of $KL(f_{\hat\theta},f_t)$ as it is tractable when $\hat\theta$ is the MLE.\\
Let $\pmb\theta_K$ denote the value of $\pmb\theta$ which would minimise $KL(\cdot,\cdot)$.\\
Consider the \textit{Taylor Expansion}
$$\log f_{\hat\theta}(\textbf{y})\simeq\log f_{\theta_K}(\textbf{y})+(\hat{\pmb\theta}-\pmb\theta_K)^T\dfrac{\partial\log f_\theta}{\partial\pmb\theta}\bigg|_{\theta_K}+\frac12(\hat{\pmb\theta}-\pmb\theta_K)^T\dfrac{\partial^2\log f_\theta}{\partial\pmb\theta\partial\pmb{\theta}^T}\bigg|_{\theta_K}(\hat{\pmb\theta}-\pmb\theta_K)$$
If $\pmb\theta_K$ minimises $KL(\cdot)$ then
$$\int\frac{\partial\log f_\theta}{\partial\theta}\bigg|_{\theta_K}f_td\textbf{y}=0$$
So substituting the taylor expansion into the definition of $KL(\cdot)$, while treating $\hat{\pmb\theta}$ as fixed, results in
$$KL(f_{\hat\theta},f_t)\simeq K(f_{\theta_K},f_t)+\frac12(\hat{\pmb\theta}-\pmb\theta_K)^T\pmb{\mathcal{I}}_{\theta_K}(\hat{\pmb\theta}-\pmb\theta_K)\text{ where }\pmb{\mathcal{I}}_{\theta_K}\text{ is the information matrix at }\pmb\theta_K$$.\\
Assume that the model is sufficiently correct that $\expect(\hat{\pmb\theta})\simeq\pmb\theta_K$ and $\cov(\hat{\pmb\theta})\simeq\pmb{\mathcal{I}_{\theta_K}}$, at least for large samples.\\
In this case we have
$$\expect[\ell(\hat{\pmb\theta})-\ell(\pmb\theta_K)]\simeq\expect\left(\frac12(\hat{\pmb\theta}-\pmb\theta_K)^T\pmb{\mathcal{I}}_{\theta_K}(\hat{\pmb\theta}-\pmb\theta_K)\right)\simeq\frac{p}2\text{ where }p:=\text{dim}(\pmb\theta)$$
Taking the expactions of $KL(f_{\hat\theta},f_t)$ and substituting an approximation from above we get
$$\expect[KL(f_{\hat\theta},f_t)]\simeq K(f_{\theta_K},f_t)+\frac{p}2$$
This still involves the unknowable $f_t$. Consider
\[\begin{array}{rcl}
\expect[-\ell(\hat{\pmb\theta})&=&\expect[-\ell(\pmb\theta_K)-\{\ell(\hat{\pmb\theta}-\ell(\pmb\theta_K)\}]\\
&\simeq&-\displaystyle\int\log(f_{\theta_K}(\textbf{y})]f_t(\textbf{y})d\textbf{y}-\frac{p}2\\
&=&KL(f_{\theta_K},f_t)-\frac{p}2-\displaystyle\int\log(f_t(\textbf{y}))f_t(\textbf{y})d\textbf{y}
\end{array}\]
Using the result to eliminate $KL(f_{\theta_K},f_t)$ from above suggest the estimate
$$\expect(\widehat{KL(f_{\hat\theta},f_t}=-\ell(\hat{\pmb\theta})+p+\displaystyle\int\log[f_t(\textbf{y})]f_t(\textbf{y})d\textbf{y}$$
Since the last term on the right-hand side only involves the truth, this last estimate is minimised by whichever model minimises
$$AIC:=-2\ell(\hat{\pmb\theta})+2p$$
\nb The factor of 2 is by convention so that AIC is on the same scale as $2[\ell(\hat\theta)-\ell(\theta)]$.\\

\remark{Objection to AIC}
AIC is \underline{not} consistent.\\
As $n\to\infty$ the probability of selecting the correct model does not tend to 1.\\
For \textit{Nested Models} $2[\ell(\hat\theta)-\ell(\theta)]\sim\chi^2$ states that the difference in $-2\ell(\hat\theta)$ between teh true model and an overly complex model follows a $chi^2_r$ distribution where $r$ is the number of spurious parameters.\\
Neither $\chi^2_r$ nor $2p$ depends on $n$, so the probability of selecting the overly complex model by $AIC$ is nonzero and independent of $n$ (for large $n$).

\section{Bayesian Inference (MCMC Metods)}

\remark{Posterior Distribution}
For linear models the posterior distribution has tractable.\\
This is generally not the case and in order to use Bayes' theorme we need to do one of the following
\begin{enumerate}
	\item Approximate the posterior, or posterior expectations that are of more direct interest; Or,
	\item Find a way of simulating from the posteior that avoids the difficulties in trying to compute posterior densities directly.
\end{enumerate}
\nb This course only covers the simulation appraoch.\\

\proposition{Divising Simulation Methods}
Note that $f(\theta|y)\propto f(\theta,y)=\frac{f(y|theta)}{f(\theta)}$.\\
We can compute values for this by simulating from $f(\theta|y)$.\\

\definition{Markov Chains}
A \textit{Markov Chain} is a sequence of random vectors $\X_1,\X_2,\dots$ which satisfies
$$f(\x_j|\x_{j-1},\x_{j-2},\dots,\x_1)=f(\x_j|\x_{j-1})\forall j$$
Ie the probability of a realisation depends solely on the previous realisation \& non-earlier.\\
\nb $\prob(\x_j|\x_{j-1})$ is called the \textit{Transition Kernel} of the \textit{Markov Chain}.\\

\remark{MCMC=Markoc Chain Monte Carlo}

\definition{Stationary Distribution}
A \textit{Stationary Distribution} of a \textit{Markov Chain} is a distribution, $f_x$ which satisfies
$$f_x(\x_j)=\int \prob(\x_j|\x_{j-1})f_x(\x_{j-1})d\x_{j-1}$$
\nb Whether a \textit{Stationary Distribution} exists depends on $\prob$ being irreducible (\ie Wherever we start the chain there is a positive probability of visiting all possible values of $\X$).\\

\definition{Recurrent}
A \textit{Markov Chain} is \textit{Recurrent} if whenveer its length tends to infinity it will revisit any non-negligible set of values an infinite number of times.\\
\nb In this case the \textit{Stationary Distribution} is also the \textit{Limiting Distribution}.\\

\remark{Recurrent}
If a \textit{Markov Chain} is \textit{Recurrent} we can start at any possible value of $\X$ and its marginal distribution will eventually converge on the \textit{Stationary Distribution}, $f_x$.\\
Thus as simulation length, $J$, tends to infinity
$$\frac1J\sum_{j=1}^J\phi(\x_j)\to\expect_{f_x}[\phi(\X)]$$
This is an extension of the law of large numbers to this particular sort of correlated sequence, this is what makes MCMC methods useful.\\
\nb This property is known as \textit{ergodicity}.\\

\definition{Reversibility}
A MCMC scheme will generate samples, $\{\pmb\theta_1,\pmb\theta_2,\dots\}$, from $f(\pmb\theta|\textbf{y})$ if it satisfies \textit{Reversibility} (AKA \textit{Detailed Balance Condition}).\\
Let $\prob(\pmb\theta_i|\pmb\theta_j)$ be the pdf of $\pmb\theta_i$ given $\pmb\theta_j$, according to the chain.\\
We require
$$P(\pmb\theta_j|\pmb\theta_{j-1})f(\pmb\theta_{j-1}|\textbf{y})=\prob(\pmb\theta_{j-1}|\pmb\theta_j)f(\pmb\theta_j|\textbf{y})$$

\proposition{Using Reversibility}
Note that the LHS is the joint pdf of $\pmb\theta_j$ and $\pmb\theta_{j-1}$.\\
Integrating wrt $\pmb\theta_{j-1}$ gives
\[\begin{array}{rcl}
\displaystyle\int P(\pmb\theta_j|\pmb\theta_{j-1})f(\pmb\theta_{j-1}|\textbf{y})d\pmb\theta_{j-1}&=&\displaystyle\int P(\pmb\theta_{j-1}|\pmb\theta_j)f(\pmb\theta_j|\textbf{y})d\pmb\theta_{j-1}\\
&=&f(\pmb\theta_J|\textbf{Y})
\end{array}\]
Thus, if we start with a $\pmb\theta_1$ that is not impossible according to $f(\pmb\theta|\textbf{y})$ then the chain will generate from the target distribution.\\
The speed of converge to a high-probability region of $f(\pmb\theta|\textbf{y})$ is a different problem.\\

\subsection{Metropolis Hastings Method}

\proposition{Metropolis Hastings Method}
The \textit{Metropolis-Hastings Method} constructs a chain with an appropriate $P$.\\
It can be performed as follows
\begin{enumerate}
	\item Pick a \textit{proposal distribution} $q(\pmb\theta_j|\pmb\theta_{j-1})$ (\eg a normal distribution centred around $\pmb\theta_{j-1}$.
	\item Pick a value $\pmb\theta_0$, set $j=1$ and iterate $iii)-v)$.
	\item Generate $\pmb\theta'_j$ from $q(\pmb\theta_j|\pmb\theta_{j-1})$.
	\item Set $\pmb\theta_j=\pmb\theta_j'$ with probabilitiy
	$$\alpha=\min\left\{1,\dfrac{f(\textbf{y}|\pmb\theta'_j)f(\pmb\theta'_j)q(\pmb\theta_{j-1}|\pmb\theta_j')}{f(\textbf{y}|\pmb\theta_{j-1})f(\pmb\theta_{j-1})q(\pmb\theta'_j|\pmb\theta_{j-1})}\right\}$$.
	\item Increment $j$
\end{enumerate}

\remark{$\alpha$ - Metropolis Hastings Method}
Note that the $q$ terms cancel if $q$ only depends on the magnitude of $(\pmb\theta_j-\pmb\theta_{j-1})$ which is the case it is a normal centred on $\pmb\theta_{j-1}$.\\
The same is true for the priors, $f(\pmb\theta'_j)$ and $f(\pmb\theta_{j-1})$, if they are improper uniform.\\
If both of these are true then $\alpha=\min\{1,L(\pmb\theta_j')/L(\pmb\theta_{j-1})\}$.\\

\remark{Choosing $\pmb\theta_0$ - Metropolis Hastings Method}
$\pmb\theta_1$ may be highly improbable, so the chain will require many iterations to reach the high-probability region of $f(\pmb\theta|\textbf{y})$.\\
Usually we require to discard the \textit{burn-in period} (\ie first few hundred $\pmb\theta_j$ vectors simulated).

\proof{Metropolis Hastings Method Works}
Here I prove that \textit{Metropolis-Hastings Method} works if it satisfies \textit{reversibility}.\\
For notation let $\pi(\pmb\theta)=f(\pmb\theta)$, remebering that $f(\pmb\theta|\textbf{y})\propto f(\textbf{y}|\pmb\theta)f(\pmb\theta)$.\\
This means the acceptance probability from $\pmb\theta$ to $\pmb\theta'$ is
$$\alpha(\pmb\theta',\pmb\theta)=\min\left\{1,\dfrac{\pi(\pmb\theta')q(\pmb\theta|\pmb\theta')}{\pi(\pmb\theta)q(\pmb\theta'|\pmb\theta)}\right\}$$
We want to show that $\pi(\pmb\theta)P(\pmb\theta'|\pmb\theta)=\pi(\pmb\theta')P(\pmb\theta|\pmb\theta')$.\\
This is trivial if $\pmb\theta'=\pmb\theta$.\\
Otherwise, we know that $P(\pmb\theta'|\pmb\theta)=q(\pmb\theta'|\pmb\theta)\alpha(\pmb\theta',\pmb\theta)$.\\
Thus
\[\begin{array}{rcl}
\pi(\pmb\theta)P(\pmb\theta'|\pmb\theta)&=&\pi(\pmb\theta)q(\pmb\theta'|\pmb\theta)\min\left\{1,\dfrac{\pi(\pmb\theta')q(\pmb\theta|\pmb\theta')}{\pi(\pmb\theta)q(\pmb\theta'|\pmb\theta)}\right\}\\
&=&\min\{\pi(\pmb\theta)q(\pmb\theta'|\pmb\theta),\pi(\pmb\theta')q(\pmb\theta|\pmb\theta')\}\\
&=&\pi(\pmb\theta')P(\pmb\theta|\pmb\theta')\text{ by symmetry}
\end{array}\]

\proposition{Choosing Proposal Distributions}
The \textit{Metropolis-Hastings Method} requires the proposal of a distribution.\\
In many practical applications, several pilot runs of the \textit{Metropolis-Hastings Sampler} are needed to `tune' the proposal distribution, along with some analysis of model struture.\\
In particular
\begin{enumerate}
	\item With simple independent random walk proposals, different standard deviations are likely to be required for different parameters.
	\item As its dimension increases it often becomes increasingly difficult to update all elements of $\pmb\theta$ simultaneously, unless uselessly tiny steps are proposed.\\
	The difficulty is that a purely random step is increasingly unlikely to land in a place wheret eh posterior is non-negligible as dimensions increase.
	\item It may be necessary to use correlated proposals, rather than updating each elment of $\pmb\theta$ independently.\\
	Bearing in mind the impractical fact that the perfect proposal would be the posterior iteself, it is tempting to base the proposal on a Gaussian approximation to the posterior, obtained analytically, or from a pilot run.
\end{enumerate}

\remark{Choosing Proposal Distribution}
To summarise the following are important when designing a proposal distribution
\begin{enumerate}
	\item It is often necessary to update parameters in blocks.
	\item The perfect proposal is the posterior itself.
\end{enumerate}
\nb $ii)$ is impractical but when applied blockwise it can result in a very efficient scheme (\ie Gibbs Sampling).

\subsection{Gibbs Sampling}

\proposition{General Idea}
Consider a random draw from the joint posterior ditribution of $\pmb\theta^{[-1]}(\theta_2,\dots,\theta_q)^T$ (\ie For all dimensions except the first).\\
Suppose we would like a draw from the joint posterior distribution of the whole of $\pmb\theta$.\\
This is trival since $f(\pmb\theta|\textbf{y})=f(\theta_1|\pmb\theta^{[-1]},\textbf{y})f(\pmb\theta^{[-1]}|\textbf{y})$.\\
Thus we can simulate $\theta_1$ from $f(\theta_1|\pmb\theta^{[-1]},\textbf{y})$ and append the result onto $\pmb\theta^{[-1]}$.\\
This doesn't only work for the first dimension, but for all.\\
Thus we can simulate the whole of $\pmb\theta$ by cycling through all dimensions.

\definition{Gibbs Sampler}
Suppose the parameter row vector is partitioned into subvectors $\pmb\theta:=(\pmb\theta^{[1]},\dots,\pmb\theta^{[K]})$.\\
Further, define
$$\tilde{\pmb\theta}_j^{[-k]}=(\pmb\theta^{[1]}_{j+1},\dots,\pmb\theta^{[k-1]}_{j+1},\pmb\theta^{[k+1]}_j,\pmb\theta^{[K]}_j)$$
Let $\pmb\theta_1$ be an initial guess.\\
We perform $J$ steps of the \textit{Gibbs Sampler Process} as follows
\begin{enumerate}
	\item For $j\in[1,J]$:
	\begin{enumerate}
		\item For $k\in[1,\dots,K]$ siulate $\pmb\theta_{j+1}^{[k]}\sim f(\pmb\theta^{[k]}|\tilde{\pmb\theta}_j^{[-k]},\textbf{y})$.
	\end{enumerate}
\end{enumerate}

\proposition{How to find these conditional distributions}
It is generally natural to specify a model in terms of a hierarchy of conditional dependencies, but these dependencies all run in one direction. Thus the problem of working out the conditional dependencies is in the other direction.\\
Alternatively, if we attempt to specify the model directly in terms of all its conditional distributions, we will have the no less tricky problem of checking that our speecification actually corresponds to a properly defined joint distribution.\\
\nb Usually identifying the conditionals is not too bad and even if we cannot recognise the condtiionals as belonging to some standard distribution it is always possible to devise some ay of simulating from them (Using a Metropolis Hastings can be done).\\

\remark{Trick for recognising conditionals}
The trick for recognising conditionals is to use the fact that, for any \textit{pdf}, multiplicative factors that do not involve the argument of the \textit{pdf} must be part of the normalising constant.\\
Thus it is sufficient to recognise its form, to within a normalising constant.\\
\nb \textbf{9.8} in notes gives an example where this trick is used.\\

\proposition{Limitations}
\textit{Gibbs Sampling} produces slow moving chains if parameters have high posterior correlation, as sampling from the conditionals then produces very small steps.\\
Updating the parameters in blocks or reparameterising to reuce posteior dependence can help to improve msing.\\
If improper priors are used with \textit{Gibbs Sampling} then it is important to check that the posterior is actuallly proper (it is not always possible to detect impropriety for the output of the sampler).

\subsection{Checking for Convergence of MCMC Chains}

\remark{MCMC methods are very general}
In principle we can use any model \& given enough time can produce a sample from the posterior.\\
Although, it may take several thousand (or way more) iterations for this sample to be produced.\\

\remark{Posterior could be Multi-Modal}
Run multiple chains starting at very different positions.\\

\proposition{Analysing quantiles}
By examining how specific quantiles of hte sample, up to iteration $j$, behave when plotted against $j$, we may be able to detect convergence if all the quantiles converge.\\

\definition{Autocorrelation Length}
The \textit{Autocorrelation Length} of a chain is twice the sum of the correlations, minus 1.\\

\proposition{Effective Sample Size}
\textit{Effective Sample Size} of a chain is what size of independent samples from $f(\pmb\theta|\textbf{y})$ would be equivalent to the correlated sample from our MCMC scheme.\\
\textit{Autocorrelation Length} can be used to assess this
$$\text{Effective Sample Size}=\frac{\text{Sample Size}}{\text{Autocorrelation}}$$

\subsection{Interval Estimation}

\proposition{}
Given reliable posterior simulations from a chian, inteval estimates and quantiles for model comparision can be computed.\\
Inteval estimates are straightforward since intervals can be based directly on the observed quantiles of the simulated parameters.

\section{Graphical Models \& Automatic Gibbs Sampling}

\newpage
\setcounter{section}{-1}
\section{Reference}

\subsection{Definitions}

\definition{Heavy Tailed}

\definition{Censored Data}

\definition{Upper Triangular Matrix}

\definition{Orthogonal Matrix}

\definition{$p$-Value}

\definition{Euclidean Distance}

\subsection{Probability}

\definition{Random Variable}
A \textit{Random Variable} is a function from the sample space to the reals.
$$X:\Omega\to\reals$$
\textit{Random Variables} take a different value each time they are observed and thus we define distributions for the probability of them taking particular values.\\
\textit{Random Variables} form the basis of models.\\

\definition{Cummulative Distribution}
The \textit{Cummulative Distribution} function of a \textit{Random Variable}, $X$, is the function $F_X(\cdot)$ st
\[\begin{array}{rllrl}
F_X(\cdot)&:&\reals\to[0,1]\\
F_X(x)&:=&\prob(X\leq x)&=&\displaystyle\sum_{i=-\infty}^x\prob(X=i)\\
&&&=&\displaystyle\int_{-\infty}^xf_X(x)dx
\end{array}\]
The \textit{Cummulative Distribution} is a monotonic function.\\

\remark{Continuous Cummulative Distribution}
If a \textit{Cummulative Distribution} is \textit{continuous} then $F_X(X)\sim\text{Uniform}[0,1]$.\\

\prooff{Remark 2.1}
\[\begin{array}{rcl}
F(X)&=&\prob(X\leq x)\\
&=&\prob(F(X)\leq F(x))\\
\implies\prob(F(X)\leq u)&=&u\text{ if $F$ is continuous}
\end{array}\]

\definition{Quantile Function}
The \textit{Quantile Function} of a \textit{Random Variable} is the inverse function of the \textit{Cumulative Distribution}.\\
\[\begin{array}{rll}
F^-_X(\cdot)&:&[0,1]\to\reals\\
F^-_X(u)&:=&\min\{x:F(x)\geq u\}
\end{array}\]
If a distribution has a computable \textit{Quantile Function} then we are able to generate random variable values by sampling from a uniform distribution \& then passing that value into the \textit{Quantile Function}.\\

\definition{(Q-Q) Plot}
Consider a data set $\{x_1,\dots,x_n\}$.\\
A \textit{(Q-Q) Plot} of this data set plots the ordered data set, $\{x_{(1)},\dots,x_{(n)}\}$, against the theoretical quantiles $F^-\left(\frac{i-.5}n\right)$.\\
The close this line is to $y=x$ the more likely it is the data was generated by this \textit{Cummulative Distribtion}.\\
\nb AKA \textit{Quantile-Quantile Plot}

\definition{Probabiltiy Mass Function}
A \textit{Probability Mass Function} returns the probabiltiy of a \underline{discrete} random variable taking a particular value.
\[\begin{array}{rll}
f_X(\cdot)&:&\reals\to[0,1]\\
f_X(x)&:=&\prob(X=x)\\
\end{array}\]

\definition{Probability Density Function}
Since the probabiltiy of a \textit{Continuous Random Variable} taking a specific value is zero we cannot use the \textit{Probability Mass Function}.
\[\begin{array}{rll}
f_X(\cdot)&:&\reals\to[0,1]\\
\prob(a\leq X\leq b)&=&\displaystyle\int_a^bf(x)dx
\end{array}\]
\nb $F_X'(x)=f(x)$ when $F_X'(\cdot)$ exists.\\

\definition{Joint Probabiltiy Density Function}
Let $X\ \& Y$ be \textit{Random Variables}.\\
The \textit{Joint Probabiltiy Density Function} of $X$ and $Y$ is the function $f_{X,Y}(x,y)$ st
$$\prob((X,Y)\in\Omega)=\iint_\Omega f_{X,Y}(x,y)dxdy$$
\nb This can be seen as evaluation $\Omega$ in the $X-Y$ plane.\\

\definition{Marginal Distribution}
Let $X\ \&\ Y$ be \textit{Random Variables} with \textit{Joint Probability Density} $f_{X,Y}(\cdot,\cdot)$.\\
We can find the \textit{Marginal Distribution} of $X$ by evaluating the $f_{X,Y}$ at each value wrt $Y$.
$$f_X(x)=\int_{-\infty}^\infty f_{X,Y}(x,y)dy$$

\definition{Expected Value, $\expect$}
The \textit{Expected Value} of a \textit{Random Variable}, $X$, is its mean value.
\[\begin{array}{rcll}
\expect(X)&:=&\displaystyle\int_{-\infty}^\infty xf(x)dx&\text{ [Continuous]}\\
\expect(g(X))&:=&\displaystyle\int_{-\infty}^\infty g(x)f(x)dx&\\\\
\expect(X)&:=&\displaystyle\sum_{-\infty}^\infty xf(x)&\text{ [Discrete]}\\
\expect(g(X))&:=&\displaystyle\sum_{-\infty}^\infty g(x)f(x)&
\end{array}\]

\remarkk{Linear Transformations of Expected Value}
$$\expect(a+bX)=a+b\expect(X)\text{ where }a,b\in\reals$$

\remark{Expected Value of Composed Random Variables}
Let $X$ \& $Y$ be \textit{Random Variables}. Then
$$\expect(X+Y)=\expect(X)+\expect(Y)$$
If $X$ \& $Y$ are \textit{independent}. Then
$$\expect(XY)=\expect(X)\expect(Y)$$

\proof{Remark 2.3}
\[\begin{array}{rcl}
\expect(X+Y)&=&\int(x+y)f_{X,Y}(x,y)dxdy\\
&=&\int xf_{X,Y}(x,y)dxdy+\int yf_{X,Y}(x,y)dxdy\\
&=&\expect(X)+\expect(Y)\\
\expect(XY)&=&\int xyf_{X,Y}(x,y)dxdy\\
&=&\int xf_X(x)yf_Y(y)dxdy\text{ by independence}\\
&=&\int xf_X(x)dx\int yf_Y(y)dy\\
&=&\expect(X)\expect(Y)
\end{array}\]

\definition{Variance, $\sigma^2$}
The \textit{Variance} of a \textit{Random Variable}, $X$, is a measure of its spread around its expected value.
$$\var(X)=\expect[(X-\expect(X))^2]=\expect(X^2)-\expect(X)^2$$

\remarkk{Linear Transformations of Variance}
$$\var(a+bX)=b^2\var(X)\text{ where }a,b\in\reals$$

\prooff{Remark 2.4}
\[\begin{array}{rcl}
\var(a+bX)&=&\expect[((a+bX)-(a-b\mu))^2]\\
&=&\expect[b^2(X-\mu)^2]\\
&=&b^2\expect[(X-\mu)^2]\\
&=&b^2\var(X)
\end{array}\]

\definition{Co-Variance}
\textit{Co-Variance} is a measure of the joint variability of two \textit{Random Variables}.
$$\cov(X,Y):=\expect[(X-\expect(X))(Y-\expect(Y))]=\expect(XY)-\expect(X)\expect(Y)$$
\nb If $X\ \&\ Y$ are independent then $\cov(X,Y)=0$ since $\expect(XY)=\expect(X)\expect(Y)$.\\
\nb $\cov(X,Y)=\cov(Y,X)$.\\

\definition{Co-Variance Matrix, $\Sigma$}
Let $\textbf{X}:=\{X_1,\dots,X_n\}$ be a set of random variables.\\
A \textit{Co-Variance Matrix} describes the \textit{Variance} \& \textit{Co-Variance} of each combination of \textit{Random Variables} in $\textbf{X}$.\\
$$\Sigma:=\expect[(\textbf{X}-\pmb\mu)(\textbf{X}-\pmb\mu)^T]$$
\nb $\Sigma_{ii}=\var(X_i)\ \&\ \Sigma_{ij}=\cov(X_i,X_j)$ for $i\neq j$. $\Sigma$ is symmetric.\\

\remarkk{Linear Transformation of Covariance}
$$\Sigma_{AX+b}=A\Sigma A^T$$

\prooff{Remark 2.5}
\[\begin{array}{rcl}
\Sigma_{AX+b}&=&\expect[(AX+\textbf{b}-A\pmb\mu-\textbf{b})(AX+\textbf{b}-A\pmb\mu-\textbf{b})^T]\\
&=&\expect[(AX-A\pmb\mu)(AX-A\pmb\mu)^T]\\
&=&A\expect[(X-\pmb\mu)(X-\pmb\mu)^T]A^T\\
&=&A\Sigma A^T
\end{array}\]

\definition{Conditional Distribution}
Let $X\ \&\ Y$ be \textit{Random Variables} with \textit{Joint Probability Density} $f_{X,Y}(\cdot,\cdot)$.\\
Suppose we know that $Y$ takes the value $y_0$ \& we wish to establish the probability of $X$ taking the value $x$.
$$f(X=x|Y=y_0)=\dfrac{f_{X,Y}(x,y_0)}{f_Y(y_0)}$$
assuming $f(y_0)>0$.\\

\proof{Conditional Distribution}
We expect $f(X=x|Y=y_0)=kf_{X,Y}(x,y_0)$ for some constant $k$.\\
We know that for $kf_{X,Y}(x,y_0)$ to be a valid distribution it must integrate to one.
\[\begin{array}{rrcl}
&k\displaystyle\int_{-\infty}^\infty f_{X,Y}(x,y_0)dx&=&1\\
\implies&kf_Y(y_0)&=&1\\
\implies&k&=&\dfrac{1}{f_Y(y_0)}\\
\implies&f(X=x|Y=y_0)&=&\dfrac{f_{X,Y}(x,y_0)}{f_Y(y_0)}
\end{array}\]

\propositionn{Conditional Distributions with Three Random Variables}
\[\begin{array}{rcl}
f(x,z|y)&=&f(x|z,y)f(z|y)\\
f(x,y,z)&=&f(x|y,z)f(z|y)f(y)\\
&=&f(x|y,z)f(y,z)
\end{array}\]

\definition{Independent Random Variables}
Let $X$ \& $Y$ be random variables.\\
$X$ \& $Y$ are said to be \textit{Statistically Independent} if the \textit{Conditional Distribution} $f(x|y)$ is independent of $y$.\\
Thus
\[\begin{array}{rcl}
f(x)=\displaystyle\int_{-\infty}^\infty f(x,y)dy\\
&=&\displaystyle\int_{-\infty}^\infty f(x|y)f(y)dy\\
&=&f(x|y)\displaystyle\int_{-\infty}^\infty f(y)dy\\
&=&f(x|y)\\
\implies f(x,y)&=&f(x|y)f_Y(y)=f_X(x)f_Y(y)
\end{array}\]

\theorem{Bayes' Theorem}
Let $X\ \&\ Y$ be \textit{Random Variables}.\\
\textit{Bayes' Theorem} states that
$$f(X|Y)=\dfrac{f(Y|X)x(X)}{f(Y)}$$

\definition{First Order Markov Property}
Let $\textbf{X}:=\{X_1,\dots,X_n\}$ be a set of \textit{Random Variables}.\\
The set $\textbf{X}$ is said to have the \textit{First Order Markov Property} if
$$f(X_i|\textbf{X}_{\neg i})= f(X_i|X_{i-1})\text{ where }\textbf{X}_{\neg i}:=\textbf{X}/\{X_i\}$$
Thus we can infer the \textit{marginal distribution}
$$f(\textbf{X})=f(X_1)\prod_{i=2}^Nf(X_i|X_{i-1})$$

\subsubsection{Probability Distributions}

\definition{$\beta$-Distribution}
Let $X\sim\text{Beta}(\alpha,\beta)$.\\
A \textit{continuous} random variable with shape parameters $\alpha,\beta>0$. Then
\[\begin{array}{rcl}
f_X(x)&\propto&x^{\alpha-1}(1-x)^{\beta-1}\mathds{1}\{x\in[0,1]\}\\
\expect(X)&=&\dfrac{\alpha}{\alpha+\beta}\\
\var(X)&=&\dfrac{\alpha\beta}{(\alpha+\beta)^2(\alpha+\beta+1)}\\
\mathcal{M}_X(t)&=&1+{\displaystyle\sum_{k=1}^\infty\left(\prod_{r=0}^{k-1}\dfrac{\alpha+r}{\alpha+\beta+r}\right)\dfrac{t^k}{k!}}
\end{array}\]

\definition{Bernoulli Distribution}
Let $X\sim\text{Bernoulli}(p)$.\\
A \textit{discrete} random variable which takes 1 with probability $p$ \& 0 with probability $(1-p)$. Then
\[\begin{array}{rcl}
p_X(k)&=&\begin{cases}1-p&\text{if }k=0\\p&\text{if }k=1\\0&\text{otherwise}\end{cases}\\
P_X(k)&=&\begin{cases}0&\text{if }k<0\\1-p&\text{if }k\in[0,1)\\1&\text{otherwise}\end{cases}\\
\expect(X)&=&p\\
\var(X)&=&p(1-p)\\
\mathcal{M}_X(t)&=&(1-p)+pe^t
\end{array}\]
\nb Often we define $q:=1-p$ for simplicity.\\

\definition{Binomial Distribution}
Let $X\sim\text{Binomial}(n,p)$.\\
A \textit{discrete} random variable modelled by a \textit{Binomial Distribution} on $n$ independent events and rate of success $p$.\\
\[\begin{array}{rcl}
p_X(k)&=&{n\choose k}p^k(1-p)^{n-k}\\
P_X(k)&=&\sum_{i=1}^k{n\choose i}p^i(1-p)^{n-i}\\
\expect(X)&=&np\\
\var(X)&=&np(1-p)\\
\mathcal{M}_X(t)&=&[(1-p)+pe^t]^n
\end{array}\]
\nb If $Y:=\sum_{i=1}^nX_i$ where $\X\iid\text{Bernoulli}(p)$ then $Y\sim\text{Binomial}(n,p)$.\\

\definition{Categorical Distribution}
Let $X\sim\text{Categorical}(\textbf{p})$.\\
A \textit{discrete} random varaible where probability vector $\textbf{p}$ for a set of events $\{1,\dots,m\}$.\\
\[\begin{array}{rcl}
f_X(i)=p_i
\end{array}\]

\definition{$\chi^2$ Distribution}
Let $X\sim\chi^2_r$.\\
A \textit{continuous} random variable modelled by the \textit{$\chi^2$ Distribution} with $r$ degrees of freedom. Then
\[\begin{array}{rcl}
f_X(x)&=&\dfrac{1}{2^{r/2}\Gamma(r/2)}x^{\frac{r}{2}-1}e^{-\frac{x}{2}}\\
F_X(x)&=&\dfrac{1}{\Gamma(k/2)}\gamma\left(\frac{r}{2},\frac{x}{2}\right)\\
\expect(X)&=&r\\
\var(X)&=&2r\\
\mathcal{M}_X(t)&=&\indicator\{t<\frac{1}{2}\}(1-2t)^{-\frac{r}{2}}
\end{array}\]
\nb If $Y:=\sum_{i=1}^kZ_i^2$ with $\textbf{Z}\iid\text{Normal}(0,1)$ then $Y\sim\chi^2_k$.\\

\definition{Exponential Distribution}
Let $X\sim\text{Exponential}(\lambda)$.\\
A \textit{continuous} random variable modelled by a \textit{Exponential Distribution} with rate-parameter $\lambda$. Then
\[\begin{array}{rcl}
f_X(x)&=&\indicator\{t\geq0\}.\lambda e^{-\lambda x}\\
F_X(x)&=&\indicator\{t\geq0\}.\left(1-e^{-\lambda x}\right)\\
\expect(X)&=&\dfrac{1}{\lambda}\\
\var(X)&=&\dfrac{1}{\lambda^2}\\
\mathcal{M}_X(t)&=&\indicator\{t<\lambda\}\dfrac{\lambda}{\lambda-t}
\end{array}\]
\nb Exponential Distribution is used to model the wait time between decays of a radioactive source.\\

\definition{Gamma Distribution}
Let $X\sim\Gamma(\alpha,\beta)$.\\
A \textit{continuous} random variable modelled by a \textit{Gamma Distribution} with shape parameter $\alpha>0$ \& rate parameter $\beta$. Then
\[\begin{array}{rcll}
f_X(x)&=&\dfrac{1}{\Gamma(\alpha)}\beta^\alpha x^{\alpha-1}e^{-\beta x}\\
F_X(x)&=&\dfrac{\Gamma(\alpha)}\gamma(\alpha,\beta x)\\
\expect(X)&=&\dfrac{\alpha}{\beta}\\
\var(X)&=&\dfrac{\alpha}{\beta^2}\\
\mathcal{M}_X(t)&=&\indicator\{t<\beta\}\left(1-\frac{t}{\beta}\right)^{-\alpha}
\end{array}\]
\nb There is an equivalent definition of a \textit{Gamma Distribution} in terms of a shape \& \underline{scale} parameter. The scale parameter is 1 over the rate parameter in this definition.\\

\definition{Multinomial Distribution}
Let $\X\sim\text{Multinomial}(n,\textbf{p})$.\\
A \textit{discrete} random varible which models $n$ events with probability vector $\textbf{p}$ for events $\{1,\dots,m\}$.\\
\[\begin{array}{rcl}
f_\X(\x)&=&{\displaystyle\mathds{1}\left\{\sum_{i=1}^mx_i\equiv m\right\}\frac{n!}{x_1!\cdot\dots\cdot x_n!}\prod_{i=1}^np_i^{x_i}}\\
\expect(X_i)&=&np_i\\
\var(X_i)&=&np_i(1-p_i)\\
\cov(X_i,x_j)&=&-np_ip_j\text{ for }i\neq j\\
\mathcal{M}_{X_i}(\theta_i)&=&\left(\displaystyle\sum_{i=1}^mp_ie^{\theta_i}\right)^n
\end{array}\]
\nb In a realisation $\x$ of $\X$, $x_i$ is the number of times event $i$ has occured.\\

\definition{Normal Distribution}
Let $X\sim\text{Normal}(\mu,\sigma^2)$.\\
A \textit{continuous} random variable  with mean $\mu$ \& variance $\sigma^2$.
\[\begin{array}{rcl}
f_X(x)&=&\dfrac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}\\
F_X(x)&=&\dfrac{1}{\sqrt{2\pi\sigma^2}}\int\limits_{-\infty}^xe^{-\frac{(y-\mu)^2}{2\sigma^2}}dy\\
\expect(X)&=&\mu\\
\var(X)&=&\sigma^2\\
\mathcal{M}_X(\theta)&=&e^{\mu\theta+\sigma^2\theta^2(1/2)}
\end{array}\]

\definition{Pareto Distribution}
Let $X\sim\text{Pareto}(x_0,\theta)$.\\
A \textit{continuous} random variable modelled by a \textit{Pareto Distribution} with minimum value $x_0$ \& shape parameter $\alpha>0$. Then
\[\begin{array}{rcll}
f_X(x)&=&\dfrac{\alpha x_0^\alpha}{x^{\alpha+1}}\\
F_X(x)&=&1-\left(\dfrac{x_0}{x}\right)^\alpha\\
\expect(X)&=&\begin{cases}\infty&\alpha\leq1\\\dfrac{\alpha x_0}{\alpha-1}&\alpha>1\end{cases}\\
\var(X)&=&\begin{cases}\infty&\alpha\leq2\\\dfrac{x_0^2\alpha}{(\alpha-1)^2(\alpha-2)}&\alpha>2\end{cases}\\
\mathcal{M}_X(t)&=&\indicator\{t<0\}\alpha(-x_0t)^\alpha\Gamma(-\alpha,-x_0t)
\end{array}\]

\definition{Poisson Distribution}
Let $X\sim\text{Poisson}(\lambda)$.\\
A \textit{discrete} random variable modelled by a \textit{Poisson Distribution} with rate parameter $\lambda$. Then
\[\begin{array}{rcll}
p_X(k)&=&\dfrac{e^{-\lambda}\lambda^k}{k!}&\text{for }k\in\nats_0\\
P_X(k)&=&{\displaystyle e^{-\lambda}\sum_{i=1}^k\frac{\lambda^i}{i!}}\\
\expect(X)&=&\lambda\\
\var(X)&=&\lambda\\
\mathcal{M}_X(t)&=&e^{\lambda(e^t-1)}
\end{array}\]
\nb Poisson Distribution is used to model the number of radioactive decays in a time period.\\

\definition{$t$-Distribution}
Let $X\sim t_r$.\\
A \textit{continuous} random variable with $r$ degrees of freedom. Then
\[\begin{array}{rcll}
f_X(k)&=&{\displaystyle\frac{\Gamma\left(\frac{\nu+1}{2}\right)}{\sqrt{\nu\pi}\Gamma\left(\frac{\nu}{2}\right)}\left(1+\frac{x^2}{\nu}\right)^{-\frac{\nu+1}{2}}}\\
\expect(X)&=&\begin{cases}0&\text{if }\nu>1\\\text{undefined}&\text{otherwise}\end{cases}\\
\var(X)&=&\begin{cases}\frac{\nu}{\nu-2}&\text{if }\nu>2\\\infty&1<\nu\leq2\\\text{undefined}&\text{otherwise}\end{cases}\\
\mathcal{M}_X(t)&=&\text{undefined}
\end{array}\]
\nb Let $Y\sim\text{Normal}(0,1)\ \&\ Z\sim\chi^2_r$ be independent random variables then $X:=\dfrac{Y}{\sqrt{Z/r}}\sim t_r$.\\

\definition{Uniform Distribution - Uniform}
Let $X\sim\text{Uniform}(a,b)$.\\
A \textit{continuous} random variable with lower bound $a$ \& upper bound $b$. Then
\[\begin{array}{rcll}
f_X(x)&=&\begin{cases}\frac{1}{b-a}&x\in[a,b]\\0&\text{otherwise}\end{cases}\\
F_X(x)&=&\begin{cases}0&x<a\\\frac{x-a}{b-a}&x\in[a,b]\\1&\text{otherwise}\end{cases}\\
\expect(X)&=&\frac{1}{2}(a+b)\\
\var(X)&=&\frac{1}{12}(b-a)^2\\
\mathcal{M}_X(t)&=&\begin{cases}\dfrac{e^{tb}-e^{ta}}{t(b-a)}&t\neq0\\1&t=0\end{cases}
\end{array}\]

\end{document}
