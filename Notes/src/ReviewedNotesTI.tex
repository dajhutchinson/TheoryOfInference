\documentclass[11pt,a4paper]{article}

\usepackage[margin=1in, paperwidth=8.3in, paperheight=11.7in]{geometry}
\usepackage[ruled, vlined, linesnumbered]{algorithm2e}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{changepage}
\usepackage{dsfont}
\usepackage{enumerate}
\usepackage{enumitem}
\usepackage{fancyhdr}
\usepackage{graphicx}
\usepackage{tikz}

\begin{document}

\pagestyle{fancy}
\setlength\parindent{0pt}
\allowdisplaybreaks

\renewcommand{\headrulewidth}{0pt}
\setlist[enumerate,1]{label={\roman*)}}

% footnotemark style
\renewcommand{\thefootnote}{[\arabic{footnote}]}

%Tik Styles
\tikzset{
	circleStyle/.style={
	circle,
	draw,
	text width=6mm,
	inner sep=0pt,
	align=center
	}
}

% Cover page title
\title{Theory of Inference - Reviewed Notes}
\author{Dom Hutchinson}
\date{\today}
\maketitle

% Header
\fancyhead[L]{Dom Hutchinson}
\fancyhead[C]{Theory of Inference - Reviewed Notes}
\fancyhead[R]{\today}

% Counters
\newcounter{definition}[section]
\newcounter{example}[section]
\newcounter{notation}[section]
\newcounter{proposition}[section]
\newcounter{proof}[section]
\newcounter{remark}[section]
\newcounter{theorem}[section]

% commands
\newcommand{\dotprod}[0]{\boldsymbol{\cdot}}
\newcommand{\cosech}[0]{\mathrm{cosech}\ }
\newcommand{\cosec}[0]{\mathrm{cosec}\ }
\newcommand{\sech}[0]{\mathrm{sech}\ }
\newcommand{\prob}[0]{\mathbb{P}}
\newcommand{\nats}[0]{\mathbb{N}}
\newcommand{\cov}[0]{\mathrm{Cov}}
\newcommand{\var}[0]{\mathrm{Var}}
\newcommand{\expect}[0]{\mathbb{E}}
\newcommand{\reals}[0]{\mathbb{R}}
\newcommand{\integers}[0]{\mathbb{Z}}
\newcommand{\indicator}[0]{\mathds{1}}
\newcommand{\nb}[0]{\textit{N.B.} }
\newcommand{\ie}[0]{\textit{i.e.} }
\newcommand{\eg}[0]{\textit{e.g.} }
\newcommand{\X}[0]{\textbf{X}}
\newcommand{\x}[0]{\textbf{x}}
\newcommand{\iid}[0]{\overset{\text{iid}}{\sim}}
\newcommand{\proved}[0]{$\hfill\square$\\}
\newcommand{\argmin}[0]{\text{argmin}}
\newcommand{\argmax}[0]{\text{argmax}}

\newcommand{\definition}[1]{\stepcounter{definition} \textbf{Definition \arabic{section}.\arabic{definition}\ - }\textit{#1}\\}
\newcommand{\definitionn}[1]{\stepcounter{definition} \textbf{Definition \arabic{section}.\arabic{definition}\ - }\textit{#1}}
\newcommand{\proof}[1]{\stepcounter{proof} \textbf{Proof \arabic{section}.\arabic{proof}\ - }\textit{#1}\\}
\newcommand{\prooff}[1]{\stepcounter{proof} \textbf{Proof \arabic{section}.\arabic{proof}\ - }\textit{#1}}
\newcommand{\example}[1]{\stepcounter{example} \textbf{Example \arabic{section}.\arabic{example}\ - }\textit{#1}\\}
\newcommand{\examplee}[1]{\stepcounter{example} \textbf{Example \arabic{section}.\arabic{example}\ - }\textit{#1}}
\newcommand{\notation}[1]{\stepcounter{notation} \textbf{Notation \arabic{section}.\arabic{notation}\ - }\textit{#1}\\}
\newcommand{\notationn}[1]{\stepcounter{notation} \textbf{Notation \arabic{section}.\arabic{notation}\ - }\textit{#1}}
\newcommand{\proposition}[1]{\stepcounter{proposition} \textbf{Proposition \arabic{section}.\arabic{proposition}\ - }\textit{#1}\\}
\newcommand{\propositionn}[1]{\stepcounter{proposition} \textbf{Proposition \arabic{section}.\arabic{proposition}\ - }\textit{#1}}
\newcommand{\remark}[1]{\stepcounter{remark} \textbf{Remark \arabic{section}.\arabic{remark}\ - }\textit{#1}\\}
\newcommand{\remarkk}[1]{\stepcounter{remark} \textbf{Remark \arabic{section}.\arabic{remark}\ - }\textit{#1}}
\newcommand{\theorem}[1]{\stepcounter{theorem} \textbf{Theorem \arabic{section}.\arabic{theorem}\ - }\textit{#1}\\}
\newcommand{\theoremm}[1]{\stepcounter{theorem} \textbf{Theorem \arabic{section}.\arabic{theorem}\ - }\textit{#1}}
TODO - JAGS \& RJAGS

\tableofcontents

% Start of content
\newpage

\section{General}

\subsection{Approaches to Inference}

\definition{Statistical Inference}
\textit{Statistical Inference} is the process of taking some data and infering a property of the world from it. This is done by theorising a \textit{Statistical Model} which may have generated the data and then calculating parameters for it from the data.\\

\definition{Statistical Model}
\textit{Statistical Models} are a, simplified, mathematical description for how a set of data could have been generated. In particular, a \textit{Statistical Model} describes the random variability in the data generating process.\\

\definition{Frequentist Inference}
The \textit{Frequentist Approach} to \textit{Statistical Inference} treats model unknowns (paramters or functions) as fixed states of nature whose values we want to estimate.\\
There is no modelling of random variability and thus any that occurs during data collection will be inherited by the model.\\

\remark{Frequentist Inference}
Often in \textit{Frequentist Inference} we use \textit{asymptotic results} which only become exact as the sample size tends to infty. This has practical drawbacks.\\

\definition{Bayesian Inference}
The \textit{Bayesian Approach} to \textit{Statistical Inference} treats unknown model parameters as random variables. We define our initial uncertainty about parameter values (the \textit{Prior Distribution}, $\prob(\Theta)$), observed data is used to update these distributions in order to reach a \text{\textit{Posterior Distribution}}, $\prob(\Theta|X)$.\\
\nb This is done by using \textit{Bayes' Theorem}.\\

\remark{Bayesian Inference}
Often in \textit{Bayesian Inference} we use \textit{simulation methods}, which only become exact as the sample size tends to infty. Again, there are practical drawbacks to this.\\

\remark{Statistical Design}
When trying to infer a model from data there are a few common questions we ask
\begin{enumerate}
	\item What range of parameter values are consistent with the data?
	\item Which of several alternative models could most plausibly have generated the data?
	\item Could our model have generate the data at all?
	\item How coudl we better arrange the data gatehering process to improve the ansers to the preceeding questions?
\end{enumerate}

\subsection{Models}

\definition{Nested Models}
Let $\X_1\sim f_1(\cdot;\pmb\theta_1),\ \X_2\sim f_2(\cdot;\pmb\theta_2)$ for $\pmb\theta_1,\pmb\theta_2\in\pmb\Theta_1$.\\
If $\pmb\theta_1\subset\pmb\theta_2$ then $\X_1$ is \textit{Nested} in $\X_2$.\\

\definition{Predictor Variables}
\textit{Predictor Variables} are the dependent variables of a system, whose values we observe.\\
\nb Typically denoted $\x$ or $\X$.\\

\definition{Metric}
\textit{Metrics} are \textit{Predictor Variables} which measure an explict quantity.\\

\definition{Factor}
\textit{Factors} are \textit{Predictor Variables} which act as labels to whether an observation belongs in a particular class due a property which cannot be explicitly quantified. (\eg Male or Female).\\

\definition{Response Variables}
\textit{Response Variables} are the \underline{in}dependent variables of a system, whose value we observe.\\
\nb Typically denoted $y$ or $\textbf{y}$.\\

\definition{Fitted Values, $\hat{y}$}
\textit{Fitted Values} are our estimated values for the \textit{Response Variable}.
$$\hat{y}_i:=f(\x_i)$$

\definition{Regular Models}
Let $\X\sim f(\cdot;\pmb\theta)$ for $\pmb\theta\in\pmb\Theta$ be a \textit{Statistical Model}.\\
A \textit{Statistical Model} is deemed \textit{Regular} if it fulfils all the following:
\begin{enumerate}
	\item Densities for distinct $\pmb\theta$ are distinct.\\
	\nb If not, parameters won't be identifiable \& thus no guaranteed consistency.
	\item $\pmb\theta^*\in\pmb\Theta$.\\
	\nb Otherwise we cannot approximat \textit{Log-Likelihood} by \textit{Taylor Expansion} in the region of $\pmb\theta^*$.
	\item Within some neighbourhood of $\pmb\theta^*$
	\begin{itemize}
		\item The first three derivatives of the \textit{Log-Likelihood} exist \& are bounded.
		\item $\mathcal{I}:=\expect\left(\dfrac{\partial\ell}{\partial\pmb\theta}\bigg|_{\theta^*}\dfrac{\partial\ell}{\partial\pmb\theta^T}\bigg|_{\theta^*}\right)\equiv-\expect\left(\dfrac{\partial^2\ell}{\partial\pmb\theta\pmb\theta^T}\bigg|_{\theta^*}\right)$ is satisfied.
		\item The \textit{Fisher Information Matrix}, $\mathcal{I}$, is positive-definite \& finite.
	\end{itemize}
\end{enumerate}
\nb These requirements are required for certain results.

\subsection{Graphical Models}
%TODO 10

\definition{Directed Acyclic Graphs}
A \textit{Directed Acyclic Graph}, DAG, is a graph which consists of directed edges and \underline{no} cycles.\\
The direction of edges show dependence with the target element being dependent on the origin element.\\

\proposition{Graphical Model}
A \textit{Model} can be represented graphically using a \textit{Directed Acyclic Graph} with variables for nodes \& dependence from the edges.\\
The distribution of a variable is completely known \underline{if} you know the values of all its parent nodes.\\
The nodes in a \textit{Graphical Model} take three types
\begin{enumerate}
	\item \textit{Stocastic Nodes} are variables with a distribution which depends stochastically on otehr nodes.\\
These can be observed or unobserved.
	\item \textit{Deterministic Nodes} are nodes that are deterministic functions of other nodes.\\
They cannot be observed.
	\item \textit{Constant Nodes} are fixed numbers and have no parents.
\end{enumerate}
The edges in a \textit{Graphical Model} show one of two relationship types
\begin{enumerate}
	\item \textit{Deterministic Relationship} between nodes (usually a dashed arrow).
	\item \textit{Stochastic Relationship} between nodes (usually a solid arrow).
\end{enumerate}

\examplee{Graphic Model}
\begin{center}
	\begin{tikzpicture}
		\node[circleStyle] (l1) at (0,0) {$\lambda_1$};
		\node[circleStyle] (a1) at (0,-1) {$\alpha_1$};
		\node[circleStyle] (l2) at (0,-2) {$\lambda_2$};
		\node[circleStyle] (a2) at (0,-3) {$\alpha_2$};

		\node[circleStyle] (K) at (2,-.5) {$K$};
		\node[circleStyle] (r) at (2,-2.5) {$r$};

		\node[circleStyle] (mu) at (4,-1.5) {$\mu$};

		\node[circleStyle] (yt) at (6,-1.5) {$y_t$};

		\node[circleStyle] (s2) at (8,-1.5) {$\sigma^2$};

		\node[circleStyle] (l3) at (10,-1) {$\lambda_3$};
		\node[circleStyle] (a3) at (10,-2) {$\alpha_3$};


		\path[->] (l1) edge (K);
		\path[->] (a1) edge (K);
		\path[->] (l2) edge (r);
		\path[->] (a2) edge (r);

		\path[dashed,->] (K) edge (mu);
		\path[dashed,->] (r) edge (mu);

		\path[->] (mu) edge (yt);
		\path[->] (s2) edge (yt);

		\path[->] (l3) edge (s2);
		\path[->] (a3) edge (s2);

	\end{tikzpicture}
\end{center}
The plot above is a DAG for a model where $y_t\sim f(\sigma^2,\mu)$, $\mu=g(K,r)$ and we assume priors of $K,r,\sigma^2\sim h(\alpha_j,\lambda_j)$ (typically gamma). The lines from $K$ and $r$ to $\mu$ is dashed because $g(\cdot,\cdot)$ is a deterministic function (\eg $g(K,r)=Ke^r$) whereas the other relationships are stochastic (\ie $f$ and $h$ are pdfs).\\

\proposition{Distributions from Graphical Model}
Let $x_i$ represent the variable associated with the $i^\text{th}$ node in the graph.\\
We have joint distribution of the \underline{non-constant} nodes
$$f(\x)=\prod_if(x_i|\text{Parent}(x_i))$$

\subsection{Inference by Mathmetical Manipulation}

% Bayesian & Frequentist use computation
% Simulation

\remark{Inference by Mathematical Manipulation}
\textit{Bayesian} and \textit{Frequentist Inference} use mathetmatical computaiton to make inferences about parameter valus \& their uncertainty. An alternative approach is to use mathematical manipulation, rather than computation.\\

\definition{Bootstrapping}
Let $X$ be a set of observed data.\\
\textit{Bootstrapping} is a \textit{simulation} of the data gathering process.\\
In \textit{Bootstrapping} we uniformly sample values from $X$ \underline{with replacement} until we reach a desired sample size (often $|X|$).\\

\proposition{Inference by Resampling}
Once we have used \textit{Bootstrapping} to generate a set of new data-sets we can use \textit{Bayesian} \& \textit{Frequentist Inference} techniques in order to estimate parameter values.\\

\remark{Bootstrap Interval}
An \textit{Interval} generated from \textit{Bootstrapping} datasets are generally narrower than those produced by \textit{Bayesian} or \textit{Frequentist Approaches}.\\
\nb This discrepancy is reduced as sample size increases.\\

\proposition{Bootstrap Percentiles}
When wishing to create an interval for $\theta$ using \textit{Bootstrapped} data, we treat the $\hat\theta$ values as if they came from $\prob(\theta|\X)$.

\subsection{Causality}

\definition{Causality}
\textit{Causality} is a relationship between two events where one of the events caused the other.\\

\definition{Correlation}
\textit{Correlation} is a relationship between two events where the events are likely to occur together. This does not mean that one event has caused the other, but they may have been caused by the same variable (which may be hidden).\\

\remark{When two variables are highly correlated it is hard to distinguish their effects}

\definition{Counfounding Variable}
A \textit{Confounding Variable} is a variable which influences both the \textit{Predictor} \& \textit{Response Variables} in a system.\\
Suppose $x,h$ are highly-correlated and $y=\beta_0+\beta_1x$. The model $y=\beta_2+\beta_3h$ would appear statistically good even though $h$ had no part in geneating $y$. Here $x$ is the \textit{Confounding Variable}.\\
\nb AKA \textit{Hidden Variables}

\subsubsection{Controlled Experiments}

\definition{Randomisation}
\textit{Randomisatiation} is a technique used when designing experiments to break relationships between \textit{Confounder Variables} and our \textit{Response Variable}.\\
\textit{Randomisation} involves taking a set of subjects and randomly assigning them to different ``treatments".\\
Provided these treaments only vary the \textit{Predictor Variable} we wish to test, this breaks association between other \textit{Prectior Variables} \& our \textit{Response Variable}. Making these \textit{Predictor Variables} now part of the ranom variability of the model, $\varepsilon$.\\

\remark{Randomisation is the Gold Standard for Inferring Causation}

\proposition{Mathematical Justification}
Consider model matrix $(\X,\textbf{H})$ where $\X$ is formed from observed \textit{Predictor Variables} \& $\textbf{H}$ is from \textit{Confounding Variables} (\nb we would not know its value in practice).\\
Assume the oolumns of $\textbf{H}$ are centred on 0.\\
We now have \textit{Least Squares Estimate} for the parameters of
$$\begin{pmatrix}\tilde{\pmb\beta}_X\\\tilde{\pmb\beta}_H\end{pmatrix}=\begin{pmatrix}\X^T\X&\X^T\textbf{H}\\\textbf{H}^T\X&\textbf{H}^T\textbf{H}\end{pmatrix}^{-1}\begin{pmatrix}\X^T\\\textbf{H}^T\end{pmatrix}\textbf{y}$$
If $\X,\textbf{H}$ are dependent on each other then $\X^T\textbf{H}\neq\pmb0\implies\tilde{\pmb\beta}_X\neq(\X^T\X)^{-1}\X^T\textbf{y}=\hat{\pmb\beta}_X$.\\
If $\X,\textbf{H}$ are \underline{independent} of each other then $\X^T\textbf{H}=\pmb0$, for a large sample size,\\
$\implies\tilde{\pmb\beta}_X=(\X^T\X)^{-1}\X^T\textbf{y}=\hat{\pmb\beta}_X$.\\
\nb \textit{Randomisation} ensures $\X$ and $\textbf{H}$ are independent.

\subsubsection{Instrumental Variables}

\remark{Motivation}
In some scenarios it is impractical or unethical to perform randomised experiments.\\

\definition{Instrumental Variables}
Let $(\X,\textbf{H})$ be a \textit{Model Matrix} with $\X$ observed \& $\textbf{H}$ confounding for our \textit{Response Variable}, $\textbf{y}$.\\
A variable is an \textit{Instrumental Variable} if
\begin{itemize}
	\item It is \underline{not} part of the true model of the \textbf{Response Variable};
	\item It \underline{is} correlated with the \textit{Predictor Variables} in $\X$;
	\item[And,] It is \underline{not} correlated with the \textit{Confounding Variables} in $\textbf{H}$.
\end{itemize}

\remark{Finding Instrumental Variables is Hard, very!}

\proof{Confounding Variables affect Least Squares Estimate in Linear Models}
Let $(\X,\textbf{H})$ be a \textit{Model Matrix} where $\X$ comes from some observed variables \& $\textbf{H}$ is from \textit{Confounding Variables}.\\
This means the true model is of the form
$$\textbf{y}=\X\pmb\beta_X+\textbf{H}\pmb\beta_H+\pmb\varepsilon$$
Since we only know $\X$ we try to fit $\textbf{y}=\X\pmb\beta_X+\textbf{e}$.\\
Effectively $\textbf{e}=\textbf{H}\pmb\beta_H+\pmb\varepsilon$, which is unlikey to fulfil the assumptions of indepdence \& constant variance.\\
This is a problem for the model. Further
\[\begin{array}{rcl}
\expect(\hat{\pmb\beta}_X)&=&(\X^T\X)^{-1}\X^T(\X,\textbf{H})\pmb\beta\\
&=&(\X^T\X)^{-1}\X^T\X\pmb\beta_X+(\X^T\X)^{-1}\X^T\textbf{H}\pmb\beta_H\\
&=&\pmb\beta_X+(\X^T\X)^{-1}\X^T\textbf{H}\pmb\beta_H\\
&\neq&\pmb\beta_X
\end{array}\]
\nb The space spanned by the columns of $\X$ is not orthogonal to $\textbf{e}$.\\

\proposition{Instrumental Variables for Linear Models}
Let $(\X,\textbf{H})$ be a \textit{Model Matrix} where $\X$ comes from some observed variables \& $\textbf{H}$ is from \textit{Confounding Variables}.\\
Let $\textbf{Z}$ be the \textit{Model Matrix} for some \textit{Instrumental Variables}.\\
We assume $\text{Rank}(\textbf{Z})\geq\text{Rank}(\X)$.\\
Perform the projection of $\X$ onto the column space of $\textbf{Z}$. Giving
$$\X_Z:=\textbf{Z}(\textbf{Z}^T\textbf{Z})^{-1}\textbf{Z}^T\X=\textbf{A}_Z\X$$
This gives us the least squares estimate of the model parameters
$$\hat{\pmb\beta}_X=(\X_Z^T\X_Z)^{-1}\X_Z^T\textbf{y}=(\X^T\textbf{A}_Z\X)^{-1}\X^T\textbf{A}_Z\textbf{y}$$
Since $\textbf{Z}$ is independent of $\textbf{H}$. $\textbf{Z}^T\textbf{H}\simeq\pmb0\implies\textbf{A}_Z\textbf{H}\simeq\pmb0$. Thus
\[\begin{array}{rcl}
\expect(\hat{\pmb\beta}_X)&=&(\X^T\textbf{A}_Z\X)^{-1}\X^TA_Z(\X,\textbf{H})\pmb\beta\\
&=&(\X\textbf{A}_Z\X)^{-1}\X^T\textbf{A}_Z\X\pmb\beta_X+\underbrace{(\X\textbf{A}_Z\X)^{-1}\X^T\underbrace{\textbf{A}_Z}_{\simeq0}\textbf{H}\pmb\beta_H}_{\simeq0}\\
&=&(\X\textbf{A}_Z\X)^{-1}\X^T\textbf{A}_Z\X\pmb\beta_X\\
&=&\pmb\beta_X
\end{array}\]
This shows the estimate produced by using \textit{Instrumental Variables} produces a much more accurate estimate of the model parameters, than when they are not used \& \textit{Convolution Variables} exist.

\subsection{Hypothesis Testing}

\remark{Hypothesis Testing is \underline{mostly} a Frequentist method, not Bayesian.}

\remark{Hyphothesis Testing amounts to choosing the simplist model which has no obvious incosistencies with the data}

\definition{Simple Hypothesis}
A \textit{Simple Hypothesis} states that a parameter takes an \underline{exact} value.\\
\ie $\theta=\theta_0$ for $\theta_0\in\Theta$.\\

\definition{Composite Hypothesis}
A \textit{Composite Hypothesis} states that a parameter takes a value from a set.\\
\ie $\theta\in\Theta_0$ for $\Theta_0\subseteq\Theta$.\\

\definition{Test Statistic}
A \textit{Test Statistic} is a random variable whose value depends on the observed set of data.\\
\textit{Test Statistics} are used to assess the likelihood of observing a certain data set under a given \textit{Null Hypothesis} in \textit{Hypothesis Testing}.\\

\definition{$p$-Value}
\textit{$p$-Value} measures the goodness of fit of statistical models.\\
The \textit{$p$-Value} is the probability of observing more extreme that the data used for fitting, under the theorised model, $\pmb\Theta_0$.\\
Let $\X\sim f(\cdot;\pmb\theta)$ and $\x$ be a realisation.
$$p(\x):=\sup_{\theta\in\Theta_0}\prob(\X\geq \x;\pmb\theta)=\sup_{\theta\in\Theta_0}f(\textbf{x};\pmb\theta)$$
A higher \textit{$p$-Value} suggests a better model fit.\\

\remark{$p$-Values are good at testing the fit of a model, but not at comparing the relative fit of two models}

\remark{$p(\x)$ is the smallest Significance Level at which we would reject the \text{Null Hypothesis}}

\definition{Hypothesis Testing}
\textit{Hypothesis Testing} is the porcess of determining which of two hypotheses about model parameters is more consistent with the data.\\
We define a \textit{Null Hypothesis} and an \textit{Alternative Hypothesis}. The \textit{Null Hypothesis} acts as our default position, and we only reject it is if the observed data is too extreme (given that it is true).\\
\nb \textit{Null} and \textit{Alternative Hypothesis} are mutually exclusive.\\

\proposition{Process for Hypothesis Testing}
Let $\x$ be a realisation of $\X$
\begin{enumerate}
	\item Choose a model $f(\cdot;\theta)$ st $\X\sim f(\cdot;\theta)$ for $\theta\in\Theta$.
	\item Define a \textit{Null Hypothesis}, $H_0$, and an \textit{Alternative Hypothesis}, $H_1$.
	\item Define a \textit{Test Statistic}, $T(\cdot)$.
	\item Choose a \textit{Significance Level}, $\alpha$, and calculate the equivalent \textit{Critical Value}, $c$, for the \textit{Test Statistic}.
	\item Calculate value of the \textit{Test Statistic} under the observed data, $t_\text{obs}=T(\x)$.
	\item If $t_\text{obs}\geq c$ then reject $H_0$ in favour of $H_1$, otherwise accept $H_0$.
\end{enumerate}

\definition{Neymann-Pearson Test Statistic}
The \textit{Neymann-Pearson Test Statistic} is a generalisation of the \textit{Likelihood Ratio}.\\
It measures the likelihood of the \textit{Alternative Hypothesis} being correct, relative to the \textit{Null Hypothesis}, given the data.\\
Let $\X\sim f(\cdot;\pmb\theta)$, $\x$ be a realisation of $\X$ and $H_0:\pmb\theta\in\pmb\Theta_0$ be our \textit{Null Hypothesis}.
$$T_{np}(\x):=\dfrac{p(\x;\pmb\Theta)}{p(\x;\pmb\Theta_0)}=\dfrac{\sup_{\theta\in\Theta} f(\x;\pmb\theta)}{\sup_{\theta_0\in\Theta_0}f(\x;\pmb\theta_0)}=\dfrac{f(\x;\hat{\pmb\theta}_\text{MLE})}{\sup_{\theta_0\in\Theta_0}f(\x;\pmb\theta_0)}\geq1$$
Lower values of the \textit{Likelihood Ratio} indicate that $H_0$ is more likely to be true.\\

\definition{Power Function, $\pi$}
The \textit{Power Function}, $\pi(\cdot)$, measures the probability of rejecting the \textit{Null-Hypothesis} given that another set of parameter values is true (usually test with the \textit{Alternative Hypothesis}).\\
Let $\X\sim f(\cdot;\theta)$, $T(\cdot)$ be a \textit{Test Statistic} and $c$ be the \textit{Critical Value} of $T$. Then
$$\pi(\theta_1;T,c)=\prob(T(\X)\geq c;\theta_1)$$

\theorem{Neyman-Pearson Lemma}
\textit{NON-EXAMINABLE}.\\
Let $\X\sim f(\cdot;\pmb\theta)$ and $\x$ be a realisation of $\x$.\\
Consider testing two \textit{Simple Hypothese} with the \textit{Neyman Pearson Test Statistic}.\\
Choose some $\alpha\in[0,1]$ and find $c_{NP}$ st $\alpha=\prob(T_{NP}\geq c_{NP};\pmb\theta_0)$.\\
Then the test $(T_{NP},c_{NP})$ is equivalent to the uniformly most powerful test.\\

\definition{Generalised Likelihood Ratio Test Statistic}
\textit{JUST NEED TO KNOW RESULT}.\\
Let $\X\sim f(\cdot;\pmb\theta)$ be a model \& $\x$ be a realisation of $\X$.\\
Consider testing two, \underline{nested}, hypotheses
$$H_0:\textbf{R}(\pmb\theta)=\pmb0\quad\text{against}\quad H_1:\textbf{R}(\pmb\theta)\neq\pmb0$$
where $\textbf{R}(\cdot)$ is a vector-valued function of $\pmb\theta$ st $H_0$ imposes $r$ restrictions on $\pmb\Theta$.\\
The \textit{Generalised Likelihood Ratio Test Statistic} is defined as
$$T_{GLR}:=2[\ell(\hat{\pmb\theta}_\text{MLE})-\sup_{\textbf{R}(\pmb\theta)=\pmb0}\ell(\pmb\theta)]\sim\chi^2_r$$

\subsection{Intervals}

\definition{Random Interval}
Let $\X\sim f_n(\cdot;\theta^*)$ for $\theta^*\in\Theta$ and $L,U:\mathcal{X}^n\to\Theta$ st $\forall\ \x\in\mathcal{X}^n\ L(\x)<U(\x)$.\\
A \textit{Random Interval} is an \textit{Interval} whose bounds depends on a \textit{Random Variable}.\\
Here $\mathcal{I}(\X):=[L(\X),U(\X)]$ is a \textit{Random Interval}.\\
\nb $L(\cdot)$ \& $U(\cdot)$ are maps from observed data to parameter values.\\

\definition{Coverage of an Interval}
Let $\mathcal{I}(\X):=[L(\X),U(\X)]$ be a \textit{Random Interval} for $\theta$ with true value $\theta^*$.\\
The \textit{Coverage of an Interval} is the probability that the true value of the parameter it is estimating lies in the inverval.
$$C_\mathcal{I}=\prob(\theta^*\in\mathcal{I}(\X);\theta^*)$$

\definition{Confidence Interval}
A $1-\alpha$ \textit{Confidence Interval} for a parameter is an interval with \textit{Coverage} at least $1-\alpha$.
\begin{center}
$\mathcal{I}(\X):=[L(\X),U(\X)]$ is a $1-\alpha$ \textit{Confidence Interval} if $\prob(\theta^*\in\mathcal{I})\geq1-\alpha$
\end{center}
\nb If $\prob(\theta^*\in\mathcal{I}(\X))=1-\alpha$ then $\mathcal{I}$ is an \textit{\underline{Exact} Confidence Interval}.\\

\remark{Confidence Intervals are a part of Frequentist Statistics, not Bayesian}

\definition{Credible Interval}
Let $\X\sim f(\cdot;\pmb\theta)$ and $\x$ be a realisation of $\X$.\\
A $1-\alpha$ \textit{Credible Interval} is as an interval $(\theta_1,\theta_2)$ where the probability that the true parameter lies in the parameter is $1-\alpha$.
$$1-\alpha=\prob(\theta^*\in(\theta_1,\theta_2)\Longleftrightarrow\int^{\theta_1}_{\theta_2}p(\theta|\theta)d\theta=1-\alpha$$
When the model has multiple parameters we find a different intervval for each parameter.\\
\nb Multiple such intervals will exist and we find these intervals by sampling.\\

\remark{Credible Intervals are a part of Bayesian Statistics, not Frequentist}

\definition{Test Inversion}
\textit{Test Inversion} is the process of finding a \textit{Confidence Interval/Set} by finding the range of values which would cause the \textit{Null Hypothesis} to be accepted.\\
\nb AKA \textit{Wilk's Intervals}.\\

\propositionn{\text{Every value in a Wilk's Interval has a greater likelihood than any value outside.}}


\subsection{Other ways of Assessing Fit}

\definition{Residual}
The \textit{Residual} is the difference between the true value of the \textit{Response Variables} \& our \textit{Fitted Values}.
$$\epsilon:=|y_i-\hat{y}_i|$$

\definition{Residual Sum of Squares}
The \textit{Residual Sum of Squares} is the sum of the squared value of the \textit{Residuals} for each observation.\\
The \textit{RSS} is used as a measure for how well our model fits the data
$$RSS:=\sum_{i=1}^N\epsilon_i^2=\sum_{i=1}^N(y_i-\hat{y}_i)^2=\|\textbf{y}-\hat{\textbf{y}}\|^2$$

\remark{More complicated models tend to have greater likelihood}
whether or not the extra complications reflect anything in the true data generating process.\\

\definition{Kullback-Leibler Divergence}
\textit{Kullback-Leibler Divergence} is a measure of how similar two models are.\\
Let $f(\cdot)$ be the true model \& $g(\cdot)$ be an approximation.
$$KL(f,g)=\int[\ln f(\textbf{y})-\ln g(\textbf{y})]f(\textbf{y})d\textbf{y}$$
\nb This is a measure of information loss caused by $g(\cdot)$.\\

\proposition{Testing Models with KL Divergence}
Let $f$ be a proposed model with true parameters values $\pmb\theta^*$.\\
To compare a proposed set of parameters, $\pmb\theta$, we want to calculate
$$KL(f^*,f_\theta)=\int[\ln f(\textbf{y};\pmb\theta^*)-\ln f(\textbf{y};\pmb\theta)]f(\textbf{y};\pmb\theta^*)d\textbf{y}$$
\nb This is not tractable since $f^*$ is unknown (otherwise we would use it).\\

\definition{Akaike's Information Criterion}
\textit{Akaike's Information Criterion}, AIC, is a goodness-of-fit measure for models.
$$AIC(\pmb\theta)=-2\ell(\pmb\theta)+2p$$
where $p:=|\pmb\theta|$ (the number of estimated parameters).\\
Lower \textit{AIC} values indicate better fit.\\
\nb The factor of $2$ is to put \textit{AIC} on the scale as the $T_{GLR}$.\\

\remark{AIC is non-consistent.}
As $n\to\infty$ the probability of choosing the correct model does not tend to 1.\\

\proposition{Using KL Divergence}
Let $f$ be a proposed model with true parameters $\pmb\theta^*$.\\
We want to find the set of parameters, $\hat{\pmb\theta}$, which perform closely to the true values.\\
\ie $\argmin_{\hat{\pmb\theta}}KL(f_{\hat\theta},f^*)$ where $f_{\hat\theta}:=f(\cdot;\hat{\pmb\theta})$ \& $f^*:=f(\cdot;\pmb\theta^*)$.\\
It turns out that $\expect(KL(f_{\hat\theta_\text{MLE}},f^*))$ is tractable.
$$\hat\expect(KL(f_{\hat\theta_\text{MLE}},f^*))=-\ell(\pmb\theta_\text{MLE})+p+\int\ell(\pmb\theta^*;\textbf{y})f(\textbf{y};\pmb\theta^*)d\textbf{y}$$
Where $p:=|\pmb\theta|$ (the number of estimaed parameters).\\
Note that this involves the true parameter value, thus is minised by whichever model minimises \textit{Akaike's Information Criterion}.\\
%TODO derivation (done on paper)

\proof{$\hat\expect(KL(f_{\hat\theta_\text{MLE}},f^*))=-\ell(\pmb\theta_\text{MLE})+p+\int\ell(\pmb\theta^*;\textbf{y})f(\textbf{y};\pmb\theta^*)d\textbf{y}$}
Define $\pmb\theta_{KL}:=\argmin_{\pmb\theta}KL(f_{\theta},f^*)$, the parameters which minimise \textit{KL Divergence}.\\
By \textit{Taylor's Theorem}
\[\begin{array}{rrcl}
&\ln f_{\hat\theta_\text{MLE}}(\textbf{y})&\simeq&\ln f_{\theta_{KL}}(\textbf{y})+(\hat{\pmb\theta}_\text{MLE}-\pmb\theta_{KL})^T\dfrac{\partial\ln f_\theta}{\partial\theta}\bigg|_{\theta_{KL}}\\
&&+&\dfrac12(\hat{\pmb\theta}_\text{MLE}-\pmb\theta_{KL})^T\dfrac{\partial^2\ln f_\theta}{\partial\theta\partial\theta^T}\bigg|_{\theta_{KL}}(\hat{\pmb\theta}_\text{MLE}-\pmb\theta_{KL})\\
\implies&KL(f_{\hat\theta_\text{MLE}},f^*)&\simeq&\displaystyle\int\ln f^*(\textbf{y})-f^*(\textbf{y})\bigg[\ln f_{\theta_{KL}}(\textbf{y})+(\hat{\pmb\theta}_\text{MLE}-\pmb\theta_{KL})^T\dfrac{\partial\ln f_\theta}{\partial\theta}\bigg|_{\theta_{KL}}\\
&&+&\frac12(\hat{\pmb\theta}_\text{MLE}-\pmb\theta_{KL})^T\dfrac{\partial^2\ln f_\theta}{\partial\theta\partial\theta^T}(\hat{\pmb\theta}_\text{MLE}-\pmb\theta_K)\bigg]d\textbf{y}\\
&&=&\displaystyle\int\ln f^*(\textbf{y})-f^*(\textbf{y})\ln f_{\theta_{KL}}(\textbf{y})+(\hat{\pmb\theta}_\text{MLE}-\pmb\theta_K)^T\underbrace{\dfrac{\partial \ln f_\theta}{\partial\theta}\bigg|_{\theta_{KL}}f^*(\textbf{y})}_{=0\text{ since }\theta_{KL}\text{ minimises}}\\
&&+&\dfrac12f^*(\textbf{y})(\hat{\pmb\theta}_\text{MLE}-\pmb\theta_{KL})^T\dfrac{\partial^2\ln f_\theta}{\partial\theta\partial\theta^T}\bigg|_{\theta_{KL}}(\hat{\pmb\theta}_\text{MLE}-\pmb\theta_{KL})^Td\textbf{y}\\
&&=&\displaystyle\int\ln f^*(\textbf{y})-f^*(\textbf{y})\ln f_{\theta_{KL}}(\textbf{y})+(\hat{\pmb\theta}_\text{MLE}-\pmb\theta_K)^T\\
&&+&\dfrac12f^*(\textbf{y})(\hat{\pmb\theta}_\text{MLE}-\pmb\theta_{KL})^T\dfrac{\partial^2\ln f_\theta}{\partial\theta\partial\theta^T}\bigg|_{\theta_{KL}}(\hat{\pmb\theta}_\text{MLE}-\pmb\theta_{KL})^Td\textbf{y}\\
&&=&KL(f_{\theta_{KL}},f^*)+\displaystyle\int\dfrac12(\hat{\pmb\theta}_\text{MLE}-\pmb\theta_{KL})^T\dfrac{\partial^2\ln f_\theta}{\partial\theta\partial\theta^T}\bigg|_{\theta_{KL}}(\hat{\pmb\theta}_\text{MLE}-\pmb\theta_{KL})f^*(\textbf{y})d\textbf{y}\\
&&=&KL(f_{\theta_{KL}},f^*)+\frac12(\hat{\pmb\theta}_\text{MLE}-\pmb\theta_{KL})^T\mathcal{I}_{\theta_{KL}}(\hat{\pmb\theta}_\text{MLE}-\pmb\theta_{KL})
\end{array}\]
where $\mathcal{I}_{\theta_{KL}}:=\expect\left(\frac{\partial\ell}{\partial\theta\partial\theta^T}\bigg|_{\theta=\theta^*}\right)$ (Fisher Information Matrix).\\
Assuming the model, $f$, is sufficiently regular then for large $n$
$$\expect(\hat{\pmb\theta}_\text{MLE})\simeq\pmb\theta_{KL}\ \&\ \cov(\hat{\pmb\theta}_{MLE})\simeq\mathcal{I}_{\theta_{KL}}$$
Since $2[\ell(\hat{\pmb\theta}_{MLE}-\ell(\hat{\pmb\theta}_0]\sim\chi^2_r$ we have
\[\begin{array}{rrcll}
&\expect[\ell(\hat{\pmb\theta}_{MLE}-\ell(\hat{\pmb\theta}_0]&\simeq&\expect\left(\frac12(\hat{\pmb\theta}-\pmb\theta_{KL})\mathcal{I}_{\theta_{KL}}(\hat{\pmb\theta}_{MLE}-\pmb\theta_{KL}\right)\\
&&=&\frac{p}2\text{ where }p:=|\pmb\theta|\text{ by result at end of 8.6}&(1)\\
\implies&\expect(KL(f_{\hat\theta_{MLE}},f^*))&\simeq&KL(f_{\theta_{KL}},f^*)+\frac{p}2&(2)
\end{array}\]
This still contains the true value, which is unknown.\\
We have
\[\begin{array}{rcll}
\expect(-\ell(\hat{\pmb\theta}_{MLE}))&=&\expect(-\ell(\hat{\pmb\theta}_{MLE})+\ell(\pmb\theta_{KL})-\ell(\pmb\theta_{KL}))\\
&=&\expect(-\ell(\pmb\theta_{KL})-\{\ell(\hat{\pmb\theta}_{MLE})-\ell(\pmb\theta_{KL})\})\\
&=&-\expect(\ell(\pmb\theta_{KL}))-\expect(\ell(\hat{\pmb\theta}_{MLE})-\ell(\pmb\theta_{KL}))\\
&\simeq&-\underbrace{\int\ell(\pmb\theta_{KL})f^*(\textbf{y})d\textbf{y}}_\text{by def of $\expect$}-\underbrace{\frac{p}2}_\text{by (1)}\\
\text{Further}&=&-\displaystyle\int\ell(\pmb\theta_{KL})f^*(\textbf{y})d\textbf{y}-\frac{p}2+\int\ell(\pmb\theta^*)f^*(\textbf{y})d\textbf{y}-\int\ell(\pmb\theta^*)f^*(\textbf{y})d\textbf{y}\\
&=&\displaystyle\int[\ell(\pmb\theta^*)-\ell(\pmb\theta_{KL})]f^*(\textbf{y})d\textbf{y}-\int\ell(\pmb\theta^*)f^*(\textbf{y})d\textbf{y}-\frac{p}2\\
&=&\underbrace{KL(f_{\theta_{KL}},f^*)}_\text{by def of KL}-\displaystyle\int\ell(\pmb\theta^*)f^*(\textbf{y})d\textbf{y}-\frac{p}2
\end{array}\]
By rearranging the final result
\[\begin{array}{rcll}
KL(f_{\theta_{KL}},f^*)&=&\displaystyle\int\ell(\pmb\theta^*)f^*(\textbf{y})d\textbf{y}+\frac{p}2+\expect(-\ell(\hat{\pmb\theta}_{MLE}))\\
&=&\displaystyle\int\ell(\pmb\theta^*)f^*(\textbf{y})d\textbf{y}+\frac{p}2-\ell(\hat{\pmb\theta}_{MLE})&(3)
\end{array}\]
Thus
$$\expect(KL(f_{\hat\theta_{MLE}},f^*)\simeq\int\ell(\pmb\theta^*)f^*(\textbf{y})d\textbf{y}+p-\ell(\hat{\pmb\theta}_{MLE})\text{ by substitution (3) into (2)}$$
\nb $f_{\theta}:=f(\cdot;\pmb\theta)$ \& $f^*:=f(\cdot;\pmb\theta^*)$ (for compactness).


\section{Linear Models}

\definition{Model Matrix}
Each element in a \textit{Model Matrix} is a function of the \textit{Predictor Variables}.\\
Each row depends on a different set of observations.\\

\proposition{Implementing Factors}
Suppose a model has \textit{Factor Variable} $g_i$ which seperates observations into $n$ categories.\\
In the function for $y_i$, $g_i$ is represented by $n-1$ terms $\gamma_{g_i}$ whose values depends on the value of $g_i$. (\ie A different weight is assigned to each group).\\
For an observation $\gamma_{g_i}$ is set to 1 iff the observation is in category $g_i$. Only $n-1$ variables are used since belonging to $g_n$ can be inferred by $\gamma_{g_i}=0\ \forall\ i$.\\
We can express this in terms of matrices, as below, with each row on the LHS denoting which category each observation belongs to
$$\begin{pmatrix}0&1&0&\dots&\\1&0&0&\dots\\0&0&1&\dots\\\vdots&\vdots&\vdots&\ddots\end{pmatrix}\begin{pmatrix}\gamma_1\\\gamma_2\\\vdots\\\gamma_{n-1}\end{pmatrix}$$
\nb Each row has a single $1$ element and $n-2$ zero elements.\\

\remark{We want to find the parameters to the Predictor Variables which produce accurate values for the Response Variables.}

\definition{Linear Model}
A \textit{Linear Model} is a \textit{Statistical Model} whose response vector, $\textbf{y}$, is linear wrt its \textit{Model Matrix}, $\X$, and some zero-mean random error, $\pmb\varepsilon$.
$$\textbf{y}=\X\pmb\beta+\pmb\varepsilon$$
$\X\in\reals^{n\times p},\ \pmb\beta\in\reals^p$ and $\varepsilon\sim\text{Normal}(\pmb0,\sigma^2 I)$.

\subsection{Frequentist Approach}

\proposition{Frequentist Approach to Linear Models}
In the \textit{Frequentist Approach} to \textit{Linear Models} we treat $\pmb\beta$ and $\sigma^2$ as fixed (but unknown) states of nature.\\
Thus all random variability from the data will be inherited into the model.\\

\subsubsection{Estimation}

\proposition{Point Value Estimates}
We can make \textit{Point Value Estimates} of parameter values by finding the set of parameters $\pmb\beta$ which minimises the \textit{Residual Sum of Squares}.
\[\begin{array}{rrl}
\hat{\pmb\beta}_\text{LSE}&:=&\displaystyle{\argmin_{\pmb\beta}\sum_{i=1}^N(y_i-(\X\pmb\beta)_i)^2}\\
&=&\displaystyle{\argmin_{\pmb\beta}\|\textbf{y}-\X\pmb\beta\|^2}
\end{array}\]
\nb This is the \textit{Least Squares Estimate} of $\pmb\beta$.\\

\remark{$\hat{\pmb\beta}_\text{LSE}=R^{-1}Q^T\textbf{y}$}
where $Q,R$ are from the decomposition of $\X$ st $\X=QR$ with $Q$ being \textit{Orthogonal} and $R$ being \textit{Upper-Triangle}.\\

\proposition{Deriving Least Squares Estimate for $\pmb\beta$}
Let $\X,\textbf{y}$ be $n$ observed data points \& $\pmb\beta\in\reals^p$ be a parameter vector we are fitting to our model.\\
We want to find $\hat{\pmb\beta}_\text{LSE}=\displaystyle{\argmin_{\pmb\beta}\|\textbf{y}-\X\pmb\beta\|^2}$.\\
Since $\X$ is a real-valued matrix it can be decomposed into
$$\X=\mathcal{Q}\begin{pmatrix}R\\\pmb0\end{pmatrix}=QR\footnote{Known as \textit{QR Decomposition} and can be performed in R using $\mathtt{qr.Q(qr(X),complete=TRUE)}\ \&\ \mathtt{qr.R(qr(X))}$}$$
where $R\in\reals^{p\times p}$ is an upper triangle matrix, $\mathcal{Q}\in\reals^{n\times n}$ is orthogonal \& $Q\in\reals^{n\times p}$ is the first $p$ columns of $\mathcal{Q}$.\\
Note that $\mathcal{Q}^T$ is \textit{Orthogonal}.\\
Thus
\[\begin{array}{rcl}
\|\textbf{y}-\X\pmb\beta\|^2&=&\left\|\textbf{y}-\mathcal{Q}\begin{pmatrix}R\\\pmb0\end{pmatrix}\pmb\beta\right\|^2\\
&=&\left\|\mathcal{Q}^T\textbf{y}-\mathcal{Q}^T\mathcal{Q}\begin{pmatrix}R\\\pmb0\end{pmatrix}\pmb\beta\right\|^2\text{ since }\mathcal{Q}^T\text{ is orthogonal}\\
&=&\left\|\mathcal{Q}^T\textbf{y}-\begin{pmatrix}R\\\pmb0\end{pmatrix}\pmb\beta\right\|^2
\end{array}\]
Decompose $\mathcal{Q}^T\textbf{y}=\begin{pmatrix}\textbf{f}\\\textbf{r}\end{pmatrix}$ with $\textbf{f}\in\reals^p$ \& $\textbf{r}\in\reals^{n-p}$.\\
Note that $\textbf{f}=Q^T\textbf{y}$.\\
$\textbf{f}$ is the first $p$ rows of $\mathcal{Q}^T\textbf{y}$ and $\textbf{r}$ is the last $n-p$ rows.\\
Thus
\[\begin{array}{rcl}
\|\textbf{y}-\X\pmb\beta\|^2&=&\left\|\begin{pmatrix}\textbf{f}\\\textbf{r}\end{pmatrix}-\begin{pmatrix}R\\\pmb0\end{pmatrix}\pmb\beta\right\|^2\\
&=&\|\textbf{f}-R\pmb\beta\|^2+\|\textbf{r}\|^2
\end{array}\]
$\|\textbf{r}\|^2$ is indepdent of $\pmb\beta$ and thus irreducible.\\
This final expression is minimised when $\|\textbf{f}-R\pmb\beta\|^2=0$ (Meaning $\|\textbf{r}\|^2=\|\textbf{y}-\X\pmb\beta\|^2$).\\
Thus
$$\hat{\pmb\beta}_\text{LSE}=R^{-1}\textbf{f}=R^{-1}Q^T\textbf{y}$$
This requires that $R$ is full rank, in order for its inverse to exist.\\
Further, $\X$ has to have full rank, which we can ensure by our design of the model.\\

\proposition{Least Squares Estimate of Parameter Vector is Unbiased}
$$\expect(\hat{\pmb\beta})=\expect(R^{-1}Q^T\textbf{y})=R^{-1}Q^T\expect(\textbf{y})=R^{-1}Q^T\X\pmb\beta=R^{-1}Q^TQR\pmb\beta=\pmb\beta$$

\propositionn{Variance of Least Squares Estimate of Parameter Vector}
\[\begin{array}{rrcl}
&\cov(\textbf{y})&=&I\sigma^2\\
\implies&\cov(\textbf{f})&=&Q^T\textbf{y}\\
&&=&Q^TQ\sigma^2\\
&&=&I\sigma^2\\
\implies&\cov(\hat{\pmb\beta}_\text{LSE})&=&\cov(R^{-1}\textbf{f})\\
&&=&R^{-1}\cov(\textbf{f})R^{-T}\\
&&=&R^{-1}I\sigma^2R^{-T}\\
&&=&R^{-1}R^{-T}\sigma^2
\end{array}\]

\remark{Least Squares Estimation - Geometric Interpretation}
\textit{Linear Models} state that $\expect(\textbf{y})$ lies on the space spanned by all possible linear combinations of the columns of the \textit{Model Matrix}.\\
\textit{Least Squares Estimation} finds the point in the space closest to $\textbf{y}$.\\
Thus \textit{Least Sqaures Estimation} amounts to find the orthogonal projection of $\textbf{y}$ in the linear space spanned by the columns of $\X$.\\

\definition{Influence Matrix}
The \textit{Influence Matrix}, $A$, is the orthogonal projection of the response variables onto the linear space spanned by the columns of $\X$.\\
Since
$$\hat{\textbf{y}}=\X\hat{\pmb\beta}=(QR)(R^{-1}Q^T\textbf{y})=QQ^T\textbf{y}$$
the \textit{Influence Matrix} is
$$A=QQ^T$$
\nb The \textit{Influence Matrix} is \textit{Idempotent}, $AA=A$.\\

\propositionn{Results in terms of Model Matrix}
\[\begin{array}{rcl}
\hat{\pmb\beta}&=&(\X^T\X)^{-1}\X^T\textbf{y}\\
\Sigma_{\hat{\pmb\beta}}&=&(\X^T\X)^{-1}\sigma^2\\
A&=&\X(\X^T\X)^{-1}\X^T
\end{array}\]
\nb Substituting $\X=QR$ gets back to previous results.

\subsubsection{Checking}
%Frequentist

\remark{Assumptions}
We assume that each $\varepsilon_i$ is independent \& has constant variance (we also assume they are normally distributed but this generaly holds due to CLT).\\
We need a way to check this assumption holds in order for inferences (beyound point estimates) to be sound.\\

\proposition{Graphical Checks}
Plotting $\hat\epsilon=y_i-(\X\hat{\pmb\beta})_i$ on a graph tends to indicate whether an assumption has been broken, and if so, how it was broken.
\begin{itemize}
	\item[-] Systematic patterns in the mean indicate independence assumption is broken.
	\item[-] Systematic patterns in the variability indicate the constant variance assumption is broken.
\end{itemize}

\subsubsection{Evaluating}

\remark{Choice of measure to minimise?}
Was choosing to minimise \textit{Residual Sum of Squares} a good one?\\
\nb Choosing $\sum_i|\epsilon_i|$, $\sum_i\epsilon^4$,\dots could have worked.\\

\remark{Problem with $\|\hat{\pmb\beta}-\pmb\beta\|$ as measure}
Suppose our data has a lot of information for estimating $\beta_i$ but not mch for $\beta_j$, should we weight them equally?\\

\remark{Preferred Estimators}
We require estiamtors to be \textit{Unbiased}, and then we shall choose the estimator with the least variance among those which are \textit{Unbiased}.\\
\nb Least variance means smallest covariance matrix (in a way which accounts for weighting individual parameters).\\

\theorem{Gauss Markov Theorem}
Let $\X,\textbf{y}$ be some observed data.\\
Consider a model where $\pmb\mu:=\expect(\textbf{y})=\X\pmb\beta$ and $\Sigma^2_y=\sigma^2I$.\\
Let $\tilde\theta:=\textbf{c}^T\textbf{y}$ be any \textit{Unbiased Linear Estimaor} of $\theta=\textbf{t}^T\pmb\beta$ for some arbitrary vector, $\textbf{t}$.\\
Then
$$\var(\tilde\theta)\geq\var(\hat\theta)$$
where $\hat\theta=\textbf{t}^T\hat{\pmb\beta}$ and $\hat{\pmb\beta}=R^{-1}Q^T\textbf{y}$ where $\X=QR$.\\
Thus each element of $\hat{\pmb\beta}$ is a \textit{minimum variance unbiased estimator}, since $\textbf{t}$ is arbitrary.

\subsubsection{Hypothesis Testing \& Intervals}

\remark{Popular Hypothesis Test}
Often we want to test whether any $\beta_i=0$ as this would indicate that those predictors do not affect the model accuracy.\\

\proposition{Distribution of $\hat{\pmb\beta}$}
We assume that $\varepsilon_i\sim\text{Normal}(0,\sigma^2)$. Thus
\[\begin{array}{rcl}
\textbf{y}&\sim&\text{Normal}(\X\pmb\beta,\sigma^2I)\\
\implies\hat{\pmb\beta}&\sim&\text{Normal}(\pmb\beta,R^{-1}R^{-T}\sigma^2)
\end{array}\]
Note that $\pmb\beta$ and $\sigma^2$ are unknown.\\
\nb $\X=QR$ where $Q$ is orthogonal \& $R$ upper-triangle.

\proposition{$\dfrac{\hat\beta_i-\beta_i}{\hat{\sigma}_{{\hat\beta}_i}}\sim t_{n-p}$}
Note that we can produce a decomposition $\X=\mathcal{Q}\begin{pmatrix}R\\\pmb0\end{pmatrix}$ where $\mathcal{Q}$ is orthogonal \& $R$ is upper triangular.\\
We have
$$\cov(\mathcal{Q}^T\textbf{y})=\mathcal{Q}^T\cov(\textbf{y})\mathcal{Q}^{-T}=\mathcal{Q}^T\cov(\textbf{y})\mathcal{Q}=\mathcal{Q}^TI\sigma^2\mathcal{Q}=I\sigma^2$$
This implies that elements of $\mathcal{Q}^T\textbf{y}$ are independent, due to their assumed normal distribution.\\
Note that
$$\expect(\mathcal{Q}^T\textbf{y})=\expect\left(\begin{pmatrix}\textbf{f}\\\textbf{r}\end{pmatrix}\right)\quad\text{and}\quad\expect(\mathcal{Q}^T\textbf{y})=\mathcal{Q}^T\expect(\textbf{y})=\mathcal{Q}^T\X\pmb\beta=\begin{pmatrix}R\\\pmb0\end{pmatrix}\pmb\beta$$
Thus
$$\expect\left(\begin{pmatrix}\textbf{f}\\\textbf{r}\end{pmatrix}\right)=\begin{pmatrix}R\\\pmb0\end{pmatrix}\pmb\beta\implies\expect(\textbf{f})=R\pmb\beta\ \&\ \expect(\textbf{r})=\pmb0$$
Further
$$\textbf{f}\sim\text{Normal}(R\pmb\beta,I_p\sigma^2)\quad\text{and}\quad\textbf{r}\sim\text{Normal}(\pmb0,I_{n-p}\sigma^2)$$
and $\textbf{f}$ \& $\textbf{r}$ are independent.\\
Thus $\hat{\pmb\beta}$ \& $\hat\sigma^2$ are independent.\\
Since each $r_i\sim\text{Normal}(0,\sigma^2)$
$$\frac{\|\textbf{r}\|^2}{\sigma^2}=\frac{1}{\sigma^2}\sum_{i=1}^{n-p}r_i^2\sim\chi^2_{n-p}$$
Since $\expect(\chi^2_{n-p})=n-p\implies\hat\sigma^2:=\frac{1}{n-p}\|\textbf{r}\|^2$ is an unbiased estimator of $\sigma^2$.\\
$\hat\Sigma_{\hat{\pmb\beta}}:=\Sigma_{\hat{\pmb\beta}}\frac{\hat\sigma^2}{\sigma^2}=R^{-1}R^{-T}\hat\sigma^2$ is an unbiased etimator of $\Sigma_{\hat{\pmb\beta}}$.\\
Thus $\hat\sigma_{\hat\beta_i}:=\sqrt{[\hat\Sigma_{\hat\beta}]_i}=\sigma_{\hat\beta_i}\frac{\hat\sigma}\sigma$.\\
Finally
$$\dfrac{\hat\beta_i-\beta_i}{\hat\sigma_{\hat\beta_i}}=\dfrac{\hat\beta_i-\beta_i}{\sigma_{\hat\beta_i}\frac{\hat\sigma}{\sigma}}=\frac{\frac1{\sigma_{\hat\beta_i}}(\hat\beta_i-\beta_i)}{\sqrt{\hat\sigma^2/\sigma^2}}=\frac{\frac1{\sigma_{\hat\beta_i}}(\hat\beta_i-\beta_i)}{\sqrt{\frac1{\sigma^2}\frac1{n-p}\|\textbf{r}\|^2}}\sim\frac{\text{Normal}(0,1)}{\sqrt{\frac{1}{n-p}\chi^2_{n-p}}}\sim t_{n-p}$$
\nb $\|\textbf{r}\|^2=\|\textbf{y}-\X\hat{\pmb\beta}\|^2$ by the results in \textbf{Proposition 2.4}.\\

\proposition{Confidence Interval for $\beta_i$}
Using the result in \textbf{Proposition 2.9} we can construct the following $1-\alpha$ confidence interval
$$\prob\left(-t_{n-p,\frac{\alpha}{2}}<\dfrac{\hat\beta_i-\beta_i}{\hat{\sigma}_{{\hat\beta}_i}}<t_{n-p,\frac\alpha2}\right)=\prob\bigg(\hat\beta_i-t_{n-p,\frac{\alpha}2}\sigma_{\hat\beta_i}<\beta_i<\hat\beta_i+t_{n-p,\frac{\alpha}2}\sigma_{\hat\beta_i}\bigg)=1-\alpha$$

\proposition{Hypothesis Testing on $\beta_i$}
Suppose we want to test $H_0:\beta_i=\beta_{i0}$ against $H_1:\beta_i\neq\beta_{i0}$.\\
We use test statistic
$$T=\frac{\hat\beta_i-\beta_{i0}}{\hat\sigma_{\hat\beta_i}}$$
under $H_0$ $T\sim t_{n-p}$ where $n$ is the number of observations \& $p$ the number of parameters.\\
Thus we can assess the test using $p=\prob(|T|\geq|t_{obs}|)$.\\

\proposition{Testing Multiple Variables in a Model}
This can be expressed as the test of $H_0:\textbf{C}\pmb\beta=\textbf{d}$ against $H_1:\textbf{C}\pmb\beta\neq\textbf{d}$ where $\textbf{C}\in\reals^{q\times p}$ \& $\textbf{d}\in\reals^q$ with $q<p$.\\
Under $H_0$ we have $(\textbf{C}\hat{\pmb\beta}-\textbf{d})\sim\text{Normal}(\pmb0,\textbf{C}\Sigma_{\hat{\pmb\beta}}\textbf{C}^T)$.\\
We can produce a \textit{Cholesky Decomposition} $\textbf{L}^T\textbf{L}=\textbf{C}\Sigma_{\hat\beta}\textbf{C}^T$.\\
Thus
\[\begin{array}{rrcl}
&\textbf{L}^{-T}(\textbf{C}\hat{\pmb\beta}-\textbf{d})&\sim&\text{Normal}(0,I)\\
\implies&(\textbf{C}\hat{\pmb\beta}-\textbf{d})^T(\textbf{C}\Sigma_{\hat{\pmb\beta}}\textbf{C}^T)^{-1}(\textbf{C}\hat{\pmb\beta}-\textbf{d})&=&(\textbf{C}\hat{\pmb\beta}-\textbf{d})^T\textbf{L}^{-1}\textbf{L}^{-T}(\textbf{C}\hat{\pmb\beta}-\textbf{d})\\
&&=&\|\textbf{L}^{-T}(\textbf{C}\hat{\pmb\beta}-\textbf{d})\|^2\\
&&\sim&\displaystyle\sum_{i=1}^q\text{Normal}(0,1)^2\\
&&\sim&\chi^2_q
\end{array}\]
Setting $\hat\Sigma_{\hat{\pmb\beta}}:=\frac{\hat\sigma^2}{\sigma^2}\Sigma_{\hat{\pmb\beta}}$ we can produce a test statistic
$$F:=\frac1q(\textbf{C}\hat{\pmb\beta}-\textbf{d})^T(\textbf{C}\Sigma_{\hat{\pmb\beta}}\textbf{C}^T)^{-1}(\textbf{C}\hat{\pmb\beta}-\textbf{d})$$
Which has the distribution
\[\begin{array}{rcl}
F&=&\frac1q\|\textbf{L}^{-T}(\textbf{C}\hat{\pmb\beta}-\textbf{d})\|^2\\
&=&\dfrac{\sigma^2}{q\hat\sigma^2}\|\textbf{L}^{-T}(\textbf{C}\hat{\pmb\beta}-\textbf{d})\|^2\\
&=&\dfrac{\frac1q\|\textbf{L}^{-T}(\textbf{C}\hat{\pmb\beta}-\textbf{d})\|^2}{\hat\sigma^2/\sigma^2}\\
&=&\dfrac{\frac1q\|\textbf{L}^{-T}(\textbf{C}\hat{\pmb\beta}-\textbf{d})\|^2}{\frac1\sigma^2\frac1{n-p}\|\textbf{r}\|^2}\\
&\sim&\dfrac{\frac1q\chi^2_q}{\frac1{n-p}\chi^2_{n-p}}\\
&\sim&F_{q,n-p}
\end{array}\]

\proposition{$F=\dfrac{\frac1q(RSS_0-RSS_q)}{\frac1{n-p}RSS_1}$}
Where $RSS_0$ is the residual sum of squares when $H_0$ is true and $RSS_1$ is the residual sum of squares when $H_1$ is true.\\

\proposition{Testing whether a Factor Variable belongs in a Model}
\textit{Factor Variables} have multiple parameters associated to them in a model and thus to test whether the \textit{Factor Variable} should be in the model requires testing whether all of these parameters should equal 0.\\
This can be tested using the results in \textbf{Propostion 2.12} with $\textbf{d}=\pmb0$ and $\textbf{C}$ is the rows of the $I_p$ which indicate the parameters we wish to test.\\
In this case $q$ is the number of parmeters we wish to test.

\subsection{Bayesian Approach}

\proposition{Prior Distributions}
We need to define \textit{Prior Distributions} for $\pmb\beta$ and $\sigma^2$.
$$\pmb\beta\sim\text{Normal}(\pmb\beta_0,\pmb\phi^{-1})\quad\text{and}\quad\frac1{\sigma^2}=:\tau\sim\Gamma(a,b)$$
where $\pmb\beta_0,\pmb\phi,a,b$ are given by us.\\
\nb In order for results to be tractable we use conjugate priors. $\tau:=\frac1{\sigma^2}$ is called \textit{Precision}.\\

\proposition{Resulting Distribution}
\[\begin{array}{rcl}
f(\textbf{y},\pmb\beta,\tau)&\propto&\displaystyle\frac{\tau^{\alpha-1+\frac{n}2}e^{-\frac\tau2\|\textbf{y}-\X\pmb\beta\|^2}}{e^{\frac12(\pmb\beta-\pmb\beta_0)^T\pmb\phi(\pmb\beta-\pmb\beta_0)}e^{-b\tau}}\\
f(\tau|\pmb\beta,\textbf{y})&\propto&\dfrac{\tau^{\alpha-1\frac{n}2}}{e^{\frac\tau2(b+\|\textbf{y}-\X\pmb\beta\|^2}}\\
&\sim&\Gamma\left(\frac{n}2+a,b+\frac12\|\textbf{y}-\X\pmb\beta\|^2\right)\\
f(\pmb\beta|\tau,\textbf{y})&\propto&\text{exp}\bigg\{-\frac12(\pmb\beta^T\X^T\X\pmb\beta\tau-2\pmb\beta\X^T\textbf{y}\tau+\pmb\beta^T\pmb\phi\pmb\beta-2\pmb\beta^T\pmb\phi\pmb\beta_0)\bigg\}\\
&\sim&\text{Normal}\left((\X^T\X\tau+\pmb\phi)^{-1}(\tau\X^T\textbf{y}+\pmb\phi\pmb\beta_0),\ (\X^T\X\tau+\pmb\phi)^{-1}\right)
\end{array}\]
If sample size tends to infinity or the prior precision matrix tends to $\pmb0$, then $$f(\pmb\beta|\tau,\textbf{y})\overset\sim\to\text{Normal}(\hat{\pmb\beta},(\X^T\X)^{-1}\sigma^2)$$
This is the same as in the \textit{Frequentist Approach}, so the same results acan be used for intervals \& hypothesis testing.\\
\nb As sample size tends to infinity $\X^T\X\tau$ dominates $\pmb\phi$.\\

\propositionn{Find Posterion, $f(\pmb\beta,\tau|\textbf{y})$}1
\begin{itemize}
	\item Iteratively find the posterior modes of $\pmb\beta$ (given the estimated mode of $\tau$) and the posterior mode of $\tau$ (given the estimated modes of $\pmb\beta$), until convergence.\\
	Then plug this into $f(\pmb\beta|\tau,\textbf{y})$.
	\item[Empirical Bayes] Integrate $\pmb\beta$ outo of $f(\tau|\pmb\beta,\textbf{y})$ to obtain $f(\tau|\textbf{y})$.\\
	Maximise $f(\tau|\textbf{y})$ to find $\hat\tau$.\\
	Then plug this into $f(\pmb\beta|\tau,\textbf{y})$.
	\item[Gibbs Sampling] Alternate simulation of $\pmb\beta$ from $f(\pmb\beta|\tau,\textbf{y})$ (give simulated $\tau$) with simulation of $\tau$ from $f(\tau|\pmb\beta,\textbf{y})$ (given simulated $\pmb\beta$)
\end{itemize}

\section{Maximum Likelihood Estimation}

\subsection{Frequentist}

\proposition{Frequentist Approach to Linear Models}
Parameters, $\pmb\beta$, are treataed as fixed states of nature and all uncertainty occurs in our estimation of these parameters.\\

\definition{Likelihood}
Let $\textbf{y}$ a set of $n$ observations from $f(\cdot;\pmb\theta)$.\\
\textit{Likelihood} measures the probability of observing specified outcomes, given a possible set of parameter values.
$$L_n(\pmb\theta;\textbf{y}):=f_n(\textbf{y};\pmb\theta)=\prod_{i=1}^nf(y_i;\pmb\theta)$$
Often we use the \textit{Log-Likelihood} function as it turns products into summations and exponents into parameter.
$$\ell_n(\pmb\theta;\textbf{y}):=\ln L(\pmb\theta;\textbf{y})=\sum_{i=1}^nf(y_i;\pmb\theta)$$
\nb $\argmax_\theta L(\theta)\equiv\argmax_\theta \ell(\theta)$.\\

\definition{Maximum Likelihood Estimate}
Let $\textbf{y}$ a set of $n$ observations from $f(\cdot;\pmb\theta)$.\\
The \textit{Maximum Likelihood Estimate},$\hat{\pmb\theta}_\text{MLE}$, for a set of parameter, $\pmb\theta$ is the set of parameter values which maximise the \textit{Likelihood Function}.
$$\hat{\pmb\theta}_\text{MLE}=\argmax_\theta L(\pmb\theta;\textbf{y})=\argmax_\theta \ell(\pmb\theta;\textbf{y})$$

\proposition{Finding Maximum Likelihood Estimate}
Let $\textbf{y}$ be a set $n$ of observations from the model $f(\textbf{X};\pmb\theta)$ with $|\pmb\theta|=m$.\\
To find the \textit{Maximum Likelihood Estimate} of $\pmb\beta$
\begin{enumerate}
	\item Define the \textit{Log-Likelihood Function} $\ell(\pmb\theta;\textbf{y})$.
	\item Find the gradient of $\ell(\pmb\theta;\textbf{y})$ wrt $\pmb\theta$
	$$\nabla\ell(\pmb\theta;\textbf{y}):=\begin{pmatrix}\frac\partial{\partial\theta_1}\ell(\pmb\theta;\textbf{y})&\dots&\frac\partial{\partial\theta_m}\ell(\pmb\theta;\textbf{y})\end{pmatrix}$$
	\item Equate the gradient to the zero-vector and solve for $\pmb\theta$ to find extrema of $\ell$
	$$\nabla\ell(\pmb\theta;\textbf{y})=\pmb0$$
	\item Calculate the \textit{Hessian} of $\ell(\pmb\theta;\textbf{x})$
	$$\nabla^2\ell(\pmb\beta;\textbf{y})=\begin{pmatrix}\frac{\partial}{\partial\theta_1^2}\ell(\pmb\theta;\textbf{y})&\dots&\frac{\partial}{\partial\theta_1\partial\theta_m}\ell(\pmb\theta;\textbf{y})\\\vdots&\ddots&\vdots\\\frac{\partial}{\partial\theta_m\partial\theta_1}\ell(\pmb\theta;\textbf{y})&\dots&\frac{\partial}{\partial\theta_m^2}\ell(\pmb\theta;\textbf{y})\end{pmatrix}$$
	\item Test each extremum, $\hat{\pmb\theta}$ to see if any are maxima
	\begin{center}
	If $\text{det}(H(\hat{\pmb\theta}))>0$ and $\frac\partial{\partial\theta_1^2}\ell(\hat{\pmb\theta};\textbf{y})<0$ then $\hat{\pmb\theta}$ is a local maximum.\\
	\ie If $H(\hat{\pmb\theta})$ is negative definite.
	\end{center}
\end{enumerate}

\remark{It is rare to find explicit expressions for MLEs. Instead we use \text{numerical optimisation}}

\subsection{Performance}

\remark{Here we look at properties of an MLE when we have a large sample size}

\definition{Fisher Information Matrix}
Let $\ell(\cdot):=\ln f(\textbf{y};\pmb\theta))\ \&\ \pmb\theta^*$ be the true parameter values.\\
\textit{Fisher Information} describes how much information the $X$ carries about the parameters, $\pmb\theta$.\\
The \textit{Fisher Information Matrix} is defined as
$$\mathcal{I}:=\expect\left(\dfrac{\partial\ell}{\partial\pmb\theta}\bigg|_{\pmb\theta=\pmb\theta^*}\dfrac{\partial\ell}{\partial\pmb\theta^T}\bigg|_{\pmb\theta=\pmb\theta^*}\right)$$

\proposition{Interpretting Fisher Information Matrix}
If $\mathcal{I}$ carries lots of information if it has large magnitude eigenvalues \& less information if they have small magnitude.\\
\nb See \textbf{Proposition 3.5} for a different formulation of \textit{Fisher Information Matrix}.\\

\remark{Properties of Expected Log-Likelihood}
Here are some properties of the \textit{Expected Log-Likelihood} as \textit{Large Sample Theory} of \textit{MLEs} relies on them.\\

\theorem{Expect a turning point in Log-Likelihood at the true parameter values}
Let $\ell(\cdot):=\ln f(\textbf{y};\pmb\theta))\ \&\ \pmb\theta^*$ be the true parameter values.
$$\expect\left(\dfrac{\partial\ell}{\partial\pmb\theta}\bigg|_{\pmb\theta=\pmb\theta^*}\right)=\pmb0$$
\textit{Proof}
$$\expect\left(\dfrac\partial{\partial\pmb\theta}\ln f(\textbf{y};\pmb\theta)\right)=\int\dfrac1{f(\textbf{y};\pmb\theta)}\dfrac{\partial f}{\partial\pmb\theta}f(\textbf{y};\pmb\theta)d\textbf{y}=\int\dfrac{\partial f}{\partial\pmb\theta}d\textbf{y}=\dfrac\partial{\partial\pmb\theta}\int f(\textbf{y};\pmb\theta)d\textbf{y}=\dfrac{\partial\pmb1}{\partial\pmb\theta}=\pmb0$$
\proved

\theorem{Covariance as Expectation}
Let $\ell(\cdot):=\ln f(\textbf{y};\pmb\theta))\ \&\ \pmb\theta^*$ be the true parameter values.
$$\cov\left(\dfrac{\partial\ell}{\partial\pmb\theta}\bigg|_{\pmb\theta=\pmb\theta^*}\right)=\expect\left(\dfrac{\partial\ell}{\partial\pmb\theta}\bigg|_{\pmb\theta=\pmb\theta^*}\dfrac{\partial\ell}{\partial\pmb\theta^T}\bigg|_{\pmb\theta=\pmb\theta^*}\right)$$
\textit{Proof}\\
\[\begin{array}{rcl}
\cov\left(\dfrac{\partial\ell}{\partial\pmb\theta}\bigg|_{\pmb\theta=\pmb\theta^*}\right)&:=&\expect\left[\left(\dfrac{\partial\ell}{\partial\pmb\theta}\bigg|_{\pmb\theta=\pmb\theta^*}-\expect\left(\dfrac{\partial\ell}{\partial\pmb\theta}\bigg|_{\pmb\theta=\pmb\theta^*}\right)\right)\expect\left(\dfrac{\partial\ell}{\partial\pmb\theta}\bigg|_{\pmb\theta=\pmb\theta^*}-\expect\left(\dfrac{\partial\ell}{\partial\pmb\theta}\bigg|_{\pmb\theta=\pmb\theta^*}\right)\right)^T\right]\\
&=&\expect\left[\left(\dfrac{\partial\ell}{\partial\pmb\theta}\bigg|_{\pmb\theta=\pmb\theta^*}-\pmb0\right)\left(\dfrac{\partial\ell}{\partial\pmb\theta}\bigg|_{\pmb\theta=\pmb\theta^*}-\pmb0\right)^T\right]\text{ by \textbf{Theorem 3.1}}\\
&=&\expect\left[\dfrac{\partial\ell}{\partial\pmb\theta}\bigg|_{\pmb\theta=\pmb\theta^*}\dfrac{\partial\ell}{\partial\pmb\theta^T}\bigg|_{\pmb\theta=\pmb\theta^*}\right]
\end{array}\]
\proved

\proposition{Fisher Information Matrix as negative expectation}
Let $\ell(\cdot):=\ln f(\textbf{y};\pmb\theta))\ \&\ \pmb\theta^*$ be the true parameter values.
$$\mathcal{I}:=\expect\left(\dfrac{\partial\ell}{\partial\pmb\theta}\bigg|_{\pmb\theta=\pmb\theta^*}\dfrac{\partial\ell}{\partial\pmb\theta^T}\bigg|_{\pmb\theta=\pmb\theta^*}\right)\equiv-\expect\left(\dfrac{\partial^2\ell}{\partial\pmb\theta\partial\pmb\theta^T}\bigg|_{\pmb\theta=\pmb\theta^*}\right)$$
\textit{Proof}
\[\begin{array}{rrcl}
&\displaystyle\int\dfrac{\partial\ell}{\partial\pmb\theta}f(\textbf{y};\pmb\theta)d\textbf{y}&=&\pmb0\\
\implies&\displaystyle\int\dfrac{\partial^2\ell}{\partial\pmb\theta\partial\pmb\theta^T}f(\textbf{y};\pmb\theta)+\dfrac{\partial\ell}{\partial\pmb\theta}\dfrac{\partial f}{\partial\pmb\theta^T}d\textbf{y}&=&\pmb0\\
\text{but}&\dfrac{\partial\ell}{\partial\pmb\theta^T}&=&\dfrac1f\dfrac{\partial f}{\partial\pmb\theta^T}\\
\implies&\displaystyle\int\dfrac{\partial^2\ell}{\partial\pmb\theta\partial\pmb\theta^T}f(\textbf{y};\pmb\theta)d\textbf{y}&=&-\displaystyle\int\dfrac{\partial\ell}{\partial\pmb\theta}\dfrac{\partial\ell}{\partial\pmb\theta^T}f(\textbf{y};\pmb\theta)d\textbf{y}
\end{array}\]
\proved
\nb $\ell(\theta)=\ln f(\theta)\implies\frac{\partial}{\partial\theta}\ell(\theta)=\frac{\frac\partial{\partial\theta}f(\theta)}{f(\theta)}$.\\

\proposition{Expected Log-Likelihood has Global Maximum at True Parameter Value}
Let $\ell(\cdot):=\ln f(\textbf{y};\pmb\theta))\ \&\ \pmb\theta^*$ be the true parameter values.
$$\forall\ \pmb\theta\in\pmb\Theta,\ \expect[\ell(\pmb\theta)]\leq\expect[\ell(\pmb\theta^*)]$$
\textit{Proof}
Since $\ln$ is concave we can use \textit{Jensen's Inequality}
$$\expect\left[\ln\left(\dfrac{f(\textbf{y};\pmb\theta)}{f(\textbf{y};\pmb\theta^*)}\right)\right]\leq\ln\left[\expect\left(\dfrac{f(\textbf{y};\pmb\theta)}{f(\textbf{y};\pmb\theta^*)}\right)\right]=\ln\int\dfrac{f(\textbf{y};\pmb\theta)}{f(\textbf{y};\pmb\theta^*)}f(\textbf{y};\pmb\theta^*)d\textbf{y}=\ln\int f(\textbf{y};\pmb\theta)d\textbf{y}=\ln1=0$$
\proved

\theorem{Cram\'er-Rao Lower Bound}
Let $\textbf{y}\sim f(\cdot;\pmb\theta)$ and $\mathcal{I}$ be the \textit{Fisher Information Matrix}.\\
The \textit{Cram\'er-Rao Lower Bound} states that
\begin{center}$\mathcal{I}^{-1}$ is a lower bound of the variance matrix of any unbiased estimator $\tilde{\pmb\theta}$ \end{center}
In the sense that $\cov(\pmb\theta)-\mathcal{I}^{-1}$ is positive semi-definite.\\
\nb Look at proof.\\

\proposition{Consistency of MLE}
\textit{Maximum Likelihood Estimators} \underline{are} usually \textit{Consistent}.\\
This is because $\frac1n\ell(\pmb\theta)\overset{n\to\infty}{\longrightarrow}\frac{1}{n}\expect(\ell(\pmb\theta))\to\pmb\theta^*$ by \textbf{Proposition 3.5} (and WLLN if log can be broken down into summations).\\
\nb \textit{Consistency} likeliy fails when the number of parameters increases as sample sie increases.\\

\proposition{MLE Distribution for Large Sample Size}
Let $\hat{\pmb\theta}$ be an MLE for a set of parameters, with true value $\pmb\theta^*$.\\
As the same size tends to infty
$$\hat{\pmb\theta}\sim\text{Normal}(\pmb\theta^*,\mathcal{I}^{-1})$$
This means that in regular situtations, for large sample sizes, MLEs are unbiased and achieve the \textit{Cram\'er Rao Lower Bound}.\\

\proof{Proposition 3.7}
If the log-likelihood is based on independent observations then $\ell(\pmb\theta)=\sum_i\ell_i(\pmb\theta)$.\\
$\implies\frac{\partial\ell}{\partial\pmb\theta}=\sum_i\frac{\partial\ell_i}{\partial\pmb\theta}$.
Thus the central limit theorem applies and we get the result.\\
If the log-likelihood is \underline{not} base don independent observations then $\frac{\partial\ell}{\partial\pmb\theta}$ usually has a limiting normal distribution so the result holds anyways.

\subsection{Intervals}



\subsection{Numerical Optimisation}

\definition{Numerical Optimisation}
\textit{Numerical Optimisation} is the process of finding the set of parameters which maximise a function by numerically evaluating the function with multiple different values. This is used when we cannot take derivatives of a function for whatever reason.\\
\nb A lot of techniques focus on finding the \underline{minimum} so we use the negative of the \textit{Objective Function} in order to find the maximum instead.\\

\definition{Objective Function}
The \textit{Objective Function} is the function we wish to optimise in \textit{Numerical Optimisation}.\\
\nb In \textit{Statistical Inference} this is the \textit{Probability Density/Mass Function}.\\

\proposition{Assumptions about Objective Function}
In order to make problems easier we assume that the \textit{Objective Function} is:
\begin{enumerate}
	\item Sufficiently smooth;
	\item Bounded below; and,
	\item The parameter elements are unrestricted real values.\\
	If we want to put restrictions on $\pmb\theta$ we need to be able to implement them as $\pmb\theta=\textbf{r}(\pmb\theta_r)$ where $\textbf{r}(\cdot)$ is a known function \& $\pmb\theta_r$ is the unrestricted parameter set.
\end{enumerate}
\nb We require $f$ to be convex for \textit{Newton Methods} to work but that is an assumption too far. If it is not then we may only find a local minimum, not global.\\

\proposition{Principles for Newton's Method}
\textit{EXAMINABLE}.\\
Let $f(\cdot)$ be the function we wish to optimise.\\
\textit{Newton's Method} for \textit{Numerical Optimisation} is based on iteratively approximating $f$ by a truncated Taylor expansion and seeking the minimum of the approxiamte at each step.
$$f(\pmb\theta+\pmb\Delta)=f(\pmb\theta)+\nabla f(\pmb\theta)^T\pmb\Delta+\frac12\pmb\Delta^T\nabla^2 f(\pmb\theta+t\pmb\Delta)\pmb\Delta\text{ for }t\in(0,1)$$
Thus
\begin{center}$f(\pmb\theta+\pmb\Delta)\geq f(\pmb\theta)$ for small $\pmb\Delta$ is equivalent to $\nabla f(\pmb\theta)=\pmb0$ and $\nabla^2 f(\pmb\theta)$ being positive definite.\\
\ie $\pmb\theta$ is a minimum of $f$.\end{center}
We have that $\pmb\Delta:=-\textbf{H}\nabla f(\pmb\theta)$ is a \textit{Descent Direction} if $\textbf{H}$ is a positive definite matrix.\\ %RESULT IN NOTES

\definitionn{Newton's Method for Numerical Optimisation}
\begin{enumerate}
	\item Make an initial parameter value guess.
	\item Obtain a quadratic approximation to the \textit{Log-Likelihood Function} which behaves similarlly to the log-likelihood function in the region of this guess.\\
	\nb This is done by using a \textit{Taylor Approximation} of the \textit{Log-Likelihood Function}.
	$$f(\pmb\theta+\pmb\Delta)=f(\pmb\theta)+\nabla f(\pmb\theta)^T\pmb\Delta+\frac12\pmb\Delta^T\nabla^2f(\pmb\theta+t\pmb\Delta)\pmb\Delta$$
	Solve for $\pmb\Delta$ which maximises.\\
	\nb Take derivate wrt $\pmb\Delta$ and equate to zero %TODO
	\item Update parameter guesss to be maximiser of this quadratic approxiation.
	\item Repeat \textit{ii)-iii)} with new guesses, until convergence.
\end{enumerate}

\proposition{Requirements for Newton's Method}
In order to guarantee that \textit{Newton's Method} converges to the MLE, we need to ensure the following
\begin{enumerate}
	\item \text{The approximating quadratic actually has a maximum (not minimum, inflection point etc.).}\\
	\nb If it has a minimum then we use its negative value instead.
	\item The proposed change in parameter values actually \underline{increases} the \textit{Log-Likelihood} itself.\\
	If not we move the parameter back towards the previous parameter guess until the \textit{Log-Likelihood} increases.
\end{enumerate}

\definition{Newton's Method}
\textit{NON-EXAMINABLE}.\\
Let $f(\pmb\theta)$ be the function we wish to optimise (this would be the \textit{Likelihood Function}).\\
\textit{Newton's Method} is a method for \textit{Numerical Optimisation}.\\
The idea is to iteratively use a truncated \textit{Taylor Expansion} (to the second degree) of function $f(\pmb\theta)$ and to find the minimum of this approximation at each step.
\begin{enumerate}
	\item Make an initial input guess $\pmb\theta^{[0]}$. Set $k=0$.
	\item Evaluate the function \& its first two derivatives
	$$f(\pmb\theta^{[k]}),\ \nabla f(\pmb\theta^{[k]}),\ \nabla^2f(\pmb\theta^{[k]})$$
	\item \textbf{If} $\nabla f(\pmb\theta^{[k]})=\pmb0$ \textbf{and} $\nabla^2f(\pmb\theta^{[k]})$ is positive semi-definite\textbf{:}
	\begin{itemize}
		\item $\pmb\theta^{[k]}$ is a minimum. TERMINATE
	\end{itemize}
	\item \textbf{If} $\nabla^2f(\pmb\theta^{[k]})$ is \textit{positive-definite}\textbf{:} Set $\textbf{H}=\nabla^2f(\pmb\theta^{[k]})$.\\
	\textbf{Else:} Set $\textbf{H}=U\tilde{\Lambda}U^T$ where we have decomposed $\nabla^2f(\pmb\theta^{[k]})=U\Lambda U^T$ with $\Lambda$ being the diagonal matrix of eigenvalues \& $\tilde{\Lambda}_{ij}=|\Lambda_{ij}|$ (all values positive).\\
	\nb This step is to ensure that $\textbf{H}$ is \textit{postive definite}.
	\item Solve $\Delta:=-\dfrac{\nabla f(\pmb\theta^{[k]})}{\textbf{H}}$ where $\Delta$ is the search direction.
	\item \textbf{If not} $f(\pmb\theta^{[k]}+\Delta)<f(\pmb\theta^{[k]})$\textbf{:} repeatedly have $\Delta$ until condition is met.\\
	\nb Implementation of \textit{Step Length Control}.
	\item Set $\pmb\theta^{[k+1]}=\pmb\theta^{[k]}+\Delta$. Set $k+=1$
	\item Repeat ii)-vii) until we get a termination in stage iii).
\end{enumerate}
\nb In practice we terminate in iii) if $\|\nabla f(\pmb\theta^{[k]})\|<|\nabla f(\pmb\theta^{[k]})|\epsilon_r+\epsilon_a$, for some small $\epsilon_a,epsilon_r$ which we set.\\

\remark{\text{The first derivative tells us the direction, the second derivative suggests the step length}}

\remark{$f(\pmb\theta^{[k]})$ is only evaluated to ensure that step is an improvement.}
\textit{NON-EXAMINABLE}.\\
If $f(\cdot)$ is not avaiable (but $\nabla f\ \&\ \nabla^2 f$ are) we have a few options
\begin{itemize}
	\item Show that $f$ is non-increasing in the direction of the step, $\Delta$, at $\pmb\theta+\Delta$ (\ie $\nabla f(\pmb\theta+\Delta)^T\Delta\leq0$).
	\item[Or] Replace $-\nabla^2 \ell(\pmb\theta)$ with $-\expect[\nabla^2\ell(\pmb\theta)]$ (Known as the \textit{Fisher Scoring Matrix}).
\end{itemize}
\nb This only affects step vi) of \textbf{Definition 3.5}.\\

\remarkk{Other Numerical Optimisation Techniques}
\begin{itemize}
	\item[Quasi-Newton] \textit{Quasi-Newton Methods} are \textit{Newton type Methods} in which an approximation is made for the \textit{Hessian Matrix} ($\nabla^2 f(\cdot)$), or its inverse, by building it from the first derivative information computed at each trial.\\
	\nb In R this is done with $\mathtt{optim(\dots,method='BFGS')}$.
	\item[Steepest Descent] Truncating the \textit{Taylor Expansion} allows us to establish the direction to step but not length. Thus we need to implement step length control methods.
\end{itemize}
\nb There plenty of methods not covered here.

\section{Estimating Posterior Distribution}
%TODO Slice sampling 10.3.2
\proposition{Difficulty Computing Bayes' Theorem} %TODO HERE
The \textit{Likelihood} \& \textit{Prior Distributions} are computable in \textit{Bayes' Theorem}, but the \textit{Evidence Distribution}, $p(\textbf{y})$ is not. Thus the difficult in calculating the \textit{Posterior Distribution} lies in trying to calculate the \textit{Evidence Distribution} for the observed data.\\

\remark{Likelihood is the probability of observing the data that we observed}

\definition{Markov Chain Monte Carlo Methods}
\textit{MCMC Methods} are techniques for generating a sample from a probability distribution.\\
Here we use them to generate a sample from the posterior of a model.\\
They are very general \& will work with almost any model, given enough iterations.\\

\remark{Convergence in MCMC Methods}
We can run MCMC Methods for as many iterations as we like, thus we need to measure whether convergence has occured so we can stop sampling at the correct time.
\begin{itemize}
	\item[-] This can be done by inspect plots of data \& looking at the rolling values of quantiles.\\
	\nb If we think the posterior is multi-modal then multiple MCMC chains should be run at once.
	\item[-] Examine the \textit{Autocorrelation Function} of the chain components.\\
	This considers reading the chain at different intervals \& what correlations occur in doing so. Lower values indicate greater independence.
	\item[-] \textit{Autocorrelation Length} is twice the sum of the correlations (at different interval lengths) minus 1.\\
	We typically sum up values until the correlations appear to be 0.\\
	From this we can calculate the effecitve sample size (\ie How many `independent' values we have sampled from all the iterations of the chain).
	$$\text{ESS}:=\frac{\#\text{ chain iterations}}{\text{Autocorrelation length}}$$
\end{itemize}
From these can perform better tests sub as two-sample Kologorov-Smirnov test, or ANOVA methods for multiple chains.\\

\remark{Interval Estimation from MCMC methods}
Given a sufficiently large sample from an \textit{MCMC Method} we can compute intervals by finding appropriate quantiles of the sample.

\subsection{Markov Chains}

\definition{Markov Chains} % 9.1
A \textit{Markov Chain} is a sequence of random vectors $\X_1,\X_2,\dots$ which satisfies the condition
$$\forall\ j,\ f(\x_j|\x_{j-1},\dots,\x_1)=f(\x_j|\x_{j-1})$$
\ie The probability of a realisation depends on the previous realisation only \& non-earlier.\\

\definition{Transition Kernel}
The \textit{Transition Kernel} of the \textit{Markov Chain} is the probability of transition to a given state, given the current state.
$$\prob(\x_j|\x_{j-1})$$

\definition{Stationary Distribution}
A \textit{Stationary Distribution} of a \textit{Markov Chain} is a distribution $f_x$ which satisfies
$$f_x(\x_j)=\int \prob(\x_j|\x_{j-1})f_x(\x_{j-1})d\x_{j-1}$$
\nb The existence of a \textit{Stationary Distribution} is not guaranteed \& depends on $\prob$ being irriducible (\ie whenever we start the chain, there is a positive probability of visiting all possible values of $\X$).\\

\definition{Recurrent}
A \textit{Markov Chain} is \textit{Recurrent} if we can start at any value of $\X$ and its marginal distribution, $\phi$, will eventually converge to the \textit{Stationary Distribution}, $f_x$.\\
For a simulation of length $J\to\infty$
$$\frac1J\sum_{j=1}^J\phi(\x_j)\to\expect_{f_x}(\phi(\X))$$
\nb This is know as \textit{Ergodicity}.\\

\remark{Reccurence is an extension of the WLLN to the correlated sequence \& is why MCMCs are useful.}

\definition{Detailed Balanced Condition}
Let $\prob(\pmb\theta_i|\pmb\theta_j)$ be the pdf of $\pmb\theta_i$ given $\pmb\theta_j$ according to the \textit{Markov Chain}.\\
The \textit{Detailed Balanced Condition} is that
$$\prob(\pmb\theta_j|\pmb\theta_{j-1})f(\pmb\theta_{j-1}|\textbf{y})=\prob(\pmb\theta_{j-1}|\pmb\theta_j)f(\pmb\theta_j|\textbf{y})$$
\nb Also know as \textit{Reversibility}.\\

\proposition{Using Detailed Balanced Condition}
Notice that the LHS of the \textit{Detailed Balanced Condition} is the joint pdf of $\pmb\theta_j\ \&\ \pmb\theta_{j-1}$.\\
Integrating both sides wrt $\pmb\theta_{j-1}$ gives
\[\begin{array}{rcl}
\displaystyle\int\prob(\pmb\theta_j|\pmb\theta_{j-1}f(\pmb\theta_{j-1}|\textbf{y})d\pmb\theta_{j-1}&=&\displaystyle\int\prob(\pmb\theta_{j-1}|\pmb\theta_j)f(\pmb\theta_j|\textbf{y})d\pmb\theta_{j-1}\\
&=&f(\pmb\theta_j|\textbf{y})
\end{array}\]
This means that if we start at a value, $\pmb\theta_1$, which is not impossible (\ie $f(\pmb\theta_1|\textbf{y})>0$), then the chain will generate from the target distribution.\\
\nb The speed of convergence to a high-probability region of $f(\pmb\theta|\textbf{y})$ is a different problem.

\subsection{Metropolis Hastings}

\proposition{Metropolis Hastings Method} % 9.3-9.6
The \textit{Metropolis Hastings Method} constructs a chain with an appropriate $P$.\\
\begin{enumerate}
	\item Propose a distribution $q(\pmb\theta_j|\pmb\theta_{j-1})$ (\eg Normal distribution centred around $\pmb\theta_{j-1}$).
	\item Pick a value $\pmb\theta_0$ \& set $j=1$.
	\item Generate $\pmb\theta_j'$ from $q(\pmb\theta_j|\pmb\theta_{j-1})$.
	\item Set $\pmb\theta_j=\pmb\theta_j'$ with probability
	$$\alpha=\min\bigg\{1,\quad\dfrac{\overbrace{f(\textbf{y}|\pmb\theta_j')}^{\propto f(\pmb\theta'_j|\mathbf{y})}f(\pmb\theta_j')q(\pmb\theta_{j-1}|\pmb\theta_j')}{\underbrace{f(\textbf{y}|\pmb\theta_{j-1})f(\pmb\theta_{j-1})}_{\propto f(\pmb\theta_{j-1}|\mathbf{y})}q(\pmb\theta'_j|\pmb\theta_{j-1})}\bigg\}$$
	\item Increment $j$.
	\item Repeat iii)-v) until convergence.
\end{enumerate}

\remark{Metropolis Hastings Method - $\alpha$}
Note that the $q$ terms cancel iff $q$ only depends on the magnitude of $(\pmb\theta_j-\pmb\theta_{j-1})$.\\
This occurs if $q$ is a normal distribution centred on $\pmb\theta_{j-1}$.\\
The priors, $f(\pmb\theta'_j)\ \&\ f(\pmb\theta_{j-1})$, cancel out if they are impropert uniform.\\
If both $q$ \& prior terms cancel out then
$$\alpha(\pmb\theta',\pmb\theta)=\min\left\{1,\quad\dfrac{L(\pmb\theta_j')}{L(\pmb\theta_{j-1})}\right\}$$

\remark{Metroplis Hastings Method - Choosing Initial Guess, $\pmb\theta_0$}
$\pmb\theta_0$ may be highly imporbably, meaning the chian will require many iteraions to reach a region of high-probability in $f(\pmb\theta|\textbf{y})$.\\
Usually we discard the \textit{burn-in period} (\ie first few hundred $\pmb\theta_j$ vectors simulated where little progress is made).\\

\remark{Metropolis Hastings Method - Choosing Proposed Distribution, $q$}
Generally we perform several pilor runs of the \textit{Metropolis-Hastings Sampler} in order to `tune' the proposal distribution.
\begin{enumerate}
	\item It is often necessary to update parameters in blocks.
	\item The perfect proposal is the posterior itself (so will never be met).
\end{enumerate}

\proof{Metropolis Hastings Method}
Here it is shown that \textit{Metropolis-Hastings Method} works if it satisfies \text{\textit{Reversibility}}.\\
For notation, let $\pi(\pmb\theta):=f(\pmb\theta|\mathbf{y})\propto f(\textbf{y}|\pmb\theta)f(\pmb\theta)$.\\
This means the acceptance probability from $\pmb\theta$ to $\pmb\theta'$ is
$$\alpha(\pmb\theta',\pmb\theta)=\min\left\{1,\dfrac{\pi(\pmb\theta')q(\pmb\theta|\pmb\theta')}{\pi(\pmb\theta)q(\pmb\theta'|\pmb\theta)}\right\}$$
We need to show that $\pi(\pmb\theta)f(\pmb\theta'|\pmb\theta)=\pi(\pmb\theta')f(\pmb\theta|\pmb\theta')$.\\
This is trivial if $\pmb\theta'=\pmb\theta$.\\
Otherwise (\ie $\pmb\theta'\neq\pmb\theta$):\\
We know that $f(\pmb\theta'|\pmb\theta)=q(\pmb\theta'|\pmb\theta)\alpha(\pmb\theta',\pmb\theta)$ by rearrangement. Thus
\[\begin{array}{rcl}
\pi(\pmb\theta)f(\pmb\theta'|\pmb\theta)&=&\pi(\pmb\theta)q(\pmb\theta'|\pmb\theta)\alpha(\pmb\theta',\pmb\theta)\\
&=&\pi(\pmb\theta)q(\pmb\theta'|\pmb\theta)\min\left\{1,\quad\dfrac{\pi(\pmb\theta')q(\pmb\theta|\pmb\theta')}{\pi(\pmb\theta)q(\pmb\theta'|\pmb\theta)}\right\}\\
&=&\min\{\pi(\pmb\theta)q(\pmb\theta'|\pmb\theta),\pi(\pmb\theta')q(\pmb\theta|\pmb\theta')\}\\
&=&\pi(\pmb\theta')d(\pmb\theta|\pmb\theta')\text{ by symmetry}
\end{array}\]
\proved

\subsection{Gibbs Sampling}

\definition{Gibbs Sampling} % 9.7-9.9
Suppose the parameter row vector is partitioned into subvectors st $\pmb\theta\equiv(\pmb\theta^{[1]},\dots,\pmb\theta^{[K]})$.\\
Further, define $$\tilde{\pmb\theta}_j^{[\neg k]}:=(\pmb\theta_{j+1}^{[1]},\dots,\pmb\theta_{j+1}^{[k-1]},\pmb\theta_{j}^{[k+1]},\dots,\pmb\theta_{j}^{[K]})$$
Let $\pmb\theta_1$ be an initial guess.\\
We perform $J$ steps of the \textit{Gibbs Sampler Process} as follows
\begin{enumerate}
	\item For $j\in[1,J]$, $k\in[1,K]$:
	\begin{enumerate}
		\item Simulate $\pmb\theta_{j+1}^{[\neg k]}\sim f(\pmb\theta^{[k]}|\tilde{\pmb\theta}_j^{[-k]},\textbf{y})$.\\
		\nb \text{We are conditioning on the most recently simulated values due to definition of $\tilde{\pmb\theta}_j^{[-k]}$.}
	\end{enumerate}
\end{enumerate}

\remarkk{Gibbs Sampling - Finding Conditional Distributions}
\begin{itemize}
	\item[-] Generally we will be able to recognise the conditions as some standar distribution.\\
	This often relies on noting that any multiplicative factors of a pdf which do not involve the argument of the pdf are part of the normalising constant \& thus recognise the pdf only requires recognising the form to within a normalising constant.
	\item[-] If not, we can devise some way of simulating them.
	\item[-] As a last resort, \textit{Metropolis Hastings} can be used for this step.
\end{itemize}

\remark{Gibbs Sampling - Limitations}
\begin{itemize}
	\item[-] \textit{Gibbs Sampling} produces a slow moving chain if parameters have high posterior correlation, as sampling from these conditionals produces very small steps.\\
Updating the parameters in blocks or reparameterising to reduce posterior dependence can help to improve mixing.
	\item[-] If improper priors are used with \textit{Gibbs Sampling}, then it is important to check that the posterior is actually proper .\\
	It is not always possible to detect impropriety for the output of the sampler.
\end{itemize}

\subsection{Automatic Gibbs Sampling}

\proposition{Gibbs Sampling uses Graphical Models (\textbf{Section 1.3})}
Let $x_i$ represent the variable associated with the $i^\text{th}$ node in a given \textit{Graphical Model}.\\
\textit{Gibbs Sampling} requires simulating from the full conditionals of all unobserved \textit{Stochastic Nodes}.\\
From the \textit{Graphical Model} we can infer a distribution
\[\begin{array}{rcl}
f(x_k|\x^{[\neg k]})&=&\dfrac{f(\x)}{\int f(\x)dx_k}\\
&=&\dfrac{\prod_if(x_i|\text{parents}(x_i))}{\int\prod_if(x_i|\text{parents}(x_i))dx_k}\text{ by \textbf{Proposition 1.2}}\\
&=&\dfrac{f(x_k|\text{parents}(x_k))\prod_{i\in\text{children}(x_k)}f(x_i|\text{parents}(x_i))}{\int f(x_k|\text{parents}(x_k))\prod_{i\in\text{children}(x_k)}f(x_i|\text{parents}(x_i))dx_k}\text{ since \footnotemark}\\
&\propto&f(x_k|\text{parents}(x_k))\prod_{i\in\text{children}(x_k)}f(x_i|\text{parent}(x_i))
\end{array}\]
\footnotetext{The terms which don't invlove $x_k$ can be removed from the intergral and then cancel out.}
This shows that, no matter how complicated the \textit{Graphical Model} is, the conditional required for the \textit{Gibbs Update} of $x_j$, $f(x_j|\x^{[-j]})$ depends only on the parent conditional densities of $x_j$ and its children.\\
This is a relatively small number of terms.\\

\proposition{Conjugate Distributions}
The RHS of the final result in \textbf{Proposition 4.4} has the same structure as a \textit{Prior} for $x_j$, $f(x_j|\text{parents}(x_j))$, multiplied by a \textit{Likelihood} term for $x_j$.\\
This means we can use \textit{conjugacy of distributions} to ascertain the density of $f(x_k|\x^{[-j]})$.\\

\proposition{Slice Sampling}
\textit{Slice Sampling} is used when there is no convenient form of the conditional, $f(x_j|\x^{[-j]})$.\\
\textit{Slice Sampling} is done as follows
\begin{enumerate}
	\item Chose some finite $k>0$.
	\item Sample $y$ uniformly from $[0,kf(x)]$.
	\item Return an $x$ which satisfies $kf(x)\geq y$.
\end{enumerate}
Here we are sampling from two distributions
$$f(y|x)\sim U(0,kf(x))\quad\text{and}\quad f(x|y)\sim U(x\in\{x:kf(x)\geq y\})$$
To identify the set $\{x:kf(x)\geq y\}$ in \textit{Uni-Modal Distributions} requires finding a single interval, but for \textit{Multi-Modal Distributions} we need to find serveral.

\subsection{Estimating Posterior Point-Value}

\definition{Posterior Mode} %11
The \textit{Posterior Mode} is the set of parameter values with the greatest likelihood, according to the \textit{Posterior Distribution}.
$$\hat{\pmb\theta}:=\argmax_\theta f(\pmb\theta|\textbf{y})$$
\nb This is the parameters which are most consistent with the data.\\

\proposition{Improper Uniform Prior}
If we specify an improper uniform prior, $f(\pmb\theta)=k$, then $f(\pmb\theta|\textbf{y})\propto f(\textbf{y}|\pmb\theta)$ and the \textit{Posterior Modes} are equivalent to the \textit{Maximum Likelihood Estimates}.\\

\proposition{Large Sample Size}
For a large sample size the \textit{Posterior Mode} is the \textit{Maximum Likelihood Estimate}
$$\pmb\theta|\textbf{y}\sim\text{Normal}(\hat{\pmb\theta}_\text{MLE},\mathcal{I}^{-1})$$

\section{Bayesian Inference}

\definition{Loss Function}
A \textit{Loss Function} quantifies the loss associated with a particular set of parameter predictions, $\hat{\pmb\theta}$.\\
We wish to find the set of parameters which minimise a \textit{Loss Function}.\\

\definition{Marginal Likelihood} % 11.1.1
The \textit{Marginal Likelihood} of a model, $M$, is the marginal density of observing the outcomes
$$f(\textbf{y}|M)=\int f(\textbf{y}|\pmb\theta)f(\pmb\theta)d\pmb\theta$$
where $\pmb\theta$ are the parameters of $M$.\\
\nb This is hard to calculate.\\

\remark{The value of the Marginal Likelihood is sensitive to the chosen Prior}

\subsection{Bayes Factors}

\definition{Bayes Factor} % 11.1.1 & 11.1.2
Let $M_0$ \& $M_1$ be two models and $\textbf{y}$ some observed data.\\
\textit{Bayes Factor} summarises the evidence for/against two alernative models.
$$B_{10}:=\dfrac{f(\textbf{y}|M_1)}{f(\textbf{y}|M_0)}\equiv\dfrac{\prob(M_1|\textbf{y})\prob(M_0)}{\prob(M_0|\textbf{y})\prob(M_1)}$$
We interpret semantic meaning of \textit{Bayes Factor} using the value of $2\ln B_{10}$
\begin{center}
\begin{tabular}{c|l}
$2\ln B_{10}$&Evidence against $B_{10}$\\
\hline
$0-2$&Barely worth mentioning\\
$2-6$&Positive\\
$6-10$&Strong\\
$>10$&Very Strong\\\hline
\end{tabular}
\end{center}
\nb This is similar to the \textit{$p$-Value} in the \textit{Frequentist Approach}.\\

\remark{Bayes Factor v Likelihood Ratio Statistic}
\textit{Bayes Factor} uses \textit{Marginal Distributions} which requires integrating over all possible parameter values. This is the major difference between \textit{Bayes Factor} \& the \textit{Likelihood Ratio Statistic}.\\

\remark{Due to sensitivity of Marginal Likelihood on the Prior, we usually cannot justify using Bayes Factor}
We can only justify it when the priors that differ between alternative models are really precise \& are meaningful representation of prior knowledge.\\
Even in this case it is hard to compute the marginal likelihood.\\

\proposition{Partial Bayes Factor}
Let $\textbf{y}$ be some observered data \& $(\x,\textbf{z})$ a partitioning of $\textbf{y}$.\\
Using $f(\pmb\theta|\x)$ as the prior gives \textit{Marginal Likelihood} of $\textbf{z}$ under model $M$
$$f(\textbf{z}|M,\x)=\int f(\textbf{z}|\pmb\theta,\x)f(\pmb\theta|\x)d\pmb\theta$$
We know that $f(\pmb\theta|\x)=\dfrac{f(\x|\pmb\theta)f(\pmb\theta)}{f(\x)}=\dfrac{f(\x|\pmb\theta)f(\pmb\theta)}{\int f(\x|\pmb\theta)f(\pmb\theta)d\pmb\theta}$.\\
Thus we get the \textit{Partial Bayes Fator}
\[\begin{array}{rcl}
f(\textbf{z}|M,\x)&=&\dfrac{\int f(\textbf{z}|\pmb\theta,\x)f(\x|\pmb\theta)f(\pmb\theta)d\pmb\theta}{\int f(\x|\pmb\theta)f(\pmb\theta)d\pmb\theta}\text{ by substitution}\\
&=&\dfrac{\int f(\textbf{y}|\pmb\theta)f(\pmb\theta)d\pmb\theta}{\int f(\textbf{x}|\pmb\theta)f(\pmb\theta)d\pmb\theta}
\end{array}\]
Since the same prior is used on the top \& bottom, the sensitivity to the prior is reduced.\\

\definition{Intrinsic Bayes Factor}
An \textit{Intrinsic Bayes Factor} is an extension of \textit{Partial Bayes Factors}.\\
When partitioning the observed data, $\textbf{y}$, into $(\x,\textbf{z})$ we ensure $\x$ is just large enough that $f(\pmb\theta|\x)$ is proper and then average the resulting \textit{Partial Bayes Factors} over all such $\x$.\\
This removes the arbitrariness of any particular choice of $\x$.\\

\definition{Fractional Bayes Factor}
There is a result that $f(\x|\pmb\theta)\approx f(\textbf{y}|\pmb\theta)^b$ where $b:=\dfrac{\text{dim}(\x)}{\text{dim}(\textbf{y})}$.\\
A \textit{Fractional Bayes Factor} combines this result with the result of \textit{Partial Bayes Factor} to get
$$f(\textbf{z}|M,\x)\approx\dfrac{\int f(\textbf{y}|\pmb\theta)f(\pmb\theta)d\pmb\theta}{\int f(\textbf{y}|\pmb\theta)^bf(\pmb\theta)d\pmb\theta}\text{ where }b:=\dfrac{\text{dim}(\x)}{\text{dim}(\textbf{y})}$$
For this to select the right model in large sample size, then $b\to0$ as $n\to\infty$.

\subsection{Information Criterion}

\proposition{Information Criterion}
\textit{Information Criterion} are an older method for comparing two models \& they avoid the difficulties around the sensitivity wrt priors.\\

\definition{Bayesian Information Criterion} %11.1.3
Let $\textbf{y}$ be observed data of dimension $n$ \& $\pmb\theta$ be the model parameters with dimension $p$.\\
The \textit{Bayesian Information Criterion} of a model is defined as
$$BIC:=-2\ln f(\textbf{y}|\hat{\pmb\theta}_{MLE})+p\ln n$$

\proposition{Comapring BIC}
The difference in \textit{Bayesian Information Criterion} for two models is an approximation of twice the \textit{log Bayes Factor}.\\
We should select the model with the lower \textit{BIC}.\\
%TODO derivation

\proposition{Derivining BIC}
Let $\textbf{y}$ be observed data of dimension $n$ \& $\pmb\theta$ be the model parameters with dimension $p$.\\
Define $P$ to be the marginal likelihood of observing $\textbf{y}$.
$$P:=\int f(\textbf{y}|\pmb\theta)f(\pmb\theta)d\pmb\theta$$
Define $\tilde{\pmb\theta}:=\argmax_\theta f(\textbf{y}|\pmb\theta)f(\pmb\theta)$.\\
By a \textit{Taylor Expansion} we have
\[\begin{array}{rrcl}
&\ln[f(\textbf{y}|\pmb\theta)f(\pmb\theta)]&\simeq&\ln[f(\textbf{y}|\tilde{\pmb\theta})f(\tilde{\pmb\theta})]-\frac12(\pmb\theta-\tilde{\pmb\theta})^T\left(-\dfrac{\partial^2\ln[f(\textbf{y}|\pmb\theta)f(\pmb\theta)]}{\partial\pmb\theta\partial\pmb\theta^T}\right)(\pmb\theta-\tilde{\pmb\theta})\\
\implies&f(\textbf{y}|\pmb\theta)f(\pmb\theta)&\simeq&f(\textbf{y}|\pmb\theta)f(\pmb\theta)\text{exp}\left\{-\frac12(\pmb\theta-\tilde{\pmb\theta})^T\left(-\dfrac{\partial^2\ln[f(\textbf{y}|\pmb\theta)f(\pmb\theta)]}{\partial\pmb\theta\partial\pmb\theta^T}\right)(\pmb\theta-\tilde{\pmb\theta})\right\}
\end{array}\]
The term in the curly braces is from a multivaraite normal pdf. Thus
$$P\simeq f(\textbf{y}|\tilde{\pmb\theta})f(\tilde{\pmb\theta})(2\pi)^{p/2}\left|-\frac{\partial^2\ln[f(\textbf{y}|\pmb\theta)f(\pmb\theta)]}{\partial\pmb\theta}{\partial\pmb\theta^T}\right|^{-1/2}$$
As $n\to\infty$ we have $-\dfrac{\partial^2\ln[f(\textbf{y}|\pmb\theta)f(\pmb\theta)]}{\partial\pmb\theta}{\partial\pmb\theta^T}=n\mathcal{I}_0$ where $\mathcal{I}_0$ is the (fixed) information matrix for a single obseration. Thus
$$\left|-\frac{\partial^2\ln[f(\textbf{y}|\pmb\theta)f(\pmb\theta)]}{\partial\pmb\theta}{\partial\pmb\theta^T}\right|=n^p|\mathcal{I}_0|$$
Thus
$$\ln P\simeq\ln f(\textbf{y}|\tilde{\pmb\theta})+\ln f(\tilde{\pmb\theta})+\frac{p}2\ln2\pi-\frac{p}2\ln n-\frac12\ln|\mathcal{I}_0|$$
As $n\to\infty$, $\tilde{\pmb\theta}\to\hat{\pmb\theta}_{MLE}$ while ther terms that do not depend on $n$ become negligible.\\
Thus we arrive at the \textit{Bayesian Information Criterion} by removing those terms \& substituting this result.\\

\remark{In Complex Bayesian Models it is not always clear how to count the number of free parameters in the model.}
Since priors restrict the freedom of a parameter to vary.\\

\definition{Deviance}
\textit{Deviance} is a measure of the number of `effective' degrees of freedom in a \textit{Bayesian Model}.
$$D(\pmb\theta):=-2\ln f(\textbf{y}|\pmb\theta)+c$$
where $c$ is a neglectable constant depending only on the $\textbf{y}$.\\

\remark{In the large sample domain $D(\pmb\theta)-D(\expect(\pmb\theta))\sim\chi^2_r$}

\definition{Effective Degrees of Freedom}
\textit{Effective Degrees of Freedom} is a measure of how many parameters are free in a \textit{Bayesian Model}.
$$p_D:=\overline{D(\pmb\theta)}-D(\overline{\pmb\theta})$$

\remark{}
\textit{Effective Degrees of Freedom}, $p_D$, is a direct estimate of $\expect[D(\pmb\theta)-D(\expect(\pmb\theta))]$.\\
Noting that $\expect(\chi^2_r)=$.\\

\definition{Deviance Information Criterion} %11.1.4
The \textit{Deviance Information Criterion} is defined as
$$DIC:=D(\overline{\pmb\theta})+2p_D$$
\nb This is similar to the \textit{AIC}.

\newpage\setcounter{section}{-1}
\section{Appendix}

\subsection{Definitions}

\definition{Proper}

\definition{Parametric Models}
\textit{Parameteric Models} are \textit{Statistical Models} whose only unkowns are parameters.\\

\definition{Semi-Parametric Models}
\textit{Parameteric Models} are \textit{Statistical Models} which contain unknown parameters \underline{and} unknown functions.\\

\definition{Non-Parametric Models}
\textit{Non-Parametric Models} make \textit{few} prior assumptions about how data was generated and instead depend mainly on the observed data.\\
We \underline{cannot} simulate data from \textit{Non-Parameteric Models}.\\

\definition{Orthongonal Matrix}
A matrix $\X$ is \textit{Orthogonal} if
$$\X^T\X=\X\X^T=I\implies\X^T=\X^{-1}$$
\textit{Orthogonal Matrices} rotate \& reflect vectors without changing their magnitude.\\
\nb $\X^T$ is \textit{Orthogonal}.\\

\definition{Full Rank Matrix}
Let $\X\in\reals^{m\times n}$.\\
If $m>n$ then $\X$ has \textit{Full Rank} iff all its \underline{columns} are linearly independent.\\
If $n>m$ then $\X$ has \textit{Full Rank} iff all its \underline{rows} are linearly independent.\\
\nb In statistics the number of $m>n$ always as we should have more observations than fields.\\

\definition{Upper Triangle Matrix}
A matrix $X$ is an \textit{Upper Triangle Matrix} if $X_{i,j}=0$ for $i>j$.\\

\definition{Unbiased Estimator}
An \textit{Estimator} of a parameter, $\hat\theta$, is unbiased if its expected value is the true value of the parameter for all possible parameter values
$$\expect(\hat\theta;\theta=\theta^*)=\theta^*$$

\definition{Conjugacy}
\definition{Fisher Information}
\definition{Correlation}
\definition{Covariance}
\definition{Expected Value}
\definition{Variance}

\definition{Positive Definite Matrix}
A matrix is \textit{Positive Definite} if it is symmetric and all its eigenvalues are \underline{positive}.\\

\definition{Positive Semi-Definite Matrix}
A matrix is \textit{Postitive Semi-Definite} if all its eigenvalues are \underline{non-negative}.

\definition{Taylor's Theorem}
\definition{Casual Inference}

\definition{Consistent Estimator}
A \textit{Parameter Estimator}, $\hat{\pmb\theta}_n$, is \textit{Consistent} if its value tends to the true parameter value, $\pmb\theta^*$, as sample size tends to infinity
$$\hat{\pmb\theta}_n\overset{n\to\infty}{\longrightarrow}\pmb\theta^*$$

\subsection{Theorems}

\theorem{Bayes' Theorem}
Suppose $X\sim f(\cdot;\Theta)$. Then
$$\underbrace{\prob(\Theta|X)}_\text{Posterior}=\frac{\overbrace{\prob(X|\Theta)}^\text{Likelihood}\overbrace{\prob(\Theta)}^\text{Prior}}{\underbrace{\prob(X)}_\text{Evidence}}$$

\theorem{Euclidean Distance Identities}
$$\|\x\|^2=\x^T\x=\sum_{i=1}^nx_i^2$$

\theorem{}
If $\X$ and $\textbf{Y}$ are independent. Then
$$\X\textbf{Y}\simeq\pmb0$$
%TODO find the formal version of this

\theorem{Jensen's Inequality}
For any random variable $X$ and concave function $f$
$$f[\expect(X)]\geq\expect[f(X)]$$

\subsection{Remarks}

\remark{Conditional from Joint}
If we are given a joint distribution $f(x,y)$ and factor out its normalising constant, we can read off the conditional distribution of a variable ($f(x|y)$ or $f(y|x)$) by just using the terms which include the variable.\\
The distribution should then be recognisable \& the normalising constant findable.


\end{document}
